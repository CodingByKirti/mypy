{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b38da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_excel_file.xlsx'  # Replace with your file path\n",
    "output_file_path = 'grouped_data_with_subtables.xlsx'  # Replace with your desired output file path\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create a Pandas Excel writer object\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read each sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "        # Group the data by 'Mapped L3' and 'Role_temp'\n",
    "        grouped = df.groupby(['Mapped L3', 'Role_temp'])\n",
    "\n",
    "        # Count the occurrences of 'High' and 'Low' in the 'High/Low' column\n",
    "        result = grouped['High/Low'].value_counts().unstack(fill_value=0).fillna(0)\n",
    "\n",
    "        # Add totals for each row ('Mapped L3', 'Role_temp')\n",
    "        result['Total'] = result.sum(axis=1)\n",
    "\n",
    "        # Add a totals row\n",
    "        total_row = result.sum(axis=0).to_frame().T\n",
    "        total_row.index = pd.MultiIndex.from_tuples([('Total', '')])\n",
    "        result = pd.concat([result, total_row])\n",
    "\n",
    "        # Reset the index to get 'Mapped L3' and 'Role_temp' as columns\n",
    "        result.reset_index(inplace=True)\n",
    "\n",
    "        # Ensure 'High' and 'Low' are present, if not add them with default 0 values\n",
    "        if 'High' not in result.columns:\n",
    "            result['High'] = 0\n",
    "        if 'Low' not in result.columns:\n",
    "            result['Low'] = 0\n",
    "        result = result[['Mapped L3', 'Role_temp', 'High', 'Low', 'Total']]\n",
    "\n",
    "        # Write the grouped data to the sheet\n",
    "        result.to_excel(writer, sheet_name=sheet_name, startrow=0, index=False)\n",
    "        \n",
    "        # Load the workbook and access the worksheet\n",
    "        workbook = writer.book\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Initialize start row for writing subtables\n",
    "        start_row = len(result) + 2  # Move to the next row after grouped data\n",
    "\n",
    "        # Create subtables for each unique 'Mapped L3'\n",
    "        unique_mapped_l3 = df['Mapped L3'].unique()\n",
    "        for mapped_l3 in unique_mapped_l3:\n",
    "            # Skip 'Total' rows if present\n",
    "            if mapped_l3 == 'Total':\n",
    "                continue\n",
    "\n",
    "            # Filter the original DataFrame based on 'Mapped L3'\n",
    "            mapped_l3_data = df[df['Mapped L3'] == mapped_l3]\n",
    "\n",
    "            # Insert a heading for unique 'Mapped L3'\n",
    "            mapped_l3_heading = f\"Unique L3 Value: {mapped_l3}\"\n",
    "            worksheet.cell(row=start_row + 1, column=1, value=mapped_l3_heading)\n",
    "\n",
    "            # Move to the next row after writing unique L3 heading\n",
    "            start_row += 2\n",
    "\n",
    "            # Iterate over each unique 'Role_temp' for the current 'Mapped L3'\n",
    "            unique_role_temp = mapped_l3_data['Role_temp'].unique()\n",
    "            for role_temp in unique_role_temp:\n",
    "                # Filter the data for the current 'Mapped L3' and 'Role_temp'\n",
    "                subtable_data = mapped_l3_data[mapped_l3_data['Role_temp'] == role_temp]\n",
    "\n",
    "                # Insert a heading for 'Role_temp'\n",
    "                role_temp_heading = f\"Role Type: {role_temp}\"\n",
    "                worksheet.cell(row=start_row + 1, column=1, value=role_temp_heading)\n",
    "\n",
    "                # Move to the next row after writing role_temp heading\n",
    "                start_row += 2\n",
    "\n",
    "                # Write the subtable data to the sheet\n",
    "                subtable_data.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False, header=True)\n",
    "\n",
    "                # Move to the next row after writing subtable data\n",
    "                start_row += len(subtable_data) + 1  # Add 1 line gap after each role_temp subtable\n",
    "\n",
    "            # Add a 2-line gap after each Mapped L3 section\n",
    "            start_row += 2\n",
    "\n",
    "print(f\"Grouped data with subtables has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901416c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_excel_file.xlsx'  # Replace with your file path\n",
    "output_file_path = 'grouped_data_with_subtables.xlsx'  # Replace with your desired output file path\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create a Pandas Excel writer object\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read each sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "        # Group the data by 'Mapped L3' and 'Role_temp'\n",
    "        grouped = df.groupby(['Mapped L3', 'Role_temp'])\n",
    "\n",
    "        # Count the occurrences of 'High' and 'Low' in the 'High/Low' column\n",
    "        result = grouped['High/Low'].value_counts().unstack(fill_value=0).fillna(0)\n",
    "\n",
    "        # Add totals for each row ('Mapped L3', 'Role_temp')\n",
    "        result['Total'] = result.sum(axis=1)\n",
    "\n",
    "        # Add a totals row\n",
    "        total_row = result.sum(axis=0).to_frame().T\n",
    "        total_row.index = pd.MultiIndex.from_tuples([('Total', '')])\n",
    "        result = pd.concat([result, total_row])\n",
    "\n",
    "        # Reset the index to get 'Mapped L3' and 'Role_temp' as columns\n",
    "        result.reset_index(inplace=True)\n",
    "\n",
    "        # Ensure 'High' and 'Low' are present, if not add them with default 0 values\n",
    "        if 'High' not in result.columns:\n",
    "            result['High'] = 0\n",
    "        if 'Low' not in result.columns:\n",
    "            result['Low'] = 0\n",
    "        result = result[['Mapped L3', 'Role_temp', 'Total', 'High', 'Low']]\n",
    "\n",
    "        # Initialize start row for writing grouped data\n",
    "        start_row = 0\n",
    "\n",
    "        # Write the grouped data to the sheet\n",
    "        result.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "        start_row += len(result) + 2  # Move to the next row after grouped data\n",
    "\n",
    "        # Create subtables for each unique 'Mapped L3'\n",
    "        unique_mapped_l3 = df['Mapped L3'].unique()\n",
    "        for mapped_l3 in unique_mapped_l3:\n",
    "            # Skip 'Total' rows if present\n",
    "            if mapped_l3 == 'Total':\n",
    "                continue\n",
    "\n",
    "            # Filter the original DataFrame based on 'Mapped L3'\n",
    "            mapped_l3_data = df[df['Mapped L3'] == mapped_l3]\n",
    "\n",
    "            # Insert a heading for unique 'Mapped L3'\n",
    "            mapped_l3_heading = f\"Unique L3 Value: {mapped_l3}\"\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            worksheet.cell(row=start_row, column=1, value=mapped_l3_heading)\n",
    "\n",
    "            # Move to the next row after writing unique L3 heading\n",
    "            start_row += 2\n",
    "\n",
    "            # Iterate over each unique 'Role_temp' for the current 'Mapped L3'\n",
    "            unique_role_temp = mapped_l3_data['Role_temp'].unique()\n",
    "            for role_temp in unique_role_temp:\n",
    "                # Filter the data for the current 'Mapped L3' and 'Role_temp'\n",
    "                subtable_data = mapped_l3_data[mapped_l3_data['Role_temp'] == role_temp]\n",
    "\n",
    "                # Insert a heading for 'Role_temp'\n",
    "                role_temp_heading = f\"Role Type: {role_temp}\"\n",
    "                worksheet.cell(row=start_row, column=1, value=role_temp_heading)\n",
    "\n",
    "                # Move to the next row after writing role_temp heading\n",
    "                start_row += 2\n",
    "\n",
    "                # Insert an empty row to separate headings from subtable data\n",
    "                worksheet.cell(row=start_row, column=1, value=\"\")\n",
    "\n",
    "                # Move to the next row after inserting empty row\n",
    "                start_row += 1\n",
    "\n",
    "                # Write the subtable data to the sheet\n",
    "                subtable_data.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "\n",
    "                # Move to the next row after writing subtable data\n",
    "                start_row += len(subtable_data) + 2  # Add extra space after each subtable\n",
    "\n",
    "print(f\"Grouped data with subtables has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19c99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS\n",
      "0    1    10  NaN\n",
      "1    2    20  NaN\n",
      "2    3    30    a\n",
      "3    4    40    b\n",
      "4    7    50    c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4, 7],\n",
    "    'colB': [10, 20, 30, 40, 50],\n",
    "    'colS': [None, None, None, None, None]  # Initially None or some default value\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    'colPM': [7, 8, 9, 10, 11, 12]\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA, colR, and colPM are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "df2['colPM'] = df2['colPM'].astype(str)\n",
    "\n",
    "# Initial merge using colA and colR\n",
    "df_merged_initial = pd.merge(df1, df2[['colR', 'colS']], left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Update df1's colS with the values from initial merge\n",
    "df1['colS'] = df_merged_initial['colS_y']\n",
    "\n",
    "# Identify rows where colS is still NaN\n",
    "mask = df1['colS'].isna()\n",
    "\n",
    "# Perform the second merge using colA and colPM for the NaN rows\n",
    "df_merged_second = pd.merge(df1[mask], df2[['colPM', 'colS']], left_on='colA', right_on='colPM', how='left')\n",
    "\n",
    "# Update colS in df1 for the NaN rows with values from the second merge\n",
    "df1.loc[mask, 'colS'] = df_merged_second['colS_y']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5784398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS\n",
      "0    1    10  NaN\n",
      "1    2    20  NaN\n",
      "2    3    30    a\n",
      "3    4    40    b\n",
      "4    7    50    c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4, 7],\n",
    "    'colB': [10, 20, 30, 40, 50],\n",
    "    'colS': [None, '', ' ', '   ', '']  # Different types of empty or blank values\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    'colPM': [7, 8, 9, 10, 11, 12]\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA, colR, and colPM are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "df2['colPM'] = df2['colPM'].astype(str)\n",
    "\n",
    "# Initial merge using colA and colR\n",
    "df_merged_initial = pd.merge(df1, df2[['colR', 'colS']], left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Update df1's colS with the values from initial merge\n",
    "df1['colS'] = df_merged_initial['colS_y']\n",
    "\n",
    "# Identify rows where colS is empty or blank\n",
    "mask = df1['colS'].apply(lambda x: x == '' or x.isspace() if isinstance(x, str) else False)\n",
    "\n",
    "# Perform the second merge using colA and colPM for the empty or blank rows\n",
    "df_merged_second = pd.merge(df1[mask], df2[['colPM', 'colS']], left_on='colA', right_on='colPM', how='left')\n",
    "\n",
    "# Update colS in df1 for the empty or blank rows with values from the second merge\n",
    "df1.loc[mask, 'colS'] = df_merged_second['colS_y']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44b6bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colA</th>\n",
       "      <th>colB</th>\n",
       "      <th>colS_x</th>\n",
       "      <th>colPM</th>\n",
       "      <th>colS_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  colA  colB colS_x colPM colS_y\n",
       "0    1    10    NaN   NaN    NaN\n",
       "1    2    20    NaN   NaN    NaN\n",
       "2    7    50    NaN     7      a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b765483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS1\n",
      "0    1    10   NaN\n",
      "1    2    20   NaN\n",
      "2    3    30     a\n",
      "3    4    40     c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4],\n",
    "    'colB': [10, 20, 30, 40],\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA and colR are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "\n",
    "# Select only the required columns from df2\n",
    "df2_selected = df2[['colR', 'colS']].drop_duplicates(subset='colR')\n",
    "\n",
    "# Merge df1 with df2_selected on colA and colR\n",
    "df_merged = pd.merge(df1, df2_selected, left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Assign the values to the new column in df1 and drop any extra columns\n",
    "df1['colS1'] = df_merged['colS']\n",
    "\n",
    "# Drop the extra merge column if needed (not strictly necessary, but clean)\n",
    "df1.drop(columns=['colR'], inplace=True, errors='ignore')\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d80a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colA colS1\n",
      "0     1   NaN\n",
      "1     2   NaN\n",
      "2     3     a\n",
      "3     4     b\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1\n",
    "data1 = {'colA': [1, 2, 3, 4]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with non-unique colR values\n",
    "data2 = {'colR': [3, 3, 4, 5, 6, 6], 'colS': ['a', 'b', 'c', 'd', 'e', 'f']}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge df1 with df2 on the condition that df1['colA'] matches df2['colR']\n",
    "df_merged = pd.merge(df1, df2, left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Select only relevant columns and rename them\n",
    "df1['colS1'] = df_merged['colS']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c042a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id colX colY colZ\n",
      "0   6   X6   Y6   Z6\n",
      "1   7   X7   Y7   Z7\n",
      "2   8   X8   Y8   Z8\n",
      "3   1  NaN   B1   C1\n",
      "4   2  NaN   B2   C2\n",
      "5   3  NaN   B3   C3\n",
      "6   4  NaN   B4   C4\n",
      "7   5  NaN   B5   C5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'colA': ['A1', 'A2', 'A3', 'A4', 'A5'],\n",
    "    'colB': ['B1', 'B2', 'B3', 'B4', 'B5'],\n",
    "    'colC': ['C1', 'C2', 'C3', 'C4', 'C5']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [6, 7, 8],\n",
    "    'colX': ['X6', 'X7', 'X8'],\n",
    "    'colY': ['Y6', 'Y7', 'Y8'],\n",
    "    'colZ': ['Z6', 'Z7', 'Z8']\n",
    "})\n",
    "\n",
    "# Columns to copy from df1 and their corresponding columns in df2\n",
    "columns_to_copy = {\n",
    "    'id': 'id',\n",
    "    'colB': 'colY',\n",
    "    'colC': 'colZ'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with the selected columns from df1\n",
    "new_rows = df1[list(columns_to_copy.keys())].copy()\n",
    "\n",
    "# Rename the columns in the new DataFrame to match the column names in df2\n",
    "new_rows.rename(columns=columns_to_copy, inplace=True)\n",
    "\n",
    "# Append the new DataFrame to df2\n",
    "df2 = df2.append(new_rows, ignore_index=True)\n",
    "\n",
    "# Display the updated df2\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08dd5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
