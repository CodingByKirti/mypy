{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6740ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyxlsb import open_workbook\n",
    "\n",
    "# Load the xlsb file\n",
    "wb2_path = 'path_to_wb2.xlsb'  # Update with the actual path to wb2\n",
    "\n",
    "# Open the 'HC - Actual' sheet\n",
    "with open_workbook(wb2_path) as wb:\n",
    "    sheet = wb.get_sheet('HC - Actual')\n",
    "\n",
    "    # Initialize variables\n",
    "    E15 = None\n",
    "    F15 = None\n",
    "    data = []\n",
    "\n",
    "    # Iterate over rows and extract values\n",
    "    for row in sheet.rows():\n",
    "        row_index = row[0].r  # Row index starts at 1 in xlsb\n",
    "\n",
    "        # Check and capture values in row 15\n",
    "        if row_index == 15:\n",
    "            E15 = row[4].v  # E15\n",
    "            F15 = row[5].v  # F15\n",
    "\n",
    "        # Capture all data starting from row 14 (header candidates and data)\n",
    "        if row_index >= 14:\n",
    "            data.append([item.v for item in row])\n",
    "\n",
    "# Identify if row 14 or 15 should be headers based on E15 and F15 values\n",
    "month_headers = ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07', 'M08', 'M09', 'M10', 'M11', 'M12']\n",
    "\n",
    "if E15 in month_headers and F15 in month_headers:\n",
    "    header_row_index = 15  # Headers are in row 15\n",
    "    # Use row 15 headers for columns A, B, C and month headers from row 15 for D onwards\n",
    "    headers = data[1][:3] + data[1][3:]  # Combine headers from row 15 for D onwards\n",
    "    start_data_row = 2     # Data starts from the row after headers (row 16)\n",
    "else:\n",
    "    header_row_index = 14  # Headers are in row 14\n",
    "    # Use row 15 headers for columns A, B, C and month headers from row 14 for D onwards\n",
    "    headers = data[1][:3] + data[0][3:]  # Use headers from row 15 for A, B, C, and row 14 for D onwards\n",
    "    start_data_row = 2     # Data starts from row 15\n",
    "\n",
    "# Extract the data from the relevant rows starting from row 15 (data rows)\n",
    "final_data = data[start_data_row:]\n",
    "\n",
    "# Create a DataFrame using pandas with the correct headers and data\n",
    "df = pd.DataFrame(final_data, columns=headers)\n",
    "\n",
    "# Output the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file if needed\n",
    "output_path = 'final_data.xlsx'  # Update the output path as needed\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc2a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/KS/data.xlsx None None None None None C:/Users/KS/final_output.xlsx None\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "class ExcelSheetSelector:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Excel Sheet Selector\")\n",
    "\n",
    "        # Custom labels for each file selection\n",
    "        self.custom_labels = [\n",
    "            \"Select OFile:\", \"Select CFile:\", \"Select DFile:\", \"Select Fourth File:\",\n",
    "            \"Select Fifth File:\", \"Select Sixth File:\", \"Select Seventh File:\", \"Select Eighth File:\"\n",
    "        ]\n",
    "\n",
    "        # List to hold selected file paths, initially None\n",
    "        self.selected_files = [None] * 8\n",
    "        self.labels = []\n",
    "\n",
    "        # Create custom labels and buttons for selecting files\n",
    "        for i in range(8):\n",
    "            # Create a custom label for each file selection\n",
    "            custom_label = tk.Label(root, text=self.custom_labels[i], width=20, anchor='w')\n",
    "            custom_label.grid(row=i, column=0, padx=10, pady=5)\n",
    "\n",
    "            # Create a label to display the selected file path\n",
    "            label = tk.Label(root, text=\"Not selected\", width=60, anchor='w')\n",
    "            label.grid(row=i, column=1, padx=10, pady=5)\n",
    "            self.labels.append(label)\n",
    "\n",
    "            # Create a button for each file selection\n",
    "            button = tk.Button(root, text=\"Browse\", command=lambda index=i: self.select_file(index))\n",
    "            button.grid(row=i, column=2, padx=10, pady=5)\n",
    "\n",
    "        # Button to confirm file selections\n",
    "        confirm_button = tk.Button(root, text=\"Confirm Selection\", command=self.confirm_selection)\n",
    "        confirm_button.grid(row=8, column=0, columnspan=3, pady=20)\n",
    "\n",
    "        # Predefined variable names for file paths\n",
    "        self.OFile = None\n",
    "        self.CFile = None\n",
    "        self.DFile = None\n",
    "        self.file4 = None\n",
    "        self.file5 = None\n",
    "        self.file6 = None\n",
    "        self.file7 = None\n",
    "        self.file8 = None\n",
    "\n",
    "    def select_file(self, index):\n",
    "        # Open file dialog to select a file\n",
    "        file_path = filedialog.askopenfilename(title=\"Select a File\", filetypes=[(\"All Files\", \"*.*\")])\n",
    "        \n",
    "        if file_path:  # If a file is selected\n",
    "            self.selected_files[index] = file_path  # Save the selected file\n",
    "            self.labels[index].config(text=file_path)  # Update label with the file path\n",
    "\n",
    "    def confirm_selection(self):\n",
    "        # Check how many files have been selected\n",
    "        num_selected = sum(1 for file in self.selected_files if file)\n",
    "\n",
    "        if num_selected == 0:\n",
    "            messagebox.showwarning(\"Warning\", \"No files selected.\")\n",
    "        else:\n",
    "            # Show confirmation dialog with options to Confirm or Select More Files\n",
    "            result = messagebox.askquestion(\n",
    "                \"Confirmation\", \n",
    "                f\"You have selected {num_selected} files. Do you want to proceed?\", \n",
    "                icon='question'\n",
    "            )\n",
    "            \n",
    "            if result == 'yes':\n",
    "                # Directly assign file paths to predefined variables\n",
    "                self.assign_file_paths()\n",
    "                messagebox.showinfo(\"Proceed\", \"Files are selected. Proceeding with the application.\")\n",
    "                # Print assigned files for verification\n",
    "                print(self.OFile, self.CFile, self.DFile, self.file4, self.file5, self.file6, self.file7, self.file8)\n",
    "                # Close the GUI\n",
    "                self.root.destroy()\n",
    "            else:\n",
    "                # Allow the user to select more files\n",
    "                messagebox.showinfo(\"Select More\", \"Please select more files.\")\n",
    "\n",
    "    def assign_file_paths(self):\n",
    "        \"\"\"Assigns selected file paths to predefined variables.\"\"\"\n",
    "        self.OFile = self.selected_files[0] if len(self.selected_files) > 0 else None\n",
    "        self.CFile = self.selected_files[1] if len(self.selected_files) > 1 else None\n",
    "        self.DFile = self.selected_files[2] if len(self.selected_files) > 2 else None\n",
    "        self.file4 = self.selected_files[3] if len(self.selected_files) > 3 else None\n",
    "        self.file5 = self.selected_files[4] if len(self.selected_files) > 4 else None\n",
    "        self.file6 = self.selected_files[5] if len(self.selected_files) > 5 else None\n",
    "        self.file7 = self.selected_files[6] if len(self.selected_files) > 6 else None\n",
    "        self.file8 = self.selected_files[7] if len(self.selected_files) > 7 else None\n",
    "\n",
    "# Initialize the Tkinter window and ExcelSheetSelector class\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ExcelSheetSelector(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36d374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "def select_file(index):\n",
    "    # Open file dialog to select a file\n",
    "    file_path = filedialog.askopenfilename(title=\"Select a File\", filetypes=[(\"All Files\", \"*.*\")])\n",
    "    \n",
    "    if file_path:  # If a file is selected\n",
    "        selected_files[index] = file_path  # Save the selected file\n",
    "        labels[index].config(text=file_path)  # Update label with the file path\n",
    "\n",
    "def confirm_selection():\n",
    "    # Check how many files have been selected\n",
    "    num_selected = sum(1 for file in selected_files if file)\n",
    "    \n",
    "    if num_selected == 0:\n",
    "        messagebox.showwarning(\"Warning\", \"No files selected.\")\n",
    "    else:\n",
    "        # Show confirmation dialog with options to Confirm or Select More Files\n",
    "        result = messagebox.askquestion(\"Confirmation\", f\"You have selected {num_selected} files. Do you want to proceed?\", icon='question')\n",
    "        \n",
    "        if result == 'yes':\n",
    "            # Proceed and close the application\n",
    "            messagebox.showinfo(\"Proceed\", \"Files are selected. Proceeding with the application.\")\n",
    "            root.destroy()\n",
    "        else:\n",
    "            # Allow the user to select more files\n",
    "            messagebox.showinfo(\"Select More\", \"Please select more files.\")\n",
    "\n",
    "# Initialize the Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"File Selector\")\n",
    "\n",
    "# List to hold selected file paths\n",
    "selected_files = [None] * 8\n",
    "labels = []\n",
    "\n",
    "# Create labels and buttons for selecting files\n",
    "for i in range(8):\n",
    "    # Create a label for each file selection\n",
    "    label = tk.Label(root, text=f\"File {i+1}: Not selected\", width=100, anchor='w')\n",
    "    label.grid(row=i, column=0, padx=10, pady=5)\n",
    "    labels.append(label)\n",
    "    \n",
    "    # Create a button for each file selection\n",
    "    button = tk.Button(root, text=\"Select File\", command=lambda index=i: select_file(index))\n",
    "    button.grid(row=i, column=1, padx=10, pady=5)\n",
    "\n",
    "# Button to confirm file selections\n",
    "confirm_button = tk.Button(root, text=\"Confirm Selection\", command=confirm_selection)\n",
    "confirm_button.grid(row=8, column=0, columnspan=2, pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "def select_files():\n",
    "    # Open the file dialog to select files\n",
    "    file_paths = filedialog.askopenfilenames(title=\"Select Files\", filetypes=[(\"All Files\", \"*.*\")])\n",
    "    \n",
    "    # Update the listbox with selected files\n",
    "    listbox.delete(0, tk.END)\n",
    "    for file in file_paths:\n",
    "        listbox.insert(tk.END, file)\n",
    "    \n",
    "    # Save the selected files to the global variable\n",
    "    selected_files.clear()\n",
    "    selected_files.extend(file_paths)\n",
    "    \n",
    "    # Confirm the number of selected files\n",
    "    if len(selected_files) == 0:\n",
    "        messagebox.showinfo(\"Information\", \"No files selected.\")\n",
    "    else:\n",
    "        messagebox.showinfo(\"Information\", f\"You have selected {len(selected_files)} files.\")\n",
    "\n",
    "def confirm_selection():\n",
    "    # Proceed with the application logic\n",
    "    if len(selected_files) > 0:\n",
    "        messagebox.showinfo(\"Proceed\", \"Files are selected. Proceeding with the application.\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"No files selected. Proceeding with the application.\")\n",
    "\n",
    "# Initialize the Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"File Selector\")\n",
    "\n",
    "selected_files = []\n",
    "\n",
    "# Create a Listbox to display selected files\n",
    "listbox = tk.Listbox(root, width=100, height=10)\n",
    "listbox.pack(pady=10)\n",
    "\n",
    "# Add buttons to select files and confirm selection\n",
    "select_button = tk.Button(root, text=\"Select Files\", command=select_files)\n",
    "select_button.pack(pady=5)\n",
    "\n",
    "confirm_button = tk.Button(root, text=\"Confirm Selection\", command=confirm_selection)\n",
    "confirm_button.pack(pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41a6afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Staff ID Position Changed                            Control Items  \\\n",
      "0       101             Left                              EUC 1 Name1   \n",
      "1       102        No Change  EUC 2 Name2\\nEUC 3 Name3\\nOther 4 Name4   \n",
      "2       102              Yes  EUC 2 Name2\\nEUC 3 Name3\\nOther 4 Name4   \n",
      "3       102             Left  EUC 2 Name2\\nEUC 3 Name3\\nOther 4 Name4   \n",
      "4       103        No Change                              EUC 5 Name5   \n",
      "\n",
      "  Control Domain  \n",
      "0       EUC only  \n",
      "1            mix  \n",
      "2            mix  \n",
      "3            mix  \n",
      "4       EUC only  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Record Type': ['EUC', 'EUC', 'EUC', 'Other', 'EUC'],\n",
    "    'Record ID': [1, 2, 3, 4, 5],\n",
    "    'Record Name': ['Name1', 'Name2', 'Name3', 'Name4', 'Name5'],\n",
    "    'Staff ID': [101, 102, 102, 102, 103],\n",
    "    'Position Changed': ['Left', 'No Change', 'Yes', 'Left', 'No Change']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to concatenate control items and determine control domain\n",
    "def concatenate_control_items(group):\n",
    "    control_items = '\\n'.join(group['Record Type'] + ' ' + group['Record ID'].astype(str) + ' ' + group['Record Name'])\n",
    "    record_types = group['Record Type'].unique()\n",
    "    if len(record_types) > 1:\n",
    "        control_domain = 'mix'\n",
    "    elif 'EUC' in record_types:\n",
    "        control_domain = 'EUC only'\n",
    "    else:\n",
    "        control_domain = 'Other'\n",
    "    return pd.Series({\n",
    "        'Control Items': control_items,\n",
    "        'Control Domain': control_domain\n",
    "    })\n",
    "\n",
    "# Group by 'Staff ID' and apply the function\n",
    "result_df = df.groupby('Staff ID').apply(concatenate_control_items).reset_index()\n",
    "\n",
    "# Merge the result back to the original DataFrame to maintain original rows\n",
    "final_df = df.drop(columns=['Record Type', 'Record ID', 'Record Name']).drop_duplicates().merge(result_df, on='Staff ID', how='left')\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(final_df)\n",
    "\n",
    "# Save the result to an Excel file if needed\n",
    "final_df.to_excel('final_output.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818cefda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humans file: C:/Users/KS/Start-Data-Analysis.xlsx\n",
      "Animals file: C:/Users/KS/Source.xlsx\n",
      "Plants file: C:/Users/KS/sample.xlsx\n",
      "Minerals file: C:/Users/KS/sam.xlsx\n",
      "Microbes file: C:/Users/KS/sf2_output.xlsx\n",
      "Fungi file: C:/Users/KS/modified_workbook1.xlsx\n",
      "Algae file: C:/Users/KS/modified_workbook.xlsx\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "class ExcelSheetSelector:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Excel Sheet Selector\")\n",
    "\n",
    "        self.file_paths = [None] * 7\n",
    "        self.labels = []\n",
    "\n",
    "        # Specific labels for each file selection\n",
    "        self.label_texts = [\n",
    "            \"Select Humans file:\",\n",
    "            \"Select Animals file:\",\n",
    "            \"Select Plants file:\",\n",
    "            \"Select Minerals file:\",\n",
    "            \"Select Microbes file:\",\n",
    "            \"Select Fungi file:\",\n",
    "            \"Select Algae file:\"\n",
    "        ]\n",
    "\n",
    "        # Create labels and buttons for 7 Excel sheets\n",
    "        for i in range(7):\n",
    "            label = tk.Label(root, text=self.label_texts[i])\n",
    "            label.grid(row=i, column=0, padx=10, pady=5)\n",
    "            \n",
    "            button = tk.Button(root, text=\"Browse\", command=lambda i=i: self.select_file(i))\n",
    "            button.grid(row=i, column=1, padx=10, pady=5)\n",
    "            \n",
    "            file_label = tk.Label(root, text=\"No file selected\")\n",
    "            file_label.grid(row=i, column=2, padx=10, pady=5)\n",
    "            self.labels.append(file_label)\n",
    "        \n",
    "        # Button to check and print selected file paths\n",
    "        self.print_button = tk.Button(root, text=\"Confirm Selections\", command=self.check_and_confirm)\n",
    "        self.print_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def select_file(self, index):\n",
    "        self.root.withdraw()  # Hide the main window\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Excel files\", \"*.xlsx *.xls\")])\n",
    "        self.root.deiconify()  # Show the main window again\n",
    "        if file_path:\n",
    "            self.file_paths[index] = file_path\n",
    "            self.labels[index].config(text=file_path)\n",
    "\n",
    "    def check_and_confirm(self):\n",
    "        if all(self.file_paths):\n",
    "            self.root.destroy()  # Close the window gracefully\n",
    "        else:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select all files before proceeding.\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "app = ExcelSheetSelector(root)\n",
    "root.mainloop()\n",
    "\n",
    "# After closing the window, capture the file paths into separate variables\n",
    "humans_file, animals_file, plants_file, minerals_file, microbes_file, fungi_file, algae_file = app.file_paths\n",
    "\n",
    "# Print the captured file paths (for verification)\n",
    "print(f\"Humans file: {humans_file}\")\n",
    "print(f\"Animals file: {animals_file}\")\n",
    "print(f\"Plants file: {plants_file}\")\n",
    "print(f\"Minerals file: {minerals_file}\")\n",
    "print(f\"Microbes file: {microbes_file}\")\n",
    "print(f\"Fungi file: {fungi_file}\")\n",
    "print(f\"Algae file: {algae_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32917012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Staff ID                          Control Items Position Changed  \\\n",
      "0         1  Issue 101 A\\nIssue 102 B\\nIssue 104 D              Yes   \n",
      "1         2             Action 103 C\\nAction 105 E              Yes   \n",
      "\n",
      "              Record Details  \n",
      "0  Detail1\\nDetail2\\nDetail4  \n",
      "1           Detail3\\nDetail5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data creation for demonstration\n",
    "data = {\n",
    "    'Record Type': ['Issue', 'Issue', 'Action', 'Issue', 'Action'],\n",
    "    'Record ID': [101, 102, 103, 104, 105],\n",
    "    'Record Name': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Record Details': ['Detail1', 'Detail2', 'Detail3', 'Detail4', 'Detail5'],\n",
    "    'Staff ID': [1, 1, 2, 1, 2],\n",
    "    'Position Changed': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to concatenate the desired fields\n",
    "def concatenate_records(group):\n",
    "    return '\\n'.join(group['Record Type'] + ' ' + group['Record ID'].astype(str) + ' ' + group['Record Name'])\n",
    "\n",
    "# Group by 'Staff ID' and apply the concatenation function\n",
    "grouped_df = df.groupby('Staff ID').apply(lambda x: pd.Series({\n",
    "    'Control Items': concatenate_records(x),\n",
    "    'Position Changed': x['Position Changed'].iloc[0]  # Assuming you want to keep the first 'Position Changed' value\n",
    "})).reset_index()\n",
    "\n",
    "# Optional: Include any other columns you want to keep from the original DataFrame\n",
    "# For demonstration, I'm adding 'Record Details' concatenated in the same way\n",
    "grouped_df['Record Details'] = df.groupby('Staff ID')['Record Details'].apply(lambda x: '\\n'.join(x)).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(grouped_df)\n",
    "\n",
    "# Save the final DataFrame to an Excel file\n",
    "# grouped_df.to_excel('path_to_output_file.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ab357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lookup_and_merge(file1_path, file2_path, vOld_path):\n",
    "    # Read the first file into a DataFrame\n",
    "    df1 = pd.read_excel(file1_path)\n",
    "    \n",
    "    # Read the second file into a DataFrame\n",
    "    df2 = pd.read_excel(file2_path)\n",
    "    \n",
    "    # Read the vOld file into a DataFrame\n",
    "    vOld = pd.read_excel(vOld_path)\n",
    "    \n",
    "    # Ensure the Staff ID in both DataFrames are treated as numeric for accurate matching\n",
    "    df1['Employee ID'] = pd.to_numeric(df1['Employee ID'], errors='coerce').astype('Int64')\n",
    "    df2['Staff ID'] = pd.to_numeric(df2['Staff ID'], errors='coerce').astype('Int64')\n",
    "    vOld['Staff ID'] = pd.to_numeric(vOld['Staff ID'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    # Perform the lookup by merging the DataFrames on Staff ID and Employee ID\n",
    "    merged_df = df2.merge(df1[['Employee ID', 'Position Changed']], \n",
    "                          left_on='Staff ID', right_on='Employee ID', \n",
    "                          how='left')\n",
    "    \n",
    "    # Drop the redundant 'Employee ID' column from the merged DataFrame\n",
    "    merged_df.drop(columns=['Employee ID'], inplace=True)\n",
    "    \n",
    "    # Filter the DataFrame to retain only rows where 'Position Changed' is 'Left' or 'Yes'\n",
    "    filtered_df = merged_df[merged_df['Position Changed'].isin(['Left', 'Yes'])]\n",
    "    \n",
    "    # Ensure 'Staff ID' and 'Position Changed' columns are filled properly\n",
    "    filtered_df['Staff ID'] = filtered_df['Staff ID'].fillna('No ID')\n",
    "    filtered_df['Position Changed'] = filtered_df['Position Changed'].fillna('No Change')\n",
    "    \n",
    "    # Perform the second lookup by merging the filtered_df with vOld on Staff ID\n",
    "    final_df = filtered_df.merge(vOld[['Staff ID', 'Employee Name', 'Employee Business Email Address', 'Global Career Band']], \n",
    "                                 on='Staff ID', \n",
    "                                 how='left')\n",
    "    \n",
    "    # Rename the fetched columns\n",
    "    final_df.rename(columns={\n",
    "        'Employee Name': 'Functional Manager Employee Name',\n",
    "        'Employee Business Email Address': 'Functional Manager Email',\n",
    "        'Global Career Band': 'Functional Manager GCB'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Return the final DataFrame\n",
    "    return final_df\n",
    "\n",
    "# Paths to the Excel files\n",
    "file1_path = 'path_to_file1.xlsx'  # File with Employee ID, Position Changed, etc.\n",
    "file2_path = 'path_to_file2.xlsx'  # File with Record ID, Record Name, Record Details, Staff ID\n",
    "vOld_path = 'path_to_vOld.xlsx'    # File with additional details based on Staff ID\n",
    "\n",
    "# Perform the lookup, merge, and filter\n",
    "final_df = lookup_and_merge(file1_path, file2_path, vOld_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n",
    "\n",
    "# Save the final DataFrame to a new Excel file\n",
    "final_df.to_excel('path_to_output_file.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lookup_and_merge(file1_path, file2_path):\n",
    "    # Read the first file into a DataFrame\n",
    "    df1 = pd.read_excel(file1_path)\n",
    "    \n",
    "    # Read the second file into a DataFrame\n",
    "    df2 = pd.read_excel(file2_path)\n",
    "    \n",
    "    # Ensure the Staff ID in both DataFrames are strings for accurate matching\n",
    "    df1['Employee ID'] = df1['Employee ID'].astype(str)\n",
    "    df2['Staff ID'] = df2['Staff ID'].astype(str)\n",
    "    \n",
    "    # Perform the lookup by merging the DataFrames on Staff ID and Employee ID\n",
    "    merged_df = df2.merge(df1[['Employee ID', 'Position Changed']], \n",
    "                          left_on='Staff ID', right_on='Employee ID', \n",
    "                          how='left')\n",
    "    \n",
    "    # Drop the redundant 'Employee ID' column from the merged DataFrame\n",
    "    merged_df.drop(columns=['Employee ID'], inplace=True)\n",
    "    \n",
    "    # Return the merged DataFrame\n",
    "    return merged_df\n",
    "\n",
    "# Paths to the Excel files\n",
    "file1_path = 'path_to_file1.xlsx'  # File with Employee ID, Position Changed, etc.\n",
    "file2_path = 'path_to_file2.xlsx'  # File with Record ID, Record Name, Record Details, Staff ID\n",
    "\n",
    "# Perform the lookup and merge\n",
    "final_df = lookup_and_merge(file1_path, file2_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n",
    "\n",
    "# If needed, save the final DataFrame to a new Excel file\n",
    "# final_df.to_excel('path_to_output_file.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e82670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_files(vnew_path, vold_path):\n",
    "    # Read the Excel files into DataFrames\n",
    "    vNew = pd.read_excel(vnew_path)\n",
    "    vOld = pd.read_excel(vold_path)\n",
    "    \n",
    "    # Check and print initial dtypes of columns\n",
    "    print(\"Initial dtypes of vNew:\")\n",
    "    print(vNew.dtypes)\n",
    "    print(\"\\nInitial dtypes of vOld:\")\n",
    "    print(vOld.dtypes)\n",
    "    \n",
    "    # Function to convert columns to int, skipping invalid rows\n",
    "    def convert_to_int(df, column):\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "        df.dropna(subset=[column], inplace=True)\n",
    "        df[column] = df[column].astype(int)\n",
    "        return df\n",
    "\n",
    "    # Convert 'Employee ID' and 'Position Number' to integers\n",
    "    vNew = convert_to_int(vNew, 'Employee ID')\n",
    "    vNew = convert_to_int(vNew, 'Position Number')\n",
    "    vOld = convert_to_int(vOld, 'Employee ID')\n",
    "    vOld = convert_to_int(vOld, 'Position Number')\n",
    "    \n",
    "    # Check and print dtypes of columns after coercion attempt\n",
    "    print(\"\\nDtypes of vNew after coercion attempt:\")\n",
    "    print(vNew.dtypes)\n",
    "    print(\"\\nDtypes of vOld after coercion attempt:\")\n",
    "    print(vOld.dtypes)\n",
    "    \n",
    "    # Select necessary columns from vNew\n",
    "    vNew_selected = vNew[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vNew_selected.rename(columns={\n",
    "        'Position Number': 'new Position Number',\n",
    "        'BF Level 4': 'new BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select necessary columns from vOld\n",
    "    vOld_selected = vOld[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vOld_selected.rename(columns={\n",
    "        'Position Number': 'old Position Number',\n",
    "        'BF Level 4': 'old BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Merge the DataFrames on Employee ID using left join\n",
    "    merged_df = pd.merge(vOld_selected, vNew_selected, on='Employee ID', how='left')\n",
    "    \n",
    "    # Create the Position Changed column based on the specified conditions\n",
    "    def determine_position_changed(row):\n",
    "        if pd.isna(row['new Position Number']) and pd.isna(row['new BF Level 4']):\n",
    "            return 'Left'\n",
    "        elif (row['old Position Number'] != row['new Position Number']) or (row['old BF Level 4'] != row['new BF Level 4']):\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No Change'\n",
    "    \n",
    "    merged_df['Position Changed'] = merged_df.apply(determine_position_changed, axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "vnew_path = 'path_to_vNew.xlsx'\n",
    "vold_path = 'path_to_vOld.xlsx'\n",
    "\n",
    "final_df = process_files(vnew_path, vold_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c5123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_files(vnew_path, vold_path):\n",
    "    # Read the Excel files into DataFrames\n",
    "    vNew = pd.read_excel(vnew_path)\n",
    "    vOld = pd.read_excel(vold_path)\n",
    "    \n",
    "    # Select necessary columns from vNew\n",
    "    vNew_selected = vNew[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vNew_selected.rename(columns={\n",
    "        'Position Number': 'new Position Number',\n",
    "        'BF Level 4': 'new BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select necessary columns from vOld\n",
    "    vOld_selected = vOld[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vOld_selected.rename(columns={\n",
    "        'Position Number': 'old Position Number',\n",
    "        'BF Level 4': 'old BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Merge the DataFrames on Employee ID using left join\n",
    "    merged_df = pd.merge(vOld_selected, vNew_selected, on='Employee ID', how='left')\n",
    "    \n",
    "    # Create the Position Changed column based on the specified conditions\n",
    "    def determine_position_changed(row):\n",
    "        if pd.isna(row['new Position Number']) and pd.isna(row['new BF Level 4']):\n",
    "            return 'Left'\n",
    "        elif (row['old Position Number'] != row['new Position Number']) or (row['old BF Level 4'] != row['new BF Level 4']):\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No Change'\n",
    "    \n",
    "    merged_df['Position Changed'] = merged_df.apply(determine_position_changed, axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "vnew_path = 'path_to_vNew.xlsx'\n",
    "vold_path = 'path_to_vOld.xlsx'\n",
    "\n",
    "final_df = process_files(vnew_path, vold_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_files(vnew_path, vold_path):\n",
    "    # Read the Excel files into DataFrames\n",
    "    vNew = pd.read_excel(vnew_path)\n",
    "    vOld = pd.read_excel(vold_path)\n",
    "    \n",
    "    # Select necessary columns from vNew\n",
    "    vNew_selected = vNew[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vNew_selected.rename(columns={\n",
    "        'Position Number': 'new Position Number',\n",
    "        'BF Level 4': 'new BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select necessary columns from vOld\n",
    "    vOld_selected = vOld[['Employee ID', 'Position Number', 'BF Level 4']].copy()\n",
    "    vOld_selected.rename(columns={\n",
    "        'Position Number': 'old Position Number',\n",
    "        'BF Level 4': 'old BF Level 4'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Merge the DataFrames on Employee ID\n",
    "    merged_df = pd.merge(vOld_selected, vNew_selected, on='Employee ID', how='outer')\n",
    "    \n",
    "    # Create the Position Changed column based on the specified conditions\n",
    "    def determine_position_changed(row):\n",
    "        if pd.isna(row['new Position Number']) and pd.isna(row['new BF Level 4']):\n",
    "            return 'Left'\n",
    "        elif (row['old Position Number'] != row['new Position Number']) or (row['old BF Level 4'] != row['new BF Level 4']):\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No Change'\n",
    "    \n",
    "    merged_df['Position Changed'] = merged_df.apply(determine_position_changed, axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "vnew_path = 'path_to_vNew.xlsx'\n",
    "vold_path = 'path_to_vOld.xlsx'\n",
    "\n",
    "final_df = process_files(vnew_path, vold_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96028352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_staff_id(action_owner_col):\n",
    "    \"\"\"Extract Staff ID from the given column using regex.\"\"\"\n",
    "    if isinstance(action_owner_col, str):\n",
    "        match = re.search(r'\\((\\d{8})\\)', action_owner_col)\n",
    "        return match.group(1) if match else None\n",
    "    return None\n",
    "\n",
    "def process_single_file(file_path, staff_id_col, issue_status_col, filter_condition,\n",
    "                        record_id_col, record_name_col, record_details_col, record_type_value):\n",
    "    \"\"\"\n",
    "    Process a single file to extract relevant data and transform it into a standardized format.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the input Excel file.\n",
    "        staff_id_col (str): Column name for the Staff ID extraction.\n",
    "        issue_status_col (str): Column name for filtering records.\n",
    "        filter_condition (str): Value to filter the records (e.g., 'open').\n",
    "        record_id_col (str): Column name for 'Record ID'.\n",
    "        record_name_col (str): Column name for 'Record Name'.\n",
    "        record_details_col (str): Column name for 'Record Details'.\n",
    "        record_type_value (str): Value to be placed in 'Record Type' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with standardized columns.\n",
    "    \"\"\"\n",
    "    # Load the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Ensure the staff ID column is treated as string\n",
    "    df[staff_id_col] = df[staff_id_col].astype(str)\n",
    "    \n",
    "    # Filter the DataFrame based on the provided condition\n",
    "    filtered_df = df[df[issue_status_col] == filter_condition]\n",
    "    \n",
    "    # Extract Staff ID from the specified column\n",
    "    filtered_df['Staff ID'] = filtered_df[staff_id_col].apply(extract_staff_id)\n",
    "    \n",
    "    # Add the 'Record Type' column with the specified value\n",
    "    filtered_df['Record Type'] = record_type_value\n",
    "    \n",
    "    # Create the final DataFrame with the required columns\n",
    "    result_df = filtered_df[[record_id_col, record_name_col, record_details_col]].copy()\n",
    "    result_df.rename(columns={\n",
    "        record_id_col: 'Record ID',\n",
    "        record_name_col: 'Record Name',\n",
    "        record_details_col: 'Record Details'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add 'Staff ID' and 'Record Type' columns\n",
    "    result_df['Staff ID'] = filtered_df['Staff ID']\n",
    "    result_df['Record Type'] = filtered_df['Record Type']\n",
    "    \n",
    "    # Return the result DataFrame\n",
    "    return result_df\n",
    "\n",
    "def concatenate_files(file_params_list):\n",
    "    \"\"\"\n",
    "    Process multiple files and concatenate the results into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        file_params_list (list of dict): List of dictionaries with parameters for each file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame with results from all files.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    \n",
    "    for params in file_params_list:\n",
    "        df = process_single_file(\n",
    "            file_path=params['file_path'],\n",
    "            staff_id_col=params['staff_id_col'],\n",
    "            issue_status_col=params['issue_status_col'],\n",
    "            filter_condition=params['filter_condition'],\n",
    "            record_id_col=params['record_id_col'],\n",
    "            record_name_col=params['record_name_col'],\n",
    "            record_details_col=params['record_details_col'],\n",
    "            record_type_value=params['record_type_value']\n",
    "        )\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Example usage\n",
    "file_params_list = [\n",
    "    {\n",
    "        'file_path': 'path_to_file1.xlsx',\n",
    "        'staff_id_col': 'Action Owner',\n",
    "        'issue_status_col': 'Issue Status',\n",
    "        'filter_condition': 'open',\n",
    "        'record_id_col': 'Issue ID',\n",
    "        'record_name_col': 'Issue Title',\n",
    "        'record_details_col': 'Issue Description',\n",
    "        'record_type_value': 'Issue'\n",
    "    },\n",
    "    {\n",
    "        'file_path': 'path_to_file2.xlsx',\n",
    "        'staff_id_col': 'Owner',\n",
    "        'issue_status_col': 'Status',\n",
    "        'filter_condition': 'open',\n",
    "        'record_id_col': 'ID',\n",
    "        'record_name_col': 'Title',\n",
    "        'record_details_col': 'Description',\n",
    "        'record_type_value': 'Action Owner'\n",
    "    },\n",
    "    # Add parameters for other files here\n",
    "]\n",
    "\n",
    "# Process multiple files and get the final DataFrame\n",
    "final_df = concatenate_files(file_params_list)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_staff_id(action_owner_col):\n",
    "    \"\"\"Extract Staff ID from the given column using regex.\"\"\"\n",
    "    if isinstance(action_owner_col, str):\n",
    "        match = re.search(r'\\((\\d{8})\\)', action_owner_col)\n",
    "        return match.group(1) if match else None\n",
    "    return None\n",
    "\n",
    "def process_file(file_path, staff_id_col, issue_status_col, filter_condition,\n",
    "                 record_id_col, record_name_col, record_details_col):\n",
    "    \"\"\"\n",
    "    Process a single file to extract relevant data and transform it into a standardized format.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the input Excel file.\n",
    "        staff_id_col (str): Column name for the Staff ID extraction.\n",
    "        issue_status_col (str): Column name for filtering records.\n",
    "        filter_condition (str): Value to filter the records (e.g., 'open').\n",
    "        record_id_col (str): Column name for 'Record ID'.\n",
    "        record_name_col (str): Column name for 'Record Name'.\n",
    "        record_details_col (str): Column name for 'Record Details'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with standardized columns.\n",
    "    \"\"\"\n",
    "    # Load the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Ensure the staff ID column is treated as string\n",
    "    df[staff_id_col] = df[staff_id_col].astype(str)\n",
    "    \n",
    "    # Filter the DataFrame based on the provided condition\n",
    "    filtered_df = df[df[issue_status_col] == filter_condition]\n",
    "    \n",
    "    # Extract Staff ID from the specified column\n",
    "    filtered_df['Staff ID'] = filtered_df[staff_id_col].apply(extract_staff_id)\n",
    "    \n",
    "    # Add the 'Record Type' column with the value 'Issue'\n",
    "    filtered_df['Record Type'] = 'Issue'\n",
    "    \n",
    "    # Create the final DataFrame with the required columns\n",
    "    result_df = filtered_df[[staff_id_col, record_id_col, record_name_col, record_details_col]].copy()\n",
    "    result_df.rename(columns={\n",
    "        staff_id_col: 'Staff ID',\n",
    "        record_id_col: 'Record ID',\n",
    "        record_name_col: 'Record Name',\n",
    "        record_details_col: 'Record Details'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add the 'Record Type' column\n",
    "    result_df['Record Type'] = 'Issue'\n",
    "    \n",
    "    # Return the result DataFrame\n",
    "    return result_df\n",
    "\n",
    "def process_multiple_files(file_paths, column_mapping, filter_condition):\n",
    "    \"\"\"\n",
    "    Process multiple files and concatenate the results into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list of str): List of paths to input Excel files.\n",
    "        column_mapping (list of dict): List of dictionaries with column mappings for each file.\n",
    "        filter_condition (str): Value to filter records (e.g., 'open').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame with results from all files.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    \n",
    "    for file_path, columns in zip(file_paths, column_mapping):\n",
    "        df = process_file(\n",
    "            file_path,\n",
    "            staff_id_col=columns['staff_id'],\n",
    "            issue_status_col=columns['issue_status'],\n",
    "            filter_condition=filter_condition,\n",
    "            record_id_col=columns['record_id'],\n",
    "            record_name_col=columns['record_name'],\n",
    "            record_details_col=columns['record_details']\n",
    "        )\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Example usage\n",
    "file_paths = [\n",
    "    'path_to_file1.xlsx',\n",
    "    'path_to_file2.xlsx',\n",
    "    'path_to_file3.xlsx',\n",
    "    'path_to_file4.xlsx',\n",
    "    'path_to_file5.xlsx'\n",
    "]\n",
    "\n",
    "column_mapping = [\n",
    "    {\n",
    "        'staff_id': 'Action Owner',  # Column name to extract Staff ID\n",
    "        'issue_status': 'Issue Status',  # Column name for issue status\n",
    "        'record_id': 'Issue ID',  # Column name for Record ID\n",
    "        'record_name': 'Issue Title',  # Column name for Record Name\n",
    "        'record_details': 'Issue Description'  # Column name for Record Details\n",
    "    },\n",
    "    # Add mappings for other files here\n",
    "]\n",
    "\n",
    "filter_condition = 'open'  # Condition to filter records\n",
    "\n",
    "# Process multiple files and get the final DataFrame\n",
    "final_df = process_multiple_files(file_paths, column_mapping, filter_condition)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract Staff ID using regular expression\n",
    "def extract_staff_id(action_owner):\n",
    "    if isinstance(action_owner, str):\n",
    "        match = re.search(r'\\((\\d{8})\\)', action_owner)\n",
    "        return match.group(1) if match else None\n",
    "    return None\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('path_to_your_file.xlsx')\n",
    "\n",
    "# Ensure \"Action Owner\" column is treated as string\n",
    "df['Action Owner'] = df['Action Owner'].astype(str)\n",
    "\n",
    "# Filter the DataFrame for rows where 'Issue Status' is 'open'\n",
    "open_issues_df = df[df['Issue Status'] == 'open']\n",
    "\n",
    "# Extract Staff ID from \"Action Owner\" column for filtered rows\n",
    "open_issues_df['Staff ID'] = open_issues_df['Action Owner'].apply(extract_staff_id)\n",
    "\n",
    "# Add the 'Record Type' column with value 'Issue'\n",
    "open_issues_df['Record Type'] = 'Issue'\n",
    "\n",
    "# Create the final DataFrame with the required columns\n",
    "result_df = open_issues_df[['Staff ID', 'Record Type', 'Issue ID', 'Issue Title', 'Issue Description']]\n",
    "result_df.rename(columns={\n",
    "    'Issue ID': 'Record ID',\n",
    "    'Issue Title': 'Record Name',\n",
    "    'Issue Description': 'Record Details'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel files into DataFrames\n",
    "vNew = pd.read_excel('path_to_vNew.xlsx')\n",
    "vOld = pd.read_excel('path_to_vOld.xlsx')\n",
    "\n",
    "# Select relevant columns from vNew and vOld\n",
    "vNew = vNew[['Employee ID', 'Position Number', 'Level4']]\n",
    "vOld = vOld[['Employee ID', 'Position Number', 'Level4']]\n",
    "\n",
    "# Merge vNew and vOld on Employee ID\n",
    "merged_df = pd.merge(vNew, vOld, on='Employee ID', suffixes=('_new', '_old'), how='left')\n",
    "\n",
    "# Rename columns to match the required format\n",
    "merged_df.rename(columns={\n",
    "    'Position Number_new': 'new Position Number',\n",
    "    'Level4_new': 'new Level4',\n",
    "    'Position Number_old': 'old Position Number',\n",
    "    'Level4_old': 'old Level4'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create the \"Position Changed\" column\n",
    "merged_df['Position Changed'] = merged_df.apply(\n",
    "    lambda row: 'New' if pd.isna(row['old Position Number']) or pd.isna(row['old Level4']) else 'No Change', axis=1)\n",
    "\n",
    "# Fetch records from vOld where Employee ID is not in vNew\n",
    "not_in_vNew = vOld[~vOld['Employee ID'].isin(vNew['Employee ID'])]\n",
    "\n",
    "# Rename columns to match the format of merged_df\n",
    "not_in_vNew.rename(columns={\n",
    "    'Position Number': 'old Position Number',\n",
    "    'Level4': 'old Level4'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add new columns with default values for records not in vNew\n",
    "not_in_vNew['new Position Number'] = None\n",
    "not_in_vNew['new Level4'] = None\n",
    "not_in_vNew['Position Changed'] = 'Left'\n",
    "\n",
    "# Reorder columns to match the merged_df structure\n",
    "not_in_vNew = not_in_vNew[['Employee ID', 'new Position Number', 'new Level4', 'old Position Number', 'old Level4', 'Position Changed']]\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "final_df = pd.concat([merged_df, not_in_vNew], ignore_index=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n",
    "\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel files into DataFrames\n",
    "vNew = pd.read_excel('path_to_vNew.xlsx')\n",
    "vOld = pd.read_excel('path_to_vOld.xlsx')\n",
    "\n",
    "# Select relevant columns from vNew and vOld\n",
    "vNew = vNew[['Employee ID', 'Position Number', 'Level4']]\n",
    "vOld = vOld[['Employee ID', 'Position Number', 'Level4']]\n",
    "\n",
    "# Merge vNew and vOld on Employee ID\n",
    "merged_df = pd.merge(vNew, vOld, on='Employee ID', suffixes=('_new', '_old'), how='left')\n",
    "\n",
    "# Rename columns to match the required format\n",
    "merged_df.rename(columns={'Position Number_new': 'new Position Number',\n",
    "                          'Level4_new': 'new Level4',\n",
    "                          'Position Number_old': 'old Position Number',\n",
    "                          'Level4_old': 'old Level4'}, inplace=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a346553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel files into DataFrames\n",
    "vNew = pd.read_excel('path_to_vNew.xlsx')\n",
    "vOld = pd.read_excel('path_to_vOld.xlsx')\n",
    "\n",
    "# Ensure column names are properly stripped of leading/trailing spaces\n",
    "vNew.columns = vNew.columns.str.strip()\n",
    "vOld.columns = vOld.columns.str.strip()\n",
    "\n",
    "# Initialize new columns in vOld with default value 'left'\n",
    "vOld['Pos Check'] = 'left'\n",
    "vOld['BF4 Check'] = 'left'\n",
    "vOld['Country Check'] = 'left'\n",
    "\n",
    "# Perform the lookup and update the values for matching Employee Ids\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Pos Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['Position Number'])\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'BF4 Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['BF Level 4 Name'])\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Country Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['Work Location Country/Territory Name'])\n",
    "\n",
    "# Create the 'In Scope' column\n",
    "vOld['In Scope'] = ((vOld['Pos Check'] != vOld['Position Number']) | \n",
    "                    (vOld['BF4 Check'] != vOld['BF Level 4 Name']) | \n",
    "                    (vOld['Country Check'] != vOld['Work Location Country/Territory Name'])).apply(lambda x: 'Movement' if x else 'No Movement')\n",
    "\n",
    "# Create 'Position Changed', 'BF Changed', and 'Country Changed' columns\n",
    "vOld['Position Changed'] = vOld.apply(lambda row: 'Left' if row['Pos Check'] == 'left' else ('Yes' if row['Pos Check'] != row['Position Number'] else 'No'), axis=1)\n",
    "vOld['BF Changed'] = vOld.apply(lambda row: 'Left' if row['BF4 Check'] == 'left' else ('Yes' if row['BF4 Check'] != row['BF Level 4 Name'] else 'No'), axis=1)\n",
    "vOld['Country Changed'] = vOld.apply(lambda row: 'Left' if row['Country Check'] == 'left' else ('Yes' if row['Country Check'] != row['Work Location Country/Territory Name'] else 'No'), axis=1)\n",
    "\n",
    "# Display the updated vOld DataFrame\n",
    "print(vOld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc18cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel files into DataFrames\n",
    "vNew = pd.read_excel('path_to_vNew.xlsx')\n",
    "vOld = pd.read_excel('path_to_vOld.xlsx')\n",
    "\n",
    "# Ensure column names are properly stripped of leading/trailing spaces\n",
    "vNew.columns = vNew.columns.str.strip()\n",
    "vOld.columns = vOld.columns.str.strip()\n",
    "\n",
    "# Initialize new columns in vOld with default value 'left'\n",
    "vOld['Pos Check'] = 'left'\n",
    "vOld['BF4 Check'] = 'left'\n",
    "vOld['Country Check'] = 'left'\n",
    "\n",
    "# Perform the lookup and update the values for matching Employee Ids\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Pos Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['Position Number'])\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'BF4 Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['BF Level 4 Name'])\n",
    "vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Country Check'] = vOld.loc[vOld['Employee ID'].isin(vNew['Employee ID']), 'Employee ID'].map(vNew.set_index('Employee ID')['Work Location Country/Territory Name'])\n",
    "\n",
    "# Display the updated vOld DataFrame\n",
    "print(vOld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the new and old data from the Excel workbooks\n",
    "vNew = pd.read_excel('path_to_vNew.xlsx')\n",
    "vOld = pd.read_excel('path_to_vOld.xlsx')\n",
    "\n",
    "# Select the required columns\n",
    "vNew = vNew[['Employee ID', 'Position Number', 'Level4']]\n",
    "vOld = vOld[['Employee ID', 'Position Number', 'Level4']]\n",
    "\n",
    "# Merge the dataframes on Employee ID\n",
    "merged_df = pd.merge(vNew, vOld, on='Employee ID', how='outer', suffixes=('_new', '_old'))\n",
    "\n",
    "# Create the Status column\n",
    "merged_df['Status'] = merged_df.apply(\n",
    "    lambda row: 'new' if pd.isna(row['Position Number_old']) and not pd.isna(row['Position Number_new']) else \n",
    "                ('left' if pd.isna(row['Position Number_new']) and not pd.isna(row['Position Number_old']) else \n",
    "                'existing'), axis=1)\n",
    "\n",
    "# Save the resulting dataframe to a new Excel file\n",
    "merged_df.to_excel('path_to_output.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1967abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_excel_file.xlsx'  # Replace with your file path\n",
    "output_file_path = 'grouped_data_with_subtables.xlsx'  # Replace with your desired output file path\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create a Pandas Excel writer object\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read each sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "        # Group the data by 'Mapped L3' and 'Role_temp'\n",
    "        grouped = df.groupby(['Mapped L3', 'Role_temp'])\n",
    "\n",
    "        # Count the occurrences of 'High' and 'Low' in the 'High/Low' column\n",
    "        result = grouped['High/Low'].value_counts().unstack(fill_value=0).fillna(0)\n",
    "\n",
    "        # Add totals for each row ('Mapped L3', 'Role_temp')\n",
    "        result['Total'] = result.sum(axis=1)\n",
    "\n",
    "        # Add a totals row\n",
    "        total_row = result.sum(axis=0).to_frame().T\n",
    "        total_row.index = pd.MultiIndex.from_tuples([('Total', '')])\n",
    "        result = pd.concat([result, total_row])\n",
    "\n",
    "        # Reset the index to get 'Mapped L3' and 'Role_temp' as columns\n",
    "        result.reset_index(inplace=True)\n",
    "\n",
    "        # Ensure 'High' and 'Low' are present, if not add them with default 0 values\n",
    "        if 'High' not in result.columns:\n",
    "            result['High'] = 0\n",
    "        if 'Low' not in result.columns:\n",
    "            result['Low'] = 0\n",
    "        result = result[['Mapped L3', 'Role_temp', 'High', 'Low', 'Total']]\n",
    "\n",
    "        # Write the grouped data to the sheet\n",
    "        result.to_excel(writer, sheet_name=sheet_name, startrow=0, index=False)\n",
    "        \n",
    "        # Load the workbook and access the worksheet\n",
    "        workbook = writer.book\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Initialize start row for writing subtables\n",
    "        start_row = len(result) + 2  # Move to the next row after grouped data\n",
    "\n",
    "        # Create a list to store all subtables\n",
    "        subtables_list = []\n",
    "\n",
    "        # Create subtables for each unique 'Mapped L3'\n",
    "        unique_mapped_l3 = df['Mapped L3'].unique()\n",
    "        for mapped_l3 in unique_mapped_l3:\n",
    "            # Skip 'Total' rows if present\n",
    "            if mapped_l3 == 'Total':\n",
    "                continue\n",
    "\n",
    "            # Filter the original DataFrame based on 'Mapped L3'\n",
    "            mapped_l3_data = df[df['Mapped L3'] == mapped_l3]\n",
    "\n",
    "            # Insert a heading for unique 'Mapped L3'\n",
    "            mapped_l3_heading = f\"Unique L3 Value: {mapped_l3}\"\n",
    "            subtables_list.append((mapped_l3_heading, None))  # Append heading to list\n",
    "\n",
    "            # Iterate over each unique 'Role_temp' for the current 'Mapped L3'\n",
    "            unique_role_temp = mapped_l3_data['Role_temp'].unique()\n",
    "            for role_temp in unique_role_temp:\n",
    "                # Filter the data for the current 'Mapped L3' and 'Role_temp'\n",
    "                subtable_data = mapped_l3_data[mapped_l3_data['Role_temp'] == role_temp]\n",
    "\n",
    "                # Insert a heading for 'Role_temp'\n",
    "                role_temp_heading = f\"Role Type: {role_temp}\"\n",
    "                subtables_list.append((role_temp_heading, None))  # Append heading to list\n",
    "\n",
    "                # Append the subtable data to the list\n",
    "                subtables_list.append((None, subtable_data))\n",
    "\n",
    "        # Write subtables to Excel with proper gaps\n",
    "        for item in subtables_list:\n",
    "            if item[0]:  # If it's a heading\n",
    "                worksheet.cell(row=start_row, column=1, value=item[0])\n",
    "                start_row += 2  # 2-line gap before next heading or subtable\n",
    "            elif item[1] is not None:  # If it's subtable data\n",
    "                item[1].to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False, header=True)\n",
    "                start_row += len(item[1]) + 1  # 1-line gap after subtable\n",
    "\n",
    "print(f\"Grouped data with subtables has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901416c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'your_excel_file.xlsx'  # Replace with your file path\n",
    "output_file_path = 'grouped_data_with_subtables.xlsx'  # Replace with your desired output file path\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create a Pandas Excel writer object\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read each sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "        # Group the data by 'Mapped L3' and 'Role_temp'\n",
    "        grouped = df.groupby(['Mapped L3', 'Role_temp'])\n",
    "\n",
    "        # Count the occurrences of 'High' and 'Low' in the 'High/Low' column\n",
    "        result = grouped['High/Low'].value_counts().unstack(fill_value=0).fillna(0)\n",
    "\n",
    "        # Add totals for each row ('Mapped L3', 'Role_temp')\n",
    "        result['Total'] = result.sum(axis=1)\n",
    "\n",
    "        # Add a totals row\n",
    "        total_row = result.sum(axis=0).to_frame().T\n",
    "        total_row.index = pd.MultiIndex.from_tuples([('Total', '')])\n",
    "        result = pd.concat([result, total_row])\n",
    "\n",
    "        # Reset the index to get 'Mapped L3' and 'Role_temp' as columns\n",
    "        result.reset_index(inplace=True)\n",
    "\n",
    "        # Ensure 'High' and 'Low' are present, if not add them with default 0 values\n",
    "        if 'High' not in result.columns:\n",
    "            result['High'] = 0\n",
    "        if 'Low' not in result.columns:\n",
    "            result['Low'] = 0\n",
    "        result = result[['Mapped L3', 'Role_temp', 'Total', 'High', 'Low']]\n",
    "\n",
    "        # Initialize start row for writing grouped data\n",
    "        start_row = 0\n",
    "\n",
    "        # Write the grouped data to the sheet\n",
    "        result.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "        start_row += len(result) + 2  # Move to the next row after grouped data\n",
    "\n",
    "        # Create subtables for each unique 'Mapped L3'\n",
    "        unique_mapped_l3 = df['Mapped L3'].unique()\n",
    "        for mapped_l3 in unique_mapped_l3:\n",
    "            # Skip 'Total' rows if present\n",
    "            if mapped_l3 == 'Total':\n",
    "                continue\n",
    "\n",
    "            # Filter the original DataFrame based on 'Mapped L3'\n",
    "            mapped_l3_data = df[df['Mapped L3'] == mapped_l3]\n",
    "\n",
    "            # Insert a heading for unique 'Mapped L3'\n",
    "            mapped_l3_heading = f\"Unique L3 Value: {mapped_l3}\"\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            worksheet.cell(row=start_row, column=1, value=mapped_l3_heading)\n",
    "\n",
    "            # Move to the next row after writing unique L3 heading\n",
    "            start_row += 2\n",
    "\n",
    "            # Iterate over each unique 'Role_temp' for the current 'Mapped L3'\n",
    "            unique_role_temp = mapped_l3_data['Role_temp'].unique()\n",
    "            for role_temp in unique_role_temp:\n",
    "                # Filter the data for the current 'Mapped L3' and 'Role_temp'\n",
    "                subtable_data = mapped_l3_data[mapped_l3_data['Role_temp'] == role_temp]\n",
    "\n",
    "                # Insert a heading for 'Role_temp'\n",
    "                role_temp_heading = f\"Role Type: {role_temp}\"\n",
    "                worksheet.cell(row=start_row, column=1, value=role_temp_heading)\n",
    "\n",
    "                # Move to the next row after writing role_temp heading\n",
    "                start_row += 2\n",
    "\n",
    "                # Insert an empty row to separate headings from subtable data\n",
    "                worksheet.cell(row=start_row, column=1, value=\"\")\n",
    "\n",
    "                # Move to the next row after inserting empty row\n",
    "                start_row += 1\n",
    "\n",
    "                # Write the subtable data to the sheet\n",
    "                subtable_data.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "\n",
    "                # Move to the next row after writing subtable data\n",
    "                start_row += len(subtable_data) + 2  # Add extra space after each subtable\n",
    "\n",
    "print(f\"Grouped data with subtables has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19c99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS\n",
      "0    1    10  NaN\n",
      "1    2    20  NaN\n",
      "2    3    30    a\n",
      "3    4    40    b\n",
      "4    7    50    c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4, 7],\n",
    "    'colB': [10, 20, 30, 40, 50],\n",
    "    'colS': [None, None, None, None, None]  # Initially None or some default value\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    'colPM': [7, 8, 9, 10, 11, 12]\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA, colR, and colPM are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "df2['colPM'] = df2['colPM'].astype(str)\n",
    "\n",
    "# Initial merge using colA and colR\n",
    "df_merged_initial = pd.merge(df1, df2[['colR', 'colS']], left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Update df1's colS with the values from initial merge\n",
    "df1['colS'] = df_merged_initial['colS_y']\n",
    "\n",
    "# Identify rows where colS is still NaN\n",
    "mask = df1['colS'].isna()\n",
    "\n",
    "# Perform the second merge using colA and colPM for the NaN rows\n",
    "df_merged_second = pd.merge(df1[mask], df2[['colPM', 'colS']], left_on='colA', right_on='colPM', how='left')\n",
    "\n",
    "# Update colS in df1 for the NaN rows with values from the second merge\n",
    "df1.loc[mask, 'colS'] = df_merged_second['colS_y']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5784398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS\n",
      "0    1    10  NaN\n",
      "1    2    20  NaN\n",
      "2    3    30    a\n",
      "3    4    40    b\n",
      "4    7    50    c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4, 7],\n",
    "    'colB': [10, 20, 30, 40, 50],\n",
    "    'colS': [None, '', ' ', '   ', '']  # Different types of empty or blank values\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    'colPM': [7, 8, 9, 10, 11, 12]\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA, colR, and colPM are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "df2['colPM'] = df2['colPM'].astype(str)\n",
    "\n",
    "# Initial merge using colA and colR\n",
    "df_merged_initial = pd.merge(df1, df2[['colR', 'colS']], left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Update df1's colS with the values from initial merge\n",
    "df1['colS'] = df_merged_initial['colS_y']\n",
    "\n",
    "# Identify rows where colS is empty or blank\n",
    "mask = df1['colS'].apply(lambda x: x == '' or x.isspace() if isinstance(x, str) else False)\n",
    "\n",
    "# Perform the second merge using colA and colPM for the empty or blank rows\n",
    "df_merged_second = pd.merge(df1[mask], df2[['colPM', 'colS']], left_on='colA', right_on='colPM', how='left')\n",
    "\n",
    "# Update colS in df1 for the empty or blank rows with values from the second merge\n",
    "df1.loc[mask, 'colS'] = df_merged_second['colS_y']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44b6bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colA</th>\n",
       "      <th>colB</th>\n",
       "      <th>colS_x</th>\n",
       "      <th>colPM</th>\n",
       "      <th>colS_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  colA  colB colS_x colPM colS_y\n",
       "0    1    10    NaN   NaN    NaN\n",
       "1    2    20    NaN   NaN    NaN\n",
       "2    7    50    NaN     7      a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b765483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colA  colB colS1\n",
      "0    1    10   NaN\n",
      "1    2    20   NaN\n",
      "2    3    30     a\n",
      "3    4    40     c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1 with 30 columns (only a few shown here for simplicity)\n",
    "data1 = {\n",
    "    'colA': [1, 2, 3, 4],\n",
    "    'colB': [10, 20, 30, 40],\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with 45 columns (only a few shown here for simplicity)\n",
    "data2 = {\n",
    "    'colR': [3, 3, 4, 5, 6, 6],\n",
    "    'colS': ['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    # Add other columns as needed\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Ensure the data types of colA and colR are the same\n",
    "df1['colA'] = df1['colA'].astype(str)\n",
    "df2['colR'] = df2['colR'].astype(str)\n",
    "\n",
    "# Select only the required columns from df2\n",
    "df2_selected = df2[['colR', 'colS']].drop_duplicates(subset='colR')\n",
    "\n",
    "# Merge df1 with df2_selected on colA and colR\n",
    "df_merged = pd.merge(df1, df2_selected, left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Assign the values to the new column in df1 and drop any extra columns\n",
    "df1['colS1'] = df_merged['colS']\n",
    "\n",
    "# Drop the extra merge column if needed (not strictly necessary, but clean)\n",
    "df1.drop(columns=['colR'], inplace=True, errors='ignore')\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d80a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colA colS1\n",
      "0     1   NaN\n",
      "1     2   NaN\n",
      "2     3     a\n",
      "3     4     b\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for df1\n",
    "data1 = {'colA': [1, 2, 3, 4]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Sample data for df2 with non-unique colR values\n",
    "data2 = {'colR': [3, 3, 4, 5, 6, 6], 'colS': ['a', 'b', 'c', 'd', 'e', 'f']}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge df1 with df2 on the condition that df1['colA'] matches df2['colR']\n",
    "df_merged = pd.merge(df1, df2, left_on='colA', right_on='colR', how='left')\n",
    "\n",
    "# Select only relevant columns and rename them\n",
    "df1['colS1'] = df_merged['colS']\n",
    "\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c042a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id colX colY colZ\n",
      "0   6   X6   Y6   Z6\n",
      "1   7   X7   Y7   Z7\n",
      "2   8   X8   Y8   Z8\n",
      "3   1  NaN   B1   C1\n",
      "4   2  NaN   B2   C2\n",
      "5   3  NaN   B3   C3\n",
      "6   4  NaN   B4   C4\n",
      "7   5  NaN   B5   C5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'colA': ['A1', 'A2', 'A3', 'A4', 'A5'],\n",
    "    'colB': ['B1', 'B2', 'B3', 'B4', 'B5'],\n",
    "    'colC': ['C1', 'C2', 'C3', 'C4', 'C5']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [6, 7, 8],\n",
    "    'colX': ['X6', 'X7', 'X8'],\n",
    "    'colY': ['Y6', 'Y7', 'Y8'],\n",
    "    'colZ': ['Z6', 'Z7', 'Z8']\n",
    "})\n",
    "\n",
    "# Columns to copy from df1 and their corresponding columns in df2\n",
    "columns_to_copy = {\n",
    "    'id': 'id',\n",
    "    'colB': 'colY',\n",
    "    'colC': 'colZ'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with the selected columns from df1\n",
    "new_rows = df1[list(columns_to_copy.keys())].copy()\n",
    "\n",
    "# Rename the columns in the new DataFrame to match the column names in df2\n",
    "new_rows.rename(columns=columns_to_copy, inplace=True)\n",
    "\n",
    "# Append the new DataFrame to df2\n",
    "df2 = df2.append(new_rows, ignore_index=True)\n",
    "\n",
    "# Display the updated df2\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08dd5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
