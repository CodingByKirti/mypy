{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eacbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import win32com.client\n",
    "\n",
    "# Load your file and sheet\n",
    "df = pd.read_excel(\"Your_File.xlsx\")  # <-- Update with your actual file\n",
    "email_col = \"Email\"  # <-- Your email column name\n",
    "\n",
    "# Initialize Outlook session\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").Session\n",
    "\n",
    "# Define a function to validate each email\n",
    "def check_email_validity(email):\n",
    "    if pd.isna(email) or not isinstance(email, str) or \"@\" not in email:\n",
    "        return \"Invalid\"\n",
    "    recipient = outlook.CreateRecipient(email.strip())\n",
    "    return \"Valid\" if recipient.Resolve() else \"Invalid\"\n",
    "\n",
    "# Apply to the dataframe\n",
    "df[\"Email Validity\"] = df[email_col].apply(check_email_validity)\n",
    "\n",
    "# Save to new file\n",
    "output_file = \"Email_Validation_With_Status.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Email validation complete. Output saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# ===== START: Email-based fallback if PSID match fails =====\n",
    "missing_mask = unique_psids[\"GIRS Current Status\"].isna() | (unique_psids[\"GIRS Current Status\"].str.lower() == \"n/a\")\n",
    "fallback_emails = unique_psids.loc[missing_mask, [\"PSID\", \"Selected Email\"]].copy()\n",
    "\n",
    "# Clean df_girs email for match\n",
    "df_girs[\"clean_email\"] = df_girs[\"Email\"].apply(lambda x: x.strip().lower() if isinstance(x, str) else \"\")\n",
    "\n",
    "# Clean fallback_emails too\n",
    "fallback_emails[\"Selected Email\"] = fallback_emails[\"Selected Email\"].apply(lambda x: x.strip().lower() if isinstance(x, str) else \"\")\n",
    "\n",
    "# Merge based on email\n",
    "email_matches = fallback_emails.merge(df_girs[[\"clean_email\", \"Role\"]], how=\"left\", left_on=\"Selected Email\", right_on=\"clean_email\")\n",
    "\n",
    "# Update missing GIRS Current Status\n",
    "for idx, row in email_matches.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    role = row[\"Role\"]\n",
    "    if pd.notna(role):\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, \"GIRS Current Status\"] = role\n",
    "# ===== END: Email-based fallback =====\n",
    "# ===== START: Enhanced update of team status using PSID, fallback to Email =====\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    email = row[\"Email\"]\n",
    "    teams = str(row[\"Tab data\"]).split(\",\")\n",
    "\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        \n",
    "        # Update based on PSID match\n",
    "        updated = unique_psids.loc[unique_psids[\"PSID\"] == psid, team]\n",
    "        if updated.notna().any():\n",
    "            unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "        # Update based on Email if PSID match didn't work\n",
    "        fallback_mask = (unique_psids[team] == \"N/A\") & (unique_psids[\"Selected Email\"] == email)\n",
    "        unique_psids.loc[fallback_mask, team] = status\n",
    "# ===== END: Enhanced update of team status using PSID, fallback to Email =====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19482ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"your_file.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read the Processed Data sheet\n",
    "df_processed = xls.parse(\"Processed Data\")\n",
    "\n",
    "# Ensure column names are lower case for consistency\n",
    "df_processed.columns = df_processed.columns.str.lower()\n",
    "\n",
    "# Define the dynamic columns\n",
    "dynamic_columns = [col for col in df_processed.columns if col not in [\"psid\", \"resource name\", \"email\", \"girs current status\", \"tier1\", \"ttrl\", \"pdmr\"]]\n",
    "\n",
    "# Function to determine the comment based on conditions\n",
    "def assign_comment(row):\n",
    "    girs_status = row[\"girs current status\"].strip().lower() if pd.notna(row[\"girs current status\"]) else \"\"\n",
    "    tier_check = row[\"tier1\"].lower() == \"yes\" or row[\"ttrl\"].lower() == \"yes\" or row[\"pdmr\"].lower() == \"yes\"\n",
    "    \n",
    "    dynamic_values = [row[col].strip().lower() if pd.notna(row[col]) else \"n/a\" for col in dynamic_columns]\n",
    "    add_exists = \"add\" in dynamic_values\n",
    "    del_exists = \"del\" in dynamic_values\n",
    "    cur_exists = \"cur\" in dynamic_values\n",
    "    only_na_cur_del = all(val in [\"n/a\", \"cur\", \"del\"] for val in dynamic_values)\n",
    "    only_na_cur_add = all(val in [\"n/a\", \"cur\", \"add\"] for val in dynamic_values)\n",
    "    only_na = all(val == \"n/a\" for val in dynamic_values)\n",
    "\n",
    "    if girs_status == \"inactive insider\" or girs_status == \"\" and tier_check:\n",
    "        return \"Part of Tier1, TTRL, PDMR\"\n",
    "    elif girs_status == \"non-core\" and tier_check:\n",
    "        return \"Change to Inactive\"\n",
    "    elif girs_status == \"\" and not tier_check and add_exists and only_na_cur_del:\n",
    "        return \"To Add\"\n",
    "    elif girs_status == \"inactive insider\" and not tier_check and del_exists and only_na_cur_add:\n",
    "        return \"Already Inactive\"\n",
    "    elif girs_status == \"non-core\" and not tier_check and add_exists and only_na_cur_del:\n",
    "        return \"Already Non-Core\"\n",
    "    elif girs_status == \"inactive insider\" and not tier_check and del_exists and only_na_cur_add:\n",
    "        return \"No Action\"\n",
    "    elif girs_status == \"non-core\" and not tier_check and (cur_exists or add_exists) and only_na:\n",
    "        return \"No Action\"\n",
    "    elif not tier_check and girs_status in [\"\", \"non-core\"] and del_exists and only_na:\n",
    "        return \"To Delete\"\n",
    "    elif not tier_check and girs_status in [\"\", \"non-core\"] and (cur_exists or add_exists) and only_na_cur_del:\n",
    "        return \"To Retain Non-Core\"\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Apply the function to create the Comment column\n",
    "df_processed[\"comment\"] = df_processed.apply(assign_comment, axis=1)\n",
    "\n",
    "# Write the updated Processed Data sheet\n",
    "with pd.ExcelWriter(\"your_updated_file.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    df_processed.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    \n",
    "    # Create separate sheets for each unique comment\n",
    "    for comment in df_processed[\"comment\"].unique():\n",
    "        df_filtered = df_processed[df_processed[\"comment\"] == comment]\n",
    "        df_filtered.to_excel(writer, sheet_name=comment[:31], index=False)  # Sheet names must be <= 31 chars\n",
    "\n",
    "print(\"Updated file saved with new comments and categorized sheets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac36501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Code for Processing Data with Comments and Categorization\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data (assuming dfs are already loaded)\n",
    "# processed_data = ...\n",
    "\n",
    "# Ensure dynamic columns are in lowercase for consistency\n",
    "dynamic_cols = [col.lower() for col in processed_data.columns if col not in [\"PSID\", \"Resource Name\", \"Email\", \"Tier1\", \"TTRL\", \"PDMR\", \"GIRS Current Status\"]]\n",
    "\n",
    "# Standardize \"N/A\" values in dynamic columns\n",
    "processed_data[dynamic_cols] = processed_data[dynamic_cols].replace(\"\", \"N/A\")\n",
    "\n",
    "# Define function to classify records\n",
    "def classify_records(row):\n",
    "    girs_status = row[\"GIRS Current Status\"].strip().lower() if pd.notna(row[\"GIRS Current Status\"]) else \"\"\n",
    "    tier_check = row[[\"Tier1\", \"TTRL\", \"PDMR\"]].eq(\"Yes\").any()\n",
    "    tier_all_no = row[[\"Tier1\", \"TTRL\", \"PDMR\"]].eq(\"No\").all()\n",
    "    \n",
    "    add_exists = (row[dynamic_cols] == \"add\").any()\n",
    "    del_exists = (row[dynamic_cols] == \"del\").any()\n",
    "    cur_exists = (row[dynamic_cols] == \"cur\").any()\n",
    "    only_na_cur_del = row[dynamic_cols].apply(lambda x: x in [\"N/A\", \"cur\", \"del\"]).all()\n",
    "    only_na_cur = row[dynamic_cols].apply(lambda x: x in [\"N/A\", \"cur\"]).all()\n",
    "    only_na = row[dynamic_cols].eq(\"N/A\").all()\n",
    "    \n",
    "    if (girs_status == \"inactive insider\" or girs_status == \"\") and tier_check:\n",
    "        return \"Part of Tier1, TTRL, PDMR\"\n",
    "    elif girs_status == \"non-core\" and tier_check:\n",
    "        return \"Change to Inactive\"\n",
    "    elif girs_status == \"\" and tier_all_no and add_exists and only_na_cur_del:\n",
    "        return \"To Add\"\n",
    "    elif girs_status == \"inactive insider\" and tier_all_no and del_exists and only_na_cur:\n",
    "        return \"Already Inactive\"\n",
    "    elif girs_status == \"non-core\" and tier_all_no and add_exists and only_na_cur_del:\n",
    "        return \"Already Non-Core\"\n",
    "    elif girs_status == \"non-core\" and tier_all_no and del_exists and only_na:\n",
    "        return \"Change to Non-Core\"\n",
    "    elif girs_status == \"inactive insider\" and tier_all_no and del_exists and only_na_cur:\n",
    "        return \"No Action\"\n",
    "    elif girs_status == \"non-core\" and tier_all_no and (cur_exists or add_exists) and only_na:\n",
    "        return \"No Action\"\n",
    "    elif tier_all_no and (girs_status == \"\" or girs_status == \"non-core\") and del_exists and only_na:\n",
    "        return \"To Delete\"\n",
    "    elif tier_all_no and (girs_status == \"\" or girs_status == \"non-core\") and (cur_exists or add_exists) and only_na_cur_del:\n",
    "        return \"To Retain Non-Core\"\n",
    "    return \"Uncategorized\"\n",
    "\n",
    "# Apply classification\n",
    "processed_data[\"Comment\"] = processed_data.apply(classify_records, axis=1)\n",
    "\n",
    "# Save categorized data into separate sheets\n",
    "categorized_sheets = processed_data.groupby(\"Comment\")\n",
    "\n",
    "with pd.ExcelWriter(\"Processed_Data_Updated.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    processed_data.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    for comment, group in categorized_sheets:\n",
    "        group.to_excel(writer, sheet_name=comment[:31], index=False)  # Excel sheet names max 31 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"GIRS2.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\", header=None, names=[\"Resource Name\"])\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Standardize PSIDs by removing leading zeros\n",
    "def standardize_psid(psid):\n",
    "    return str(int(psid)) if str(psid).isdigit() else psid\n",
    "\n",
    "df_conso[\"PSID\"] = df_conso[\"PSID\"].astype(str).apply(standardize_psid)\n",
    "df_girs[\"PSID\"] = df_girs[\"PSID\"].astype(str).apply(standardize_psid)\n",
    "df_tier[\"PSID\"] = df_tier[\"PSID\"].astype(str).apply(standardize_psid)\n",
    "df_ttrl[\"PSID\"] = df_ttrl[\"PSID\"].astype(str).apply(standardize_psid)\n",
    "\n",
    "# Extract email from < > if present\n",
    "def extract_email(email):\n",
    "    match = re.search(r\"<(.*?)>\", email)\n",
    "    return match.group(1) if match else email.split()[0] if \"@\" in email else \"\"\n",
    "\n",
    "# Process unique PSIDs with Resource Name and Email\n",
    "def process_psid_group(group):\n",
    "    resource_names = [name.strip() for name in group[\"Resource Name\"].dropna().unique()]\n",
    "    email_ids = [extract_email(email.strip()) for email in group[\"Email\"].dropna().unique()]\n",
    "    psid = group[\"PSID\"].iloc[0]\n",
    "    \n",
    "    # Remove resource names containing PSID unless it's the only one\n",
    "    valid_names = [name for name in resource_names if str(psid) not in name]\n",
    "    resource_name = max(valid_names, key=lambda x: len(x.split()), default=resource_names[0] if resource_names else \"\")\n",
    "    \n",
    "    # Validate email addresses\n",
    "    valid_emails = [email for email in email_ids if \"@\" in email and not any(sym in email for sym in [\"/\", \"#\"])]\n",
    "    email = \"; \".join(valid_emails) if valid_emails else \"\"\n",
    "    \n",
    "    selected_email = valid_emails[0] if len(set(valid_emails)) == 1 else \"; \".join(valid_emails) if len(valid_emails) > 1 else \"\"\n",
    "    \n",
    "    return pd.Series({\"Resource Name\": resource_name, \"Email\": email, \"All Emails\": \"; \".join(email_ids), \"Selected Email\": selected_email})\n",
    "\n",
    "# Filter valid PSIDs (numeric only)\n",
    "df_valid_psid = df_conso[df_conso[\"PSID\"].str.isnumeric()].copy()\n",
    "df_invalid_psid = df_conso[~df_conso[\"PSID\"].str.isnumeric()].copy()\n",
    "# df_invalid_psid.insert(0, \"PSID\", \"Invalid\")\n",
    "\n",
    "unique_psids = df_valid_psid.groupby(\"PSID\").apply(process_psid_group).reset_index()\n",
    "\n",
    "# Capture invalid email records\n",
    "invalid_emails = df_valid_psid[df_valid_psid[\"PSID\"].isin(unique_psids.loc[unique_psids[\"Email\"].eq(\"\"), \"PSID\"])].copy()\n",
    "\n",
    "# Capture multiple email discrepancies\n",
    "multiple_emails = unique_psids[unique_psids[\"All Emails\"].str.contains(\";\")].copy()\n",
    "multiple_emails[\"Selected Email\"] = multiple_emails[\"Selected Email\"]\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "# unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "df_invalid_psid[\"PDMR\"]=\"Resource Name is missing.\"\n",
    "# Extract unique team names from Conso Data Tab data column\n",
    "df_conso[\"Tab data\"] = df_conso[\"Tab data\"].astype(str)\n",
    "unique_teams = df_conso[\"Tab data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = str(row[\"Tab data\"]).split(\",\")\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    invalid_emails.to_excel(writer, sheet_name=\"Invalid Emails\", index=False)\n",
    "    df_invalid_psid.to_excel(writer, sheet_name=\"Invalid PSIDs\", index=False)\n",
    "    multiple_emails.to_excel(writer, sheet_name=\"Multiple Emails\", index=False)\n",
    "    df_conso.to_excel(writer, sheet_name=\"Original Data\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"GIRS2.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\", header=None, names=[\"Resource Name\"])\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Extract email from < > if present\n",
    "def extract_email(email):\n",
    "    match = re.search(r\"<(.*?)>\", email)\n",
    "    return match.group(1) if match else email\n",
    "\n",
    "# Process unique PSIDs with Resource Name and Email\n",
    "def process_psid_group(group):\n",
    "    resource_names = [name.strip() for name in group[\"Resource Name\"].dropna().unique()]\n",
    "    email_ids = [extract_email(email.strip()) for email in group[\"Email\"].dropna().unique()]\n",
    "    psid = group[\"PSID\"].iloc[0]\n",
    "    \n",
    "    # Remove resource names containing PSID unless it's the only one\n",
    "    valid_names = [name for name in resource_names if str(psid) not in name]\n",
    "    resource_name = max(valid_names, key=lambda x: len(x.split()), default=resource_names[0] if resource_names else \"\")\n",
    "    \n",
    "    # Validate email addresses\n",
    "    valid_emails = [email for email in email_ids if \"@\" in email and not any(sym in email for sym in [\"/\", \"#\"])]\n",
    "    email = \"; \".join(valid_emails) if valid_emails else \"\"\n",
    "    \n",
    "    selected_email = valid_emails[0] if len(set(valid_emails)) == 1 else \"\"\n",
    "    \n",
    "    return pd.Series({\"Resource Name\": resource_name, \"Email\": email, \"All Emails\": \"; \".join(email_ids), \"Selected Email\": selected_email})\n",
    "\n",
    "# Filter valid PSIDs (numeric only)\n",
    "df_conso[\"PSID\"] = df_conso[\"PSID\"].astype(str)\n",
    "df_valid_psid = df_conso[df_conso[\"PSID\"].str.isnumeric()].copy()\n",
    "df_invalid_psid = df_conso[~df_conso[\"PSID\"].str.isnumeric()].copy()\n",
    "df_invalid_psid.insert(0, \"PSID\", \"Invalid\")  # Ensure PSID column exists\n",
    "\n",
    "unique_psids = df_valid_psid.groupby(\"PSID\").apply(process_psid_group).reset_index()\n",
    "\n",
    "# Capture invalid email records\n",
    "invalid_emails = df_valid_psid[df_valid_psid[\"PSID\"].isin(unique_psids.loc[unique_psids[\"Email\"].eq(\"\"), \"PSID\"])].copy()\n",
    "\n",
    "# Capture multiple email discrepancies\n",
    "multiple_emails = unique_psids[unique_psids[\"All Emails\"].str.contains(\";\")].copy()\n",
    "multiple_emails[\"Selected Email\"] = multiple_emails[\"Selected Email\"]\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Extract unique team names from Conso Data Tab data column\n",
    "df_conso[\"Tab data\"] = df_conso[\"Tab data\"].astype(str)\n",
    "unique_teams = df_conso[\"Tab data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = str(row[\"Tab data\"]).split(\",\")\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    invalid_emails.to_excel(writer, sheet_name=\"Invalid Emails\", index=False)\n",
    "    df_invalid_psid.to_excel(writer, sheet_name=\"Invalid PSIDs\", index=False)\n",
    "    multiple_emails.to_excel(writer, sheet_name=\"Multiple Emails\", index=False)\n",
    "    df_conso.to_excel(writer, sheet_name=\"Original Data\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"GIRS2.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\", header=None, names=[\"Resource Name\"])\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Process unique PSIDs with Resource Name and Email\n",
    "def process_psid_group(group):\n",
    "    resource_names = [name.strip() for name in group[\"Resource Name\"].dropna().unique()]\n",
    "    email_ids = [email.strip() for email in group[\"Email\"].dropna().unique()]\n",
    "    psid = group[\"PSID\"].iloc[0]\n",
    "    \n",
    "    # Remove resource names containing PSID unless it's the only one\n",
    "    valid_names = [name for name in resource_names if str(psid) not in name]\n",
    "    resource_name = max(valid_names, key=lambda x: len(x.split()), default=resource_names[0] if resource_names else \"\")\n",
    "    \n",
    "    # Validate email addresses\n",
    "    valid_emails = [email for email in email_ids if \"@\" in email and not any(sym in email for sym in [\"/\", \"#\"])]\n",
    "    email = \"; \".join(valid_emails) if valid_emails else (email_ids[0] if email_ids else \"\")\n",
    "    \n",
    "    return pd.Series({\"Resource Name\": resource_name, \"Email\": email})\n",
    "\n",
    "unique_psids = df_conso.groupby(\"PSID\").apply(process_psid_group).reset_index()\n",
    "\n",
    "# Capture invalid email records\n",
    "invalid_emails = df_conso[df_conso[\"PSID\"].isin(unique_psids[unique_psids[\"Email\"].eq(\"\")][\"PSID\"])]\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Extract unique team names from Conso Data Tab data column\n",
    "df_conso[\"Tab data\"] = df_conso[\"Tab data\"].astype(str)  # Convert to string to avoid errors\n",
    "unique_teams = df_conso[\"Tab data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = str(row[\"Tab data\"]).split(\",\")  # Convert to string before splitting\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Handle records with missing or non-numeric PSIDs\n",
    "invalid_psid_records = df_conso[df_conso[\"PSID\"].isna() | ~df_conso[\"PSID\"].astype(str).str.isnumeric()]\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    invalid_emails.to_excel(writer, sheet_name=\"Invalid Emails\", index=False)\n",
    "    invalid_psid_records.to_excel(writer, sheet_name=\"Invalid PSIDs\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"your_excel_file.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\")\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Extract unique PSIDs\n",
    "unique_psids = df_conso[[\"PSID\", \"Resource Name\", \"Email\"]].drop_duplicates()\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Extract unique team names from Conso Data Tab Data column\n",
    "unique_teams = df_conso[\"Tab Data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = row[\"Tab Data\"].split(\",\")\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b42ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"your_file.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read required sheets\n",
    "df_conso = pd.read_excel(xls, sheet_name='Conso Data')\n",
    "df_girs = pd.read_excel(xls, sheet_name=\"GIRS Extract_20 Mar'25\")\n",
    "df_tier1 = pd.read_excel(xls, sheet_name=\"TIER1_5 Mar'25\")\n",
    "df_ttrl = pd.read_excel(xls, sheet_name=\"TTRL_3 Mar'25\")\n",
    "df_pdmr = pd.read_excel(xls, sheet_name=\"PDMR_1Jan'25\", header=None, names=['PDMR'])\n",
    "\n",
    "# Data Cleaning & Standardization\n",
    "df_conso['PSID'] = df_conso['PSID'].astype(str).str.lstrip('0')\n",
    "df_conso['Resource name'] = df_conso['Resource name'].str.title()\n",
    "df_pdmr['PDMR'] = df_pdmr['PDMR'].str.lower()\n",
    "\n",
    "df_girs['Employee ID'] = df_girs['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_girs['Insider Name'] = df_girs['Insider Name'].str.title()\n",
    "\n",
    "df_tier1['Employee ID'] = df_tier1['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_tier1['Insider Name'] = df_tier1['Insider Name'].str.title()\n",
    "\n",
    "df_ttrl['Employee ID'] = df_ttrl['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_ttrl['Insider Name'] = df_ttrl['Insider Name'].str.title()\n",
    "\n",
    "# Merge Conso Data with GIRS Extract\n",
    "df_merged = df_conso.merge(df_girs, left_on='PSID', right_on='Employee ID', how='left')\n",
    "\n",
    "# Identify status updates\n",
    "final_records = []\n",
    "for _, row in df_merged.iterrows():\n",
    "    psid = row['PSID']\n",
    "    resource_name = row['Resource name']\n",
    "    email = row['Email']\n",
    "    original_status = row['Role'] if pd.notna(row['Role']) else 'Not in GIRS'\n",
    "    updated_status = row['Status']\n",
    "    comments = []\n",
    "    \n",
    "    if row['TIER1'] == 'Yes' or row['TTRL'] == 'Yes' or resource_name.lower() in df_pdmr['PDMR'].values:\n",
    "        comments.append(\"Employee in TIER1/TTRL/PDMR\")\n",
    "    \n",
    "    if original_status == 'Non-Core' and updated_status == 'DEL':\n",
    "        updated_status = 'Inactive Insider'\n",
    "        comments.append(\"Non-Core user marked for deletion\")\n",
    "    \n",
    "    if original_status == 'Inactive Insider' and updated_status == 'ADD':\n",
    "        updated_status = 'Non-Core'\n",
    "        comments.append(\"Inactive Insider reactivated as Non-Core\")\n",
    "    \n",
    "    final_records.append([psid, resource_name, email, original_status, updated_status, ', '.join(comments)])\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_records, columns=['PSID', 'Resource name', 'Email', 'Original Status', 'Updated Status', 'Comments'])\n",
    "\n",
    "# Export to Excel\n",
    "final_df.to_excel(\"Processed_GIRS_Data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_girs_data(file_path):\n",
    "    # Load required sheets\n",
    "    conso_data = pd.read_excel(file_path, sheet_name='Conso Data')\n",
    "    girs_data = pd.read_excel(file_path, sheet_name=\"GIRS Extract_20 Mar'25\")\n",
    "    tier1_data = pd.read_excel(file_path, sheet_name='TIER1_5 Mar'25')\n",
    "    ttrl_data = pd.read_excel(file_path, sheet_name='TTRL_3 Mar'25')\n",
    "    pdmr_data = pd.read_excel(file_path, sheet_name='PDMR_1Jan'25', header=None)  # PDMR has one column\n",
    "    \n",
    "    # Standardizing column names\n",
    "    conso_data.rename(columns={'Resource name': 'Insider Name'}, inplace=True)\n",
    "    girs_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    tier1_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    ttrl_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    \n",
    "    # Convert 'PDMR' column to lowercase for matching\n",
    "    pdmr_data[0] = pdmr_data[0].str.lower()\n",
    "    \n",
    "    # Remove leading zeros from PSID\n",
    "    conso_data['PSID'] = conso_data['PSID'].astype(str).str.lstrip('0')\n",
    "    girs_data['PSID'] = girs_data['PSID'].astype(str).str.lstrip('0')\n",
    "    tier1_data['PSID'] = tier1_data['PSID'].astype(str).str.lstrip('0')\n",
    "    ttrl_data['PSID'] = ttrl_data['PSID'].astype(str).str.lstrip('0')\n",
    "    \n",
    "    # Capitalize Insider Names\n",
    "    conso_data['Insider Name'] = conso_data['Insider Name'].str.upper()\n",
    "    girs_data['Insider Name'] = girs_data['Insider Name'].str.upper()\n",
    "    tier1_data['Insider Name'] = tier1_data['Insider Name'].str.upper()\n",
    "    ttrl_data['Insider Name'] = ttrl_data['Insider Name'].str.upper()\n",
    "    \n",
    "    # Merge GIRS Current Status into Conso Data\n",
    "    merged_data = conso_data.merge(girs_data[['PSID', 'Insider Name', 'Email', 'Role']], \n",
    "                                   on=['PSID', 'Insider Name'], how='left')\n",
    "    merged_data.rename(columns={'Role': 'Original Status in GIRS'}, inplace=True)\n",
    "    \n",
    "    # Identify if PSID is present in Tier1, TTRL\n",
    "    merged_data['Tier1 Flag'] = merged_data['PSID'].isin(tier1_data['PSID']).map({True: 'Yes', False: 'No'})\n",
    "    merged_data['TTRL Flag'] = merged_data['PSID'].isin(ttrl_data['PSID']).map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # Identify if Insider Name matches with PDMR data\n",
    "    merged_data['PDMR Flag'] = merged_data['Insider Name'].str.lower().isin(pdmr_data[0]).map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # Determine Updated Status Request based on rules\n",
    "    def determine_updated_status(row):\n",
    "        if row['Status'] == 'ADD':\n",
    "            return 'Non-Core' if row['Original Status in GIRS'] == 'Inactive Insider' else 'ADD'\n",
    "        elif row['Status'] == 'DEL':\n",
    "            return 'Inactive Insider' if row['Original Status in GIRS'] == 'Non-Core' else 'DEL'\n",
    "        elif row['Status'] == 'Cur':\n",
    "            return row['Original Status in GIRS']  # Keep as is\n",
    "        return row['Status']\n",
    "    \n",
    "    merged_data['Updated Status Request'] = merged_data.apply(determine_updated_status, axis=1)\n",
    "    \n",
    "    # Identify Request Type (New/Updated Request)\n",
    "    merged_data['Request Type'] = merged_data['Original Status in GIRS'].apply(\n",
    "        lambda x: 'New Request' if pd.isna(x) else 'Updated Request'\n",
    "    )\n",
    "    \n",
    "    # Generate Comments Column\n",
    "    def generate_comment(row):\n",
    "        comments = []\n",
    "        if row['Status'] == 'ADD' and row['Updated Status Request'] == 'ADD':\n",
    "            comments.append('Fresh Addition')\n",
    "        if row['Status'] == 'DEL' and row['Updated Status Request'] == 'Inactive Insider':\n",
    "            comments.append('Converted to Inactive Insider')\n",
    "        if row['Status'] == 'ADD' and row['Updated Status Request'] == 'Non-Core':\n",
    "            comments.append('Reactivated to Non-Core')\n",
    "        if row['Tier1 Flag'] == 'Yes':\n",
    "            comments.append('Present in Tier1')\n",
    "        if row['TTRL Flag'] == 'Yes':\n",
    "            comments.append('Present in TTRL')\n",
    "        if row['PDMR Flag'] == 'Yes':\n",
    "            comments.append('Listed in PDMR')\n",
    "        return '; '.join(comments)\n",
    "    \n",
    "    merged_data['Comment'] = merged_data.apply(generate_comment, axis=1)\n",
    "    \n",
    "    # Select final required columns\n",
    "    final_columns = ['PSID', 'Insider Name', 'Email', 'Original Status in GIRS',\n",
    "                     'Updated Status Request', 'Request Type', 'Comment']\n",
    "    final_data = merged_data[final_columns]\n",
    "    \n",
    "    # Save output to a new Excel file\n",
    "    output_file = 'Final_Consolidated_Data.xlsx'\n",
    "    final_data.to_excel(output_file, index=False)\n",
    "    print(f'Final consolidated data saved as {output_file}')\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'GIRS_Processing.xlsx'  # Update this with your actual file path\n",
    "final_output = process_girs_data(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
