{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"GIRS2.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\", header=None, names=[\"Resource Name\"])\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Process unique PSIDs with Resource Name and Email\n",
    "def process_psid_group(group):\n",
    "    resource_names = [name.strip() for name in group[\"Resource Name\"].dropna().unique()]\n",
    "    email_ids = [email.strip() for email in group[\"Email\"].dropna().unique()]\n",
    "    psid = group[\"PSID\"].iloc[0]\n",
    "    \n",
    "    # Remove resource names containing PSID unless it's the only one\n",
    "    valid_names = [name for name in resource_names if str(psid) not in name]\n",
    "    resource_name = max(valid_names, key=lambda x: len(x.split()), default=resource_names[0] if resource_names else \"\")\n",
    "    \n",
    "    # Validate email addresses\n",
    "    valid_emails = [email for email in email_ids if \"@\" in email and not any(sym in email for sym in [\"/\", \"#\"])]\n",
    "    email = \"; \".join(valid_emails) if valid_emails else (email_ids[0] if email_ids else \"\")\n",
    "    \n",
    "    return pd.Series({\"Resource Name\": resource_name, \"Email\": email})\n",
    "\n",
    "unique_psids = df_conso.groupby(\"PSID\").apply(process_psid_group).reset_index()\n",
    "\n",
    "# Capture invalid email records\n",
    "invalid_emails = df_conso[df_conso[\"PSID\"].isin(unique_psids[unique_psids[\"Email\"].eq(\"\")][\"PSID\"])]\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Extract unique team names from Conso Data Tab data column\n",
    "df_conso[\"Tab data\"] = df_conso[\"Tab data\"].astype(str)  # Convert to string to avoid errors\n",
    "unique_teams = df_conso[\"Tab data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = str(row[\"Tab data\"]).split(\",\")  # Convert to string before splitting\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Handle records with missing or non-numeric PSIDs\n",
    "invalid_psid_records = df_conso[df_conso[\"PSID\"].isna() | ~df_conso[\"PSID\"].astype(str).str.isnumeric()]\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n",
    "    invalid_emails.to_excel(writer, sheet_name=\"Invalid Emails\", index=False)\n",
    "    invalid_psid_records.to_excel(writer, sheet_name=\"Invalid PSIDs\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"your_excel_file.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load necessary sheets\n",
    "df_conso = xl.parse(\"Conso Data\")\n",
    "df_girs = xl.parse(\"GIRS\")\n",
    "df_tier = xl.parse(\"Tier_Data\")\n",
    "df_ttrl = xl.parse(\"TTRL_Data\")\n",
    "df_pdmr = xl.parse(\"PDMR_Data\")\n",
    "\n",
    "# Remove extra spaces & standardize case\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "df_conso = clean_dataframe(df_conso)\n",
    "df_girs = clean_dataframe(df_girs)\n",
    "df_tier = clean_dataframe(df_tier)\n",
    "df_ttrl = clean_dataframe(df_ttrl)\n",
    "df_pdmr = clean_dataframe(df_pdmr)\n",
    "\n",
    "# Extract unique PSIDs\n",
    "unique_psids = df_conso[[\"PSID\", \"Resource Name\", \"Email\"]].drop_duplicates()\n",
    "\n",
    "# Merge GIRS Current Status\n",
    "unique_psids = unique_psids.merge(df_girs[[\"PSID\", \"Role\"]], on=\"PSID\", how=\"left\")\n",
    "unique_psids.rename(columns={\"Role\": \"GIRS Current Status\"}, inplace=True)\n",
    "\n",
    "# Merge Tier1 & TTRL status\n",
    "unique_psids[\"Tier1\"] = unique_psids[\"PSID\"].isin(df_tier[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "unique_psids[\"TTRL\"] = unique_psids[\"PSID\"].isin(df_ttrl[\"PSID\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Merge PDMR status\n",
    "unique_psids[\"PDMR\"] = unique_psids[\"Resource Name\"].isin(df_pdmr[\"Resource Name\"]).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "# Extract unique team names from Conso Data Tab Data column\n",
    "unique_teams = df_conso[\"Tab Data\"].str.split(\",\").explode().str.strip().unique()\n",
    "\n",
    "# Initialize team columns with N/A\n",
    "for team in unique_teams:\n",
    "    unique_psids[team] = \"N/A\"\n",
    "\n",
    "# Update team status based on Conso Data\n",
    "for _, row in df_conso.iterrows():\n",
    "    psid = row[\"PSID\"]\n",
    "    status = row[\"Status\"]\n",
    "    teams = row[\"Tab Data\"].split(\",\")\n",
    "    for team in teams:\n",
    "        team = team.strip()\n",
    "        unique_psids.loc[unique_psids[\"PSID\"] == psid, team] = status\n",
    "\n",
    "# Save the final processed data\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace') as writer:\n",
    "    unique_psids.to_excel(writer, sheet_name=\"Processed Data\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b42ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"your_file.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read required sheets\n",
    "df_conso = pd.read_excel(xls, sheet_name='Conso Data')\n",
    "df_girs = pd.read_excel(xls, sheet_name=\"GIRS Extract_20 Mar'25\")\n",
    "df_tier1 = pd.read_excel(xls, sheet_name=\"TIER1_5 Mar'25\")\n",
    "df_ttrl = pd.read_excel(xls, sheet_name=\"TTRL_3 Mar'25\")\n",
    "df_pdmr = pd.read_excel(xls, sheet_name=\"PDMR_1Jan'25\", header=None, names=['PDMR'])\n",
    "\n",
    "# Data Cleaning & Standardization\n",
    "df_conso['PSID'] = df_conso['PSID'].astype(str).str.lstrip('0')\n",
    "df_conso['Resource name'] = df_conso['Resource name'].str.title()\n",
    "df_pdmr['PDMR'] = df_pdmr['PDMR'].str.lower()\n",
    "\n",
    "df_girs['Employee ID'] = df_girs['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_girs['Insider Name'] = df_girs['Insider Name'].str.title()\n",
    "\n",
    "df_tier1['Employee ID'] = df_tier1['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_tier1['Insider Name'] = df_tier1['Insider Name'].str.title()\n",
    "\n",
    "df_ttrl['Employee ID'] = df_ttrl['Employee ID'].astype(str).str.lstrip('0')\n",
    "df_ttrl['Insider Name'] = df_ttrl['Insider Name'].str.title()\n",
    "\n",
    "# Merge Conso Data with GIRS Extract\n",
    "df_merged = df_conso.merge(df_girs, left_on='PSID', right_on='Employee ID', how='left')\n",
    "\n",
    "# Identify status updates\n",
    "final_records = []\n",
    "for _, row in df_merged.iterrows():\n",
    "    psid = row['PSID']\n",
    "    resource_name = row['Resource name']\n",
    "    email = row['Email']\n",
    "    original_status = row['Role'] if pd.notna(row['Role']) else 'Not in GIRS'\n",
    "    updated_status = row['Status']\n",
    "    comments = []\n",
    "    \n",
    "    if row['TIER1'] == 'Yes' or row['TTRL'] == 'Yes' or resource_name.lower() in df_pdmr['PDMR'].values:\n",
    "        comments.append(\"Employee in TIER1/TTRL/PDMR\")\n",
    "    \n",
    "    if original_status == 'Non-Core' and updated_status == 'DEL':\n",
    "        updated_status = 'Inactive Insider'\n",
    "        comments.append(\"Non-Core user marked for deletion\")\n",
    "    \n",
    "    if original_status == 'Inactive Insider' and updated_status == 'ADD':\n",
    "        updated_status = 'Non-Core'\n",
    "        comments.append(\"Inactive Insider reactivated as Non-Core\")\n",
    "    \n",
    "    final_records.append([psid, resource_name, email, original_status, updated_status, ', '.join(comments)])\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_records, columns=['PSID', 'Resource name', 'Email', 'Original Status', 'Updated Status', 'Comments'])\n",
    "\n",
    "# Export to Excel\n",
    "final_df.to_excel(\"Processed_GIRS_Data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_girs_data(file_path):\n",
    "    # Load required sheets\n",
    "    conso_data = pd.read_excel(file_path, sheet_name='Conso Data')\n",
    "    girs_data = pd.read_excel(file_path, sheet_name=\"GIRS Extract_20 Mar'25\")\n",
    "    tier1_data = pd.read_excel(file_path, sheet_name='TIER1_5 Mar'25')\n",
    "    ttrl_data = pd.read_excel(file_path, sheet_name='TTRL_3 Mar'25')\n",
    "    pdmr_data = pd.read_excel(file_path, sheet_name='PDMR_1Jan'25', header=None)  # PDMR has one column\n",
    "    \n",
    "    # Standardizing column names\n",
    "    conso_data.rename(columns={'Resource name': 'Insider Name'}, inplace=True)\n",
    "    girs_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    tier1_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    ttrl_data.rename(columns={'Employee ID': 'PSID', 'Employee Email': 'Email'}, inplace=True)\n",
    "    \n",
    "    # Convert 'PDMR' column to lowercase for matching\n",
    "    pdmr_data[0] = pdmr_data[0].str.lower()\n",
    "    \n",
    "    # Remove leading zeros from PSID\n",
    "    conso_data['PSID'] = conso_data['PSID'].astype(str).str.lstrip('0')\n",
    "    girs_data['PSID'] = girs_data['PSID'].astype(str).str.lstrip('0')\n",
    "    tier1_data['PSID'] = tier1_data['PSID'].astype(str).str.lstrip('0')\n",
    "    ttrl_data['PSID'] = ttrl_data['PSID'].astype(str).str.lstrip('0')\n",
    "    \n",
    "    # Capitalize Insider Names\n",
    "    conso_data['Insider Name'] = conso_data['Insider Name'].str.upper()\n",
    "    girs_data['Insider Name'] = girs_data['Insider Name'].str.upper()\n",
    "    tier1_data['Insider Name'] = tier1_data['Insider Name'].str.upper()\n",
    "    ttrl_data['Insider Name'] = ttrl_data['Insider Name'].str.upper()\n",
    "    \n",
    "    # Merge GIRS Current Status into Conso Data\n",
    "    merged_data = conso_data.merge(girs_data[['PSID', 'Insider Name', 'Email', 'Role']], \n",
    "                                   on=['PSID', 'Insider Name'], how='left')\n",
    "    merged_data.rename(columns={'Role': 'Original Status in GIRS'}, inplace=True)\n",
    "    \n",
    "    # Identify if PSID is present in Tier1, TTRL\n",
    "    merged_data['Tier1 Flag'] = merged_data['PSID'].isin(tier1_data['PSID']).map({True: 'Yes', False: 'No'})\n",
    "    merged_data['TTRL Flag'] = merged_data['PSID'].isin(ttrl_data['PSID']).map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # Identify if Insider Name matches with PDMR data\n",
    "    merged_data['PDMR Flag'] = merged_data['Insider Name'].str.lower().isin(pdmr_data[0]).map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # Determine Updated Status Request based on rules\n",
    "    def determine_updated_status(row):\n",
    "        if row['Status'] == 'ADD':\n",
    "            return 'Non-Core' if row['Original Status in GIRS'] == 'Inactive Insider' else 'ADD'\n",
    "        elif row['Status'] == 'DEL':\n",
    "            return 'Inactive Insider' if row['Original Status in GIRS'] == 'Non-Core' else 'DEL'\n",
    "        elif row['Status'] == 'Cur':\n",
    "            return row['Original Status in GIRS']  # Keep as is\n",
    "        return row['Status']\n",
    "    \n",
    "    merged_data['Updated Status Request'] = merged_data.apply(determine_updated_status, axis=1)\n",
    "    \n",
    "    # Identify Request Type (New/Updated Request)\n",
    "    merged_data['Request Type'] = merged_data['Original Status in GIRS'].apply(\n",
    "        lambda x: 'New Request' if pd.isna(x) else 'Updated Request'\n",
    "    )\n",
    "    \n",
    "    # Generate Comments Column\n",
    "    def generate_comment(row):\n",
    "        comments = []\n",
    "        if row['Status'] == 'ADD' and row['Updated Status Request'] == 'ADD':\n",
    "            comments.append('Fresh Addition')\n",
    "        if row['Status'] == 'DEL' and row['Updated Status Request'] == 'Inactive Insider':\n",
    "            comments.append('Converted to Inactive Insider')\n",
    "        if row['Status'] == 'ADD' and row['Updated Status Request'] == 'Non-Core':\n",
    "            comments.append('Reactivated to Non-Core')\n",
    "        if row['Tier1 Flag'] == 'Yes':\n",
    "            comments.append('Present in Tier1')\n",
    "        if row['TTRL Flag'] == 'Yes':\n",
    "            comments.append('Present in TTRL')\n",
    "        if row['PDMR Flag'] == 'Yes':\n",
    "            comments.append('Listed in PDMR')\n",
    "        return '; '.join(comments)\n",
    "    \n",
    "    merged_data['Comment'] = merged_data.apply(generate_comment, axis=1)\n",
    "    \n",
    "    # Select final required columns\n",
    "    final_columns = ['PSID', 'Insider Name', 'Email', 'Original Status in GIRS',\n",
    "                     'Updated Status Request', 'Request Type', 'Comment']\n",
    "    final_data = merged_data[final_columns]\n",
    "    \n",
    "    # Save output to a new Excel file\n",
    "    output_file = 'Final_Consolidated_Data.xlsx'\n",
    "    final_data.to_excel(output_file, index=False)\n",
    "    print(f'Final consolidated data saved as {output_file}')\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'GIRS_Processing.xlsx'  # Update this with your actual file path\n",
    "final_output = process_girs_data(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
