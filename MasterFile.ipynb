{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb720fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Employee ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-785e15639cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0mmds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Global Career Band\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"MD\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_row\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Employee ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmd_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m# Step 7: Create final DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-785e15639cf3>\u001b[0m in \u001b[0;36mtrace\u001b[1;34m(emp_id, md_info, gcb3_info, rm_info)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Basic employee info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;34m\"Employee ID\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0memp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Employee ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;34m\"Employee Name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0memp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Employee Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;34m\"Employee Email\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0memp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Employee Business Email Address\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Employee ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input details\n",
    "input_file = 'GHA.xlsx'\n",
    "sheet_name = 'Headcount - Employee Detail'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(input_file, sheet_name=sheet_name)\n",
    "\n",
    "# Ensure proper types\n",
    "df['Employee ID'] = df['Employee ID'].astype(str)\n",
    "df['Entity Manager Employee ID'] = df['Entity Manager Employee ID'].astype(str)\n",
    "df['Global Career Band'] = df['Global Career Band'].astype(str)\n",
    "\n",
    "# Function to trace reporting chain\n",
    "def trace_hierarchy(emp_id):\n",
    "    visited = set()\n",
    "    md_info = gcb3_info = rep_mgr_info = None\n",
    "    current_id = emp_id\n",
    "\n",
    "    while True:\n",
    "        row = df[df['Employee ID'] == current_id]\n",
    "        if row.empty or current_id in visited:\n",
    "            break\n",
    "\n",
    "        visited.add(current_id)\n",
    "        row = row.iloc[0]\n",
    "        mgr_id = row['Entity Manager Employee ID']\n",
    "        gcb = row['Global Career Band']\n",
    "\n",
    "        # Assign roles based on GCB\n",
    "        if gcb == 'MD' and md_info is None:\n",
    "            md_info = row\n",
    "        elif gcb == '3' and gcb3_info is None:\n",
    "            gcb3_info = row\n",
    "        elif rep_mgr_info is None:\n",
    "            rep_mgr_info = row\n",
    "\n",
    "        current_id = mgr_id\n",
    "\n",
    "    return md_info, gcb3_info, rep_mgr_info\n",
    "\n",
    "# Prepare rows\n",
    "records = []\n",
    "for _, emp in df.iterrows():\n",
    "    emp_id = emp['Employee ID']\n",
    "    md, gcb3, rep_mgr = trace_hierarchy(emp['Entity Manager Employee ID'])\n",
    "\n",
    "    records.append({\n",
    "        # MD details\n",
    "        \"MD Employee ID\": md['Employee ID'] if md is not None else \"\",\n",
    "        \"MD Name\": md['Employee Name'] if md is not None else \"\",\n",
    "        \"MD Email\": md['Employee Business Email Address'] if md is not None else \"\",\n",
    "\n",
    "        # GCB3 details\n",
    "        \"GCB3 Employee ID\": gcb3['Employee ID'] if gcb3 is not None else \"\",\n",
    "        \"GCB3 Name\": gcb3['Employee Name'] if gcb3 is not None else \"\",\n",
    "        \"GCB3 Email\": gcb3['Employee Business Email Address'] if gcb3 is not None else \"\",\n",
    "\n",
    "        # Reporting Manager (GCB3 or GCB4)\n",
    "        \"Reporting Manager ID\": rep_mgr['Employee ID'] if rep_mgr is not None else \"\",\n",
    "        \"Reporting Manager Name\": rep_mgr['Employee Name'] if rep_mgr is not None else \"\",\n",
    "        \"Reporting Manager Email\": rep_mgr['Employee Business Email Address'] if rep_mgr is not None else \"\",\n",
    "\n",
    "        # Actual employee details\n",
    "        \"Employee ID\": emp['Employee ID'],\n",
    "        \"Employee Name\": emp['Employee Name'],\n",
    "        \"Employee Email\": emp['Employee Business Email Address'],\n",
    "        \"Employee GCB\": emp['Global Career Band'],\n",
    "    })\n",
    "\n",
    "# Final DataFrame\n",
    "output_df = pd.DataFrame(records)\n",
    "\n",
    "# Save to Excel\n",
    "output_df.to_excel(\"GHA_Hierarchy_Output.xlsx\", index=False)\n",
    "print(\"Hierarchy file saved as 'GHA_Hierarchy_Output.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564c28f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame:\n",
      "       A      B      C           D           E\n",
      "0   5000   1000  20000         1.0        -1.0\n",
      "1  15000   8000   5000  found data         1.0\n",
      "2   7000  12000   8000         inf  found data\n",
      "3   3000   4000   6000         0.0         1.0\n",
      "4  12000  12200    900         2.0  found data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataframe\n",
    "data = {\n",
    "    'A': [5000, 15000, 7000, 3000,12000],\n",
    "    'B': [1000, 8000, 12000, 4000,12200],\n",
    "    'C': [20000, 5000, 8000, 6000,900],\n",
    "    'D': [1, -1, np.inf, 0,2],\n",
    "    'E': [-1, 1, np.inf, 1,-np.inf]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# List of columns to check for > 10,000\n",
    "cols = ['A', 'B', 'C']\n",
    "\n",
    "# Corresponding list of columns to check specific values\n",
    "cols_to_check = ['D', 'E', 'A']  # Assuming correspondence is by index\n",
    "\n",
    "# Specific values to check\n",
    "specific_values = [1, -1, np.inf, -np.inf]\n",
    "\n",
    "# Iterate through each column pair by index\n",
    "for i, col in enumerate(cols):\n",
    "#     if col in df.columns and cols_to_check[i] in df.columns:\n",
    "        # Get rows where the value in the current column is > 10,000\n",
    "    high_value_rows = df[col] > 10000\n",
    "\n",
    "    # Check the corresponding column for specific values\n",
    "    valid_rows = df.loc[high_value_rows, cols_to_check[i]].isin(specific_values)\n",
    "\n",
    "    # Update the corresponding column value to \"found data\"\n",
    "    df.loc[high_value_rows & valid_rows, cols_to_check[i]] = \"found data\"\n",
    "\n",
    "# Results\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for updated, new, and demised records\n",
    "updated_df = []\n",
    "new_df = []\n",
    "demised_records = []\n",
    "\n",
    "# Iterate through the current month's data\n",
    "for index, current_record in current_df.iterrows():\n",
    "    # Generate the combined Emp_Pos_ID for current and next data\n",
    "    current_emp_pos = current_record[\"Emp_Pos_ID\"]\n",
    "    next_record = next_df[next_df[\"Emp_Pos_ID\"] == current_emp_pos]\n",
    "\n",
    "    # Case 1: Emp_Pos_ID exists in both months\n",
    "    if not next_record.empty:\n",
    "        next_record = next_record.iloc[0]\n",
    "\n",
    "        # Initialize the change description list\n",
    "        change_desc = []\n",
    "\n",
    "        # Compare columns for changes\n",
    "        for col in comparison_columns:\n",
    "            current_value = current_record[col]\n",
    "            next_value = next_record[col]\n",
    "\n",
    "            # Case 1.1: Values differ between current and next\n",
    "            if pd.notna(current_value) and pd.notna(next_value) and current_value != next_value:\n",
    "                if col == 'BF Level 3 Name':\n",
    "                    change_desc.append('Target Transfer. Internal Movement')\n",
    "                elif col == 'BF Level 4 Name':\n",
    "                    change_desc.append('Internal Movement in Finance')\n",
    "                else:\n",
    "                    change_desc.append(f\"{col} changed\")\n",
    "\n",
    "            # Case 1.2: Value is blank/missing in current but exists in next\n",
    "            elif (pd.isna(current_value) or current_value == \"\") and pd.notna(next_value):\n",
    "                change_desc.append(f\"{col} new value added\")\n",
    "\n",
    "        # Append updated values (next_record) to updated_df if any differences are found\n",
    "        if change_desc:\n",
    "            updated_row = next_record.to_dict()  # Use updated (next month's) values\n",
    "            updated_row.update({\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"; \".join(change_desc),\n",
    "                \"Source\": \"GHA\",\n",
    "            })\n",
    "            updated_df.append(updated_row)\n",
    "\n",
    "    # Case 2: Emp_Pos_ID is in the current month but not in the next month\n",
    "    elif next_record.empty:\n",
    "        # Check if Employee ID exists in the next month with a different Position ID\n",
    "        employee_matches = next_df[next_df[\"Employee ID\"] == current_record[\"Employee ID\"]]\n",
    "        if not employee_matches.empty:\n",
    "            # Employee exists but with a different Position ID (Mobility)\n",
    "            new_pos_id = employee_matches.iloc[0][\"Position ID\"]\n",
    "            new_emp_pos_id = employee_matches.iloc[0][\"Emp_Pos_ID\"]\n",
    "            updated_row = employee_matches.iloc[0].to_dict()  # Use updated (next month's) values\n",
    "            updated_row.update({\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": f\"Mobility: Position ID changed to {new_pos_id} (New Emp_Pos_ID: {new_emp_pos_id})\",\n",
    "                \"Source\": \"GHA\",\n",
    "            })\n",
    "            updated_df.append(updated_row)\n",
    "        else:\n",
    "            # Check if Position ID exists in next month's Open Positions file\n",
    "            if current_record[\"Position ID\"] not in open_pos_file[\"Position ID\"].values:\n",
    "                demised_records.append({\n",
    "                    \"Position ID\": current_record[\"Position ID\"],\n",
    "                    \"Month Demised\": next_month,\n",
    "                    \"Change Description\": \"Position Demised\",\n",
    "                })\n",
    "            else:\n",
    "                # Employee ID does not exist in the next month (Movement Out)\n",
    "                updated_row = current_record.to_dict()\n",
    "                updated_row.update({\n",
    "                    \"Month Changed\": month,\n",
    "                    \"Change Description\": \"Leaver/Movement Out\",\n",
    "                    \"Source\": \"GHA\",\n",
    "                })\n",
    "                updated_df.append(updated_row)\n",
    "\n",
    "# Case 3: Check for new records in the next month\n",
    "for index, next_record in next_df.iterrows():\n",
    "    next_emp_pos = next_record[\"Emp_Pos_ID\"]\n",
    "    current_record = current_df[current_df[\"Emp_Pos_ID\"] == next_emp_pos]\n",
    "\n",
    "    # If Emp_Pos_ID is not in the current month, it's a new record\n",
    "    if current_record.empty:\n",
    "        new_row = next_record.to_dict()\n",
    "        new_row.update({\n",
    "            \"Month Added\": month,\n",
    "            \"Source\": \"GHA\",\n",
    "            \"Change Description\": \"New Record\",\n",
    "        })\n",
    "        new_df.append(new_row)\n",
    "\n",
    "# Convert updated_df, new_df, and demised_records to DataFrames\n",
    "updated_df = pd.DataFrame(updated_df)\n",
    "new_df = pd.DataFrame(new_df)\n",
    "demised_records = pd.DataFrame(demised_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Emp_Pos_ID for both current and previous month's GHA data\n",
    "current_df[\"Emp_Pos_ID\"] = current_df[\"Employee ID\"].astype(str) + \"_\" + current_df[\"Position ID\"].astype(str)\n",
    "prev_month_df[\"Emp_Pos_ID\"] = prev_month_df[\"Employee ID\"].astype(str) + \"_\" + prev_month_df[\"Position ID\"].astype(str)\n",
    "\n",
    "# Step 1: Identify new records\n",
    "def is_new_record(row):\n",
    "    pos_id = row[\"Position ID\"]\n",
    "    emp_id = row[\"Employee ID\"]\n",
    "    emp_pos_id = row[\"Emp_Pos_ID\"]\n",
    "    \n",
    "    # Check if Position ID exists in the previous month's data\n",
    "    if pos_id not in prev_month_df[\"Position ID\"].values:\n",
    "        return True  # New Position ID = New record\n",
    "    \n",
    "    # If Position ID exists, check if Emp_Pos_ID is new\n",
    "    if emp_pos_id not in prev_month_df[\"Emp_Pos_ID\"].values:\n",
    "        # Check if Employee ID is also new (not in previous month)\n",
    "        if emp_id not in prev_month_df[\"Employee ID\"].values:\n",
    "            return True  # New Employee ID + Position ID = New record\n",
    "    \n",
    "    return False\n",
    "\n",
    "current_df[\"Is New Record\"] = current_df.apply(is_new_record, axis=1)\n",
    "\n",
    "# Step 2: Identify mobility\n",
    "def is_mobility(row):\n",
    "    pos_id = row[\"Position ID\"]\n",
    "    emp_id = row[\"Employee ID\"]\n",
    "    \n",
    "    # Check if Position ID exists in the previous month's data\n",
    "    if pos_id in prev_month_df[\"Position ID\"].values:\n",
    "        # Check if Employee ID has changed\n",
    "        prev_emp_id = prev_month_df[prev_month_df[\"Position ID\"] == pos_id][\"Employee ID\"].values[0]\n",
    "        if emp_id != prev_emp_id:\n",
    "            # Check if Employee ID exists elsewhere in the previous month's data\n",
    "            if emp_id in prev_month_df[\"Employee ID\"].values:\n",
    "                return True  # Mobility: Employee moved to a new Position ID\n",
    "    \n",
    "    return False\n",
    "\n",
    "current_df[\"Is Mobility\"] = current_df.apply(is_mobility, axis=1)\n",
    "\n",
    "# Step 3: Finalize master_df\n",
    "current_df[\"Status\"] = current_df.apply(\n",
    "    lambda row: \"New Record\" if row[\"Is New Record\"] else \"Mobility\" if row[\"Is Mobility\"] else \"Existing\", axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the current month's data\n",
    "for index, current_record in current_df.iterrows():\n",
    "    # Generate the combined Emp_Pos_ID for current and next data\n",
    "    current_emp_pos = current_record[\"Emp_Pos_ID\"]\n",
    "    next_record = next_df[next_df[\"Emp_Pos_ID\"] == current_emp_pos]\n",
    "\n",
    "    # If exact Emp_Pos_ID doesn't exist in the next month\n",
    "    if next_record.empty:\n",
    "        # Check if the Employee ID exists in the next month with a different Position ID\n",
    "        employee_matches = next_df[next_df[\"Employee ID\"] == current_record[\"Employee ID\"]]\n",
    "        if not employee_matches.empty:\n",
    "            # Employee exists but with a different Position ID\n",
    "            new_pos_id = employee_matches.iloc[0][\"Position ID\"]\n",
    "            new_emp_pos_id = employee_matches.iloc[0][\"Emp_Pos_ID\"]\n",
    "            changes.append({\n",
    "                \"Position ID\": current_record[\"Position ID\"],\n",
    "                \"Employee ID\": current_record[\"Employee ID\"],\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": f\"Mobility: Position ID changed to {new_pos_id} (New Emp_Pos_ID: {new_emp_pos_id})\",\n",
    "                \"Source\": \"GHA\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Employee ID does not exist in the next month (Movement Out)\n",
    "        changes.append({\n",
    "            \"Position ID\": current_record[\"Position ID\"],\n",
    "            \"Employee ID\": current_record[\"Employee ID\"],\n",
    "            \"Month Changed\": month,\n",
    "            \"Change Description\": \"Employee ID does not exist, movement out\",\n",
    "            \"Source\": \"GHA\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Convert to a single next record for further comparison\n",
    "    next_record = next_record.iloc[0]\n",
    "\n",
    "    # Initialize the change description list\n",
    "    change_desc = []\n",
    "\n",
    "    # Compare other important columns for changes\n",
    "    for col in comparison_columns:\n",
    "        current_value = current_record[col]\n",
    "        next_value = next_record[col]\n",
    "\n",
    "        # Case 1: Values differ between current and next\n",
    "        if pd.notna(current_value) and pd.notna(next_value) and current_value != next_value:\n",
    "            change_desc.append(f\"{col} changed\")\n",
    "\n",
    "        # Case 2: Value is blank/missing in current but exists in next\n",
    "        elif (pd.isna(current_value) or current_value == \"\") and pd.notna(next_value):\n",
    "            change_desc.append(f\"{col} new value added\")\n",
    "\n",
    "    # Append to changes list if any differences are found\n",
    "    if change_desc:\n",
    "        changes.append({\n",
    "            \"Position ID\": current_record[\"Position ID\"],\n",
    "            \"Employee ID\": current_record[\"Employee ID\"],\n",
    "            \"Month Changed\": month,\n",
    "            \"Change Description\": \"; \".join(change_desc),\n",
    "            \"Source\": \"GHA\",\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the entire row to changes_df when changes are detected\n",
    "if current_record[\"Employee ID\"] == next_record[\"Employee ID\"] and current_record[\"Position ID\"] != next_record[\"Position ID\"]:\n",
    "    # Add the entire row from current_df with change-specific details\n",
    "    change_row = current_record.copy()  # Copy the entire current record row\n",
    "    change_row[\"Position ID (New)\"] = next_record[\"Position ID\"]  # Add specific info for the change\n",
    "    change_row[\"Change Description\"] = \"Mobility: Position ID changed\"  # Description for the change\n",
    "    change_row[\"Month Changed\"] = month  # Add month of the change\n",
    "    change_row[\"Change Type\"] = \"Mobility\"  # Specify change type\n",
    "    change_row[\"Source\"] = \"GHA\"  # Specify source of the change\n",
    "    changes_df = changes_df.append(change_row, ignore_index=True)  # Append to changes_df\n",
    "\n",
    "    \n",
    "    \n",
    "    # Standardize columns in changes_df before concatenating with master_df\n",
    "for col in master_df.columns:\n",
    "    if col not in changes_df.columns:\n",
    "        changes_df[col] = None  # Add missing columns with default value None\n",
    "\n",
    "# Drop extra columns that are not in master_df\n",
    "extra_cols = [col for col in changes_df.columns if col not in master_df.columns]\n",
    "changes_df.drop(columns=extra_cols, inplace=True)\n",
    "\n",
    "# Concatenate GHA and Open Position changes\n",
    "final_changes_df = pd.concat([gha_changes_df, open_pos_changes_df], ignore_index=True)\n",
    "\n",
    "\n",
    "for col in master_df.columns:\n",
    "    if col not in gha_changes_df.columns:\n",
    "        gha_changes_df[col] = None\n",
    "extra_cols = [col for col in gha_changes_df.columns if col not in master_df.columns]\n",
    "gha_changes_df.drop(columns=extra_cols, inplace=True)\n",
    "\n",
    "\n",
    "for col in master_df.columns:\n",
    "    if col not in open_pos_changes_df.columns:\n",
    "        open_pos_changes_df[col] = None\n",
    "extra_cols = [col for col in open_pos_changes_df.columns if col not in master_df.columns]\n",
    "open_pos_changes_df.drop(columns=extra_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad00a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the current month's data\n",
    "for index, current_record in current_df.iterrows():\n",
    "    # Generate the combined emp_pos_ID for current and next data\n",
    "    current_emp_pos = current_record[\"emp_pos_ID\"]\n",
    "    next_record = next_df[next_df[\"emp_pos_ID\"] == current_emp_pos]\n",
    "\n",
    "    # If exact emp_pos_ID doesn't exist in the next month\n",
    "    if next_record.empty:\n",
    "        # Check if the Employee ID exists but with a different Position ID\n",
    "        employee_matches = next_df[next_df[\"Employee ID\"] == current_record[\"Employee ID\"]]\n",
    "        if not employee_matches.empty:\n",
    "            # Mobility case: Employee has changed Position ID\n",
    "            new_pos_id = employee_matches.iloc[0][\"Position ID\"]\n",
    "            changes.append({\n",
    "                \"Position ID\": current_record[\"Position ID\"],\n",
    "                \"Employee ID\": current_record[\"Employee ID\"],\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": f\"Mobility: Position ID changed to {new_pos_id}\",\n",
    "                \"Source\": \"GHA\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Employee ID does not exist in the next month\n",
    "        changes.append({\n",
    "            \"Position ID\": current_record[\"Position ID\"],\n",
    "            \"Employee ID\": current_record[\"Employee ID\"],\n",
    "            \"Month Changed\": month,\n",
    "            \"Change Description\": \"Employee ID does not exist, movement out\",\n",
    "            \"Source\": \"GHA\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Convert to a single next record for further comparison\n",
    "    next_record = next_record.iloc[0]\n",
    "\n",
    "    # Initialize the change description list\n",
    "    change_desc = []\n",
    "\n",
    "    # Compare other important columns for changes\n",
    "    for col in comparison_columns:\n",
    "        if pd.notna(current_record[col]) and pd.notna(next_record[col]) and current_record[col] != next_record[col]:\n",
    "            change_desc.append(f\"{col} changed\")\n",
    "\n",
    "    # Append to changes list if any differences are found\n",
    "    if change_desc:\n",
    "        changes.append({\n",
    "            \"Position ID\": current_record[\"Position ID\"],\n",
    "            \"Employee ID\": current_record[\"Employee ID\"],\n",
    "            \"Month Changed\": month,\n",
    "            \"Change Description\": \"; \".join(change_desc),\n",
    "            \"Source\": \"GHA\",\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df, source_type):\n",
    "    # Standardize column names\n",
    "    df = df.rename(columns={\n",
    "        \"Position Number\": \"Position ID\",\n",
    "        \"Employee Global Career Band\": \"Global Career Band\"  # For open positions\n",
    "    })\n",
    "    \n",
    "    # Clean Position ID and Employee ID\n",
    "    if \"Position ID\" in df.columns:\n",
    "        df[\"Position ID\"] = df[\"Position ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    if \"Employee ID\" in df.columns:\n",
    "        df[\"Employee ID\"] = df[\"Employee ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Add missing columns if not present\n",
    "    required_cols = [\"Position ID\", \"Employee ID\"]  # Add more as needed\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "def find_changes_gha(current_df, next_df, cols_to_check, month):\n",
    "    changes = []\n",
    "    \n",
    "    # Standardize column names\n",
    "    current_df = standardize_columns(current_df, \"GHA\")\n",
    "    next_df = standardize_columns(next_df, \"GHA\")\n",
    "    \n",
    "    # Concatenate Employee ID and Position ID to create unique identifiers\n",
    "    current_df[\"Emp_Pos_ID\"] = current_df[\"Employee ID\"] + \"_\" + current_df[\"Position ID\"]\n",
    "    next_df[\"Emp_Pos_ID\"] = next_df[\"Employee ID\"] + \"_\" + next_df[\"Position ID\"]\n",
    "\n",
    "    # Compare based on Emp_Pos_ID\n",
    "    current_set = set(current_df[\"Emp_Pos_ID\"])\n",
    "    next_set = set(next_df[\"Emp_Pos_ID\"])\n",
    "    \n",
    "    # Identify records in current_df but not in next_df\n",
    "    for emp_pos_id in current_set - next_set:\n",
    "        record = current_df[current_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        employee_id = record[\"Employee ID\"]\n",
    "        \n",
    "        # Check if the Employee ID exists in next_df\n",
    "        if employee_id not in next_df[\"Employee ID\"].values:\n",
    "            changes.append({\n",
    "                \"Position ID\": record[\"Position ID\"],\n",
    "                \"Employee ID\": employee_id,\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"Employee ID does not exist, movement out\",\n",
    "                \"Source\": \"GHA\"\n",
    "            })\n",
    "    \n",
    "    # Identify records in both but with changes in other columns\n",
    "    common_ids = current_set & next_set\n",
    "    for emp_pos_id in common_ids:\n",
    "        current_record = current_df[current_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        next_record = next_df[next_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        \n",
    "        # Check for changes in important columns\n",
    "        change_desc = []\n",
    "        for col in cols_to_check:\n",
    "            if col in current_record and col in next_record:\n",
    "                if current_record[col] != next_record[col]:\n",
    "                    change_desc.append(f\"{col} changed\")\n",
    "        \n",
    "        if change_desc:\n",
    "            changes.append({\n",
    "                \"Position ID\": current_record[\"Position ID\"],\n",
    "                \"Employee ID\": current_record[\"Employee ID\"],\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"; \".join(change_desc),\n",
    "                \"Source\": \"GHA\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(changes)\n",
    "\n",
    "def find_changes_open_positions(current_df, next_df, cols_to_check, month):\n",
    "    changes = []\n",
    "    \n",
    "    # Standardize column names for open positions\n",
    "    current_df = standardize_columns(current_df, \"Open Positions\")\n",
    "    next_df = standardize_columns(next_df, \"Open Positions\")\n",
    "    \n",
    "    # Compare based on Position ID\n",
    "    current_set = set(current_df[\"Position ID\"])\n",
    "    next_set = set(next_df[\"Position ID\"])\n",
    "    \n",
    "    # Identify records in current_df but not in next_df\n",
    "    for pos_id in current_set - next_set:\n",
    "        record = current_df[current_df[\"Position ID\"] == pos_id].iloc[0]\n",
    "        changes.append({\n",
    "            \"Position ID\": pos_id,\n",
    "            \"Month Changed\": month,\n",
    "            \"Change Description\": \"Position ID removed\",\n",
    "            \"Source\": \"Open Positions\"\n",
    "        })\n",
    "    \n",
    "    # Identify records in both but with changes in other columns\n",
    "    common_ids = current_set & next_set\n",
    "    for pos_id in common_ids:\n",
    "        current_record = current_df[current_df[\"Position ID\"] == pos_id].iloc[0]\n",
    "        next_record = next_df[next_df[\"Position ID\"] == pos_id].iloc[0]\n",
    "        \n",
    "        # Check for changes in important columns\n",
    "        change_desc = []\n",
    "        for col in cols_to_check:\n",
    "            if col in current_record and col in next_record:\n",
    "                if current_record[col] != next_record[col]:\n",
    "                    change_desc.append(f\"{col} changed\")\n",
    "        \n",
    "        if change_desc:\n",
    "            changes.append({\n",
    "                \"Position ID\": pos_id,\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"; \".join(change_desc),\n",
    "                \"Source\": \"Open Positions\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(changes)\n",
    "\n",
    "def process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos):\n",
    "    changes_df = pd.DataFrame()\n",
    "    \n",
    "    months = list(monthly_files.keys())\n",
    "    for i in range(len(months) - 1):\n",
    "        current_month = months[i]\n",
    "        next_month = months[i + 1]\n",
    "        \n",
    "        gha_current_file, open_pos_current_file = monthly_files[current_month]\n",
    "        gha_next_file, open_pos_next_file = monthly_files[next_month]\n",
    "        \n",
    "        # Read files (assuming single sheet for simplicity)\n",
    "        gha_current_df = pd.read_excel(gha_current_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        gha_next_df = pd.read_excel(gha_next_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        open_pos_current_df = pd.read_excel(open_pos_current_file)\n",
    "        open_pos_next_df = pd.read_excel(open_pos_next_file)\n",
    "        \n",
    "        # Process GHA\n",
    "        gha_changes = find_changes_gha(gha_current_df, gha_next_df, cols_to_check_gha, next_month)\n",
    "        changes_df = pd.concat([changes_df, gha_changes], ignore_index=True)\n",
    "        \n",
    "        # Process Open Positions (use your existing logic here)\n",
    "        open_pos_changes = find_changes_open_positions(open_pos_current_df, open_pos_next_df, cols_to_check_open_pos, next_month)\n",
    "        changes_df = pd.concat([changes_df, open_pos_changes], ignore_index=True)\n",
    "    \n",
    "    return changes_df\n",
    "\n",
    "# Example usage\n",
    "monthly_files = {\n",
    "    \"Jan 24\": (\"gha_jan.xlsx\", \"open_pos_jan.xlsx\"),\n",
    "    \"Feb 24\": (\"gha_feb.xlsx\", \"open_pos_feb.xlsx\"),\n",
    "    # Add other months...\n",
    "}\n",
    "\n",
    "cols_to_check_gha = [\"Global Career Band\", \"Employee FTE\", \"Employee Type\", \"Work Location City\"]\n",
    "cols_to_check_open_pos = [\"Global Career Band\", \"Work Location City\"]\n",
    "\n",
    "changes_df = process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos)\n",
    "changes_df.to_excel(\"changes_output.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19063769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df, source_type):\n",
    "    # Standardize column names\n",
    "    df = df.rename(columns={\n",
    "        \"Position Number\": \"Position ID\",\n",
    "        \"Employee Global Career Band\": \"Global Career Band\"  # For open positions\n",
    "    })\n",
    "    \n",
    "    # Clean Position ID and Employee ID\n",
    "    if \"Position ID\" in df.columns:\n",
    "        df[\"Position ID\"] = df[\"Position ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    if \"Employee ID\" in df.columns:\n",
    "        df[\"Employee ID\"] = df[\"Employee ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Add missing columns if not present\n",
    "    required_cols = [\"Position ID\", \"Employee ID\"]  # Add more as needed\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "def find_changes_gha(current_df, next_df, cols_to_check, month):\n",
    "    changes = []\n",
    "    \n",
    "    # Standardize column names\n",
    "    current_df = standardize_columns(current_df, \"GHA\")\n",
    "    next_df = standardize_columns(next_df, \"GHA\")\n",
    "    \n",
    "    # Concatenate Employee ID and Position ID to create unique identifiers\n",
    "    current_df[\"Emp_Pos_ID\"] = current_df[\"Employee ID\"] + \"_\" + current_df[\"Position ID\"]\n",
    "    next_df[\"Emp_Pos_ID\"] = next_df[\"Employee ID\"] + \"_\" + next_df[\"Position ID\"]\n",
    "\n",
    "    # Compare based on Emp_Pos_ID\n",
    "    current_set = set(current_df[\"Emp_Pos_ID\"])\n",
    "    next_set = set(next_df[\"Emp_Pos_ID\"])\n",
    "    \n",
    "    # Identify records in current_df but not in next_df\n",
    "    for emp_pos_id in current_set - next_set:\n",
    "        record = current_df[current_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        employee_id = record[\"Employee ID\"]\n",
    "        \n",
    "        # Check if the Employee ID exists in next_df\n",
    "        if employee_id not in next_df[\"Employee ID\"].values:\n",
    "            changes.append({\n",
    "                \"Position ID\": record[\"Position ID\"],\n",
    "                \"Employee ID\": employee_id,\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"Employee ID does not exist, movement out\",\n",
    "                \"Source\": \"GHA\"\n",
    "            })\n",
    "    \n",
    "    # Identify records in both but with changes in other columns\n",
    "    common_ids = current_set & next_set\n",
    "    for emp_pos_id in common_ids:\n",
    "        current_record = current_df[current_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        next_record = next_df[next_df[\"Emp_Pos_ID\"] == emp_pos_id].iloc[0]\n",
    "        \n",
    "        # Check for changes in important columns\n",
    "        change_desc = []\n",
    "        for col in cols_to_check:\n",
    "            if col in current_record and col in next_record:\n",
    "                if current_record[col] != next_record[col]:\n",
    "                    change_desc.append(f\"{col} changed\")\n",
    "        \n",
    "        if change_desc:\n",
    "            changes.append({\n",
    "                \"Position ID\": current_record[\"Position ID\"],\n",
    "                \"Employee ID\": current_record[\"Employee ID\"],\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"; \".join(change_desc),\n",
    "                \"Source\": \"GHA\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(changes)\n",
    "\n",
    "def process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos):\n",
    "    changes_df = pd.DataFrame()\n",
    "    \n",
    "    months = list(monthly_files.keys())\n",
    "    for i in range(len(months) - 1):\n",
    "        current_month = months[i]\n",
    "        next_month = months[i + 1]\n",
    "        \n",
    "        gha_current_file, open_pos_current_file = monthly_files[current_month]\n",
    "        gha_next_file, open_pos_next_file = monthly_files[next_month]\n",
    "        \n",
    "        # Read files (assuming single sheet for simplicity)\n",
    "        gha_current_df = pd.read_excel(gha_current_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        gha_next_df = pd.read_excel(gha_next_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        open_pos_current_df = pd.read_excel(open_pos_current_file)\n",
    "        open_pos_next_df = pd.read_excel(open_pos_next_file)\n",
    "        \n",
    "        # Process GHA\n",
    "        gha_changes = find_changes_gha(gha_current_df, gha_next_df, cols_to_check_gha, next_month)\n",
    "        changes_df = pd.concat([changes_df, gha_changes], ignore_index=True)\n",
    "        \n",
    "        # Process Open Positions (unchanged)\n",
    "        open_pos_changes = find_changes(open_pos_current_df, open_pos_next_df, cols_to_check_open_pos, next_month, \"Open Positions\")\n",
    "        changes_df = pd.concat([changes_df, open_pos_changes], ignore_index=True)\n",
    "    \n",
    "    return changes_df\n",
    "\n",
    "# Example usage\n",
    "monthly_files = {\n",
    "    \"Jan 24\": (\"gha_jan.xlsx\", \"open_pos_jan.xlsx\"),\n",
    "    \"Feb 24\": (\"gha_feb.xlsx\", \"open_pos_feb.xlsx\"),\n",
    "    # Add other months...\n",
    "}\n",
    "\n",
    "cols_to_check_gha = [\"Global Career Band\", \"Employee FTE\", \"Employee Type\", \"Work Location City\"]\n",
    "cols_to_check_open_pos = [\"Global Career Band\", \"Work Location City\"]\n",
    "\n",
    "changes_df = process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos)\n",
    "changes_df.to_excel(\"changes_output.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def standardize_columns(df, source_type):\n",
    "    # Standardize column names\n",
    "    df = df.rename(columns={\n",
    "        \"Position Number\": \"Position ID\",\n",
    "        \"Employee Global Career Band\": \"Global Career Band\"  # For open positions\n",
    "    })\n",
    "    \n",
    "    # Clean Position ID and Employee ID\n",
    "    if \"Position ID\" in df.columns:\n",
    "        df[\"Position ID\"] = df[\"Position ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    if \"Employee ID\" in df.columns:\n",
    "        df[\"Employee ID\"] = df[\"Employee ID\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Add missing columns if not present\n",
    "    required_cols = [\"Position ID\", \"Employee ID\"]  # Add more as needed\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "def find_changes(current_df, next_df, cols_to_check, month, source_type):\n",
    "    changes = []\n",
    "    \n",
    "    # Standardize column names\n",
    "    current_df = standardize_columns(current_df, source_type)\n",
    "    next_df = standardize_columns(next_df, source_type)\n",
    "\n",
    "    # Merge on Position ID (and Employee ID if GHA)\n",
    "    merge_cols = [\"Position ID\"]\n",
    "    if source_type == \"GHA\":\n",
    "        merge_cols.append(\"Employee ID\")\n",
    "    \n",
    "    merged = pd.merge(current_df, next_df, on=merge_cols, how=\"outer\", suffixes=(\"_current\", \"_next\"), indicator=True)\n",
    "    \n",
    "    for _, row in merged.iterrows():\n",
    "        if row[\"_merge\"] == \"right_only\":\n",
    "            # New record in the next month, skip it\n",
    "            continue\n",
    "        \n",
    "        if row[\"_merge\"] == \"left_only\":\n",
    "            # Position/Employee no longer present\n",
    "            continue\n",
    "        \n",
    "        # Check for changes in important columns\n",
    "        change_desc = []\n",
    "        for col in cols_to_check:\n",
    "            col_current = f\"{col}_current\"\n",
    "            col_next = f\"{col}_next\"\n",
    "            if col_current in row and col_next in row and row[col_current] != row[col_next]:\n",
    "                change_desc.append(f\"{col} changed\")\n",
    "        \n",
    "        if change_desc:\n",
    "            changes.append({\n",
    "                \"Position ID\": row[\"Position ID\"],\n",
    "                \"Employee ID\": row.get(\"Employee ID\", \"\"),\n",
    "                \"Month Changed\": month,\n",
    "                \"Change Description\": \"; \".join(change_desc),\n",
    "                \"Source\": source_type\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(changes)\n",
    "\n",
    "def process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos):\n",
    "    changes_df = pd.DataFrame()\n",
    "    \n",
    "    months = list(monthly_files.keys())\n",
    "    for i in range(len(months) - 1):\n",
    "        current_month = months[i]\n",
    "        next_month = months[i + 1]\n",
    "        \n",
    "        gha_current_file, open_pos_current_file = monthly_files[current_month]\n",
    "        gha_next_file, open_pos_next_file = monthly_files[next_month]\n",
    "        \n",
    "        # Read files (assuming single sheet for simplicity)\n",
    "        gha_current_df = pd.read_excel(gha_current_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        gha_next_df = pd.read_excel(gha_next_file, sheet_name=\"Headcount - Employee Detail\")\n",
    "        open_pos_current_df = pd.read_excel(open_pos_current_file)\n",
    "        open_pos_next_df = pd.read_excel(open_pos_next_file)\n",
    "        \n",
    "        # Process GHA\n",
    "        gha_changes = find_changes(gha_current_df, gha_next_df, cols_to_check_gha, next_month, \"GHA\")\n",
    "        changes_df = pd.concat([changes_df, gha_changes], ignore_index=True)\n",
    "        \n",
    "        # Process Open Positions\n",
    "        open_pos_changes = find_changes(open_pos_current_df, open_pos_next_df, cols_to_check_open_pos, next_month, \"Open Positions\")\n",
    "        changes_df = pd.concat([changes_df, open_pos_changes], ignore_index=True)\n",
    "    \n",
    "    return changes_df\n",
    "\n",
    "# Example usage\n",
    "monthly_files = {\n",
    "    \"Jan 24\": (\"gha_jan.xlsx\", \"open_pos_jan.xlsx\"),\n",
    "    \"Feb 24\": (\"gha_feb.xlsx\", \"open_pos_feb.xlsx\"),\n",
    "    # Add other months...\n",
    "}\n",
    "\n",
    "cols_to_check_gha = [\"Global Career Band\", \"Employee FTE\", \"Employee Type\", \"Work Location City\"]\n",
    "cols_to_check_open_pos = [\"Global Career Band\", \"Work Location City\"]\n",
    "\n",
    "changes_df = process_monthly_files(monthly_files, cols_to_check_gha, cols_to_check_open_pos)\n",
    "changes_df.to_excel(\"changes_output.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def standardize_ids(df):\n",
    "    \"\"\"\n",
    "    Standardize 'Position ID' and 'Emp`loyee ID' columns.\n",
    "    Removes extra decimal points, leading/trailing spaces, \n",
    "    and converts IDs to string format with uniform length.\n",
    "    \"\"\"\n",
    "    if \"Position ID\" in df.columns:\n",
    "        df[\"Position ID\"] = df[\"Position ID\"].astype(str).str.split('.').str[0].str.strip()\n",
    "    if \"Employee ID\" in df.columns:\n",
    "        df[\"Employee ID\"] = df[\"Employee ID\"].astype(str).str.split('.').str[0].str.strip()\n",
    "    return df\n",
    "\n",
    "def find_new_records(file_df, master_df, month, source):\n",
    "    \"\"\"\n",
    "    Find new records in the current month's file compared to the master dataframe.\n",
    "    \"\"\"\n",
    "    # Standardize IDs for comparison\n",
    "    file_df = standardize_ids(file_df)\n",
    "    master_df = standardize_ids(master_df)\n",
    "\n",
    "    # Add missing columns to file_df to match master_df\n",
    "    for col in master_df.columns:\n",
    "        if col not in file_df.columns:\n",
    "            file_df[col] = \"\"\n",
    "\n",
    "    # Drop columns not in master_df\n",
    "    file_df = file_df[master_df.columns]\n",
    "\n",
    "    # Identify new records (not in master_df)\n",
    "    new_records = file_df[~file_df[\"Position ID\"].isin(master_df[\"Position ID\"])]\n",
    "    new_records[\"Month Added\"] = month\n",
    "    new_records[\"Source\"] = source\n",
    "\n",
    "    # Ensure new_records matches the structure of new_df\n",
    "    new_records = new_records.reindex(columns=master_df.columns.tolist() + [\"Month Added\", \"Source\"], fill_value=\"\")\n",
    "\n",
    "    return new_records\n",
    "\n",
    "def find_changed_records(current_df, next_df, cols_to_check, month, source):\n",
    "    \"\"\"\n",
    "    Find records with changes in the next month's file compared to the current month's file.\n",
    "    \"\"\"\n",
    "    # Standardize IDs for comparison\n",
    "    current_df = standardize_ids(current_df)\n",
    "    next_df = standardize_ids(next_df)\n",
    "\n",
    "    # Merge both dataframes on 'Position ID' and 'Employee ID' for comparison\n",
    "    merged = pd.merge(current_df, next_df, on=[\"Position ID\", \"Employee ID\"], suffixes=(\"_current\", \"_next\"), how=\"inner\")\n",
    "\n",
    "    changed_records = []\n",
    "    for _, row in merged.iterrows():\n",
    "        changed_cols = [\n",
    "            col for col in cols_to_check\n",
    "            if row[f\"{col}_current\"] != row[f\"{col}_next\"]\n",
    "        ]\n",
    "        if changed_cols:\n",
    "            updated_row = row.to_dict()\n",
    "            updated_row[\"Month Changed\"] = month\n",
    "            updated_row[\"Source\"] = source\n",
    "            updated_row[\"Cols Changed\"] = \", \".join(changed_cols)\n",
    "            changed_records.append(updated_row)\n",
    "\n",
    "    # Convert changed records to a DataFrame\n",
    "    if changed_records:\n",
    "        changes_df = pd.DataFrame(changed_records)\n",
    "        changes_df = changes_df.reindex(columns=current_df.columns.tolist() + [\"Month Changed\", \"Source\", \"Cols Changed\"], fill_value=\"\")\n",
    "        return changes_df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=current_df.columns.tolist() + [\"Month Changed\", \"Source\", \"Cols Changed\"])\n",
    "\n",
    "def process_monthly_files(master_df, monthly_files, cols_to_check_gha, cols_to_check_open_pos):\n",
    "    \"\"\"\n",
    "    Process monthly files to find new and changed records.\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(columns=master_df.columns.tolist() + [\"Month Added\", \"Source\"])\n",
    "    changes_df = pd.DataFrame(columns=master_df.columns.tolist() + [\"Month Changed\", \"Source\", \"Cols Changed\"])\n",
    "\n",
    "    for i in range(len(monthly_files) - 1):\n",
    "        current_month, current_file = monthly_files[i]\n",
    "        next_month, next_file = monthly_files[i + 1]\n",
    "\n",
    "        # Process GHA files\n",
    "        if \"gha\" in current_file.lower():\n",
    "            current_df = pd.read_excel(current_file)\n",
    "            next_df = pd.read_excel(next_file)\n",
    "\n",
    "            # Find new records\n",
    "            new_df = pd.concat([new_df, find_new_records(current_df, master_df, current_month, \"GHA\")], ignore_index=True)\n",
    "\n",
    "            # Find changed records\n",
    "            changes_df = pd.concat([changes_df, find_changed_records(current_df, next_df, cols_to_check_gha, next_month, \"GHA\")], ignore_index=True)\n",
    "\n",
    "        # Process Open Position files\n",
    "        if \"open position\" in current_file.lower():\n",
    "            current_df = pd.read_excel(current_file)\n",
    "            next_df = pd.read_excel(next_file)\n",
    "\n",
    "            # Find new records\n",
    "            new_df = pd.concat([new_df, find_new_records(current_df, master_df, current_month, \"Open Position\")], ignore_index=True)\n",
    "\n",
    "            # Find changed records\n",
    "            changes_df = pd.concat([changes_df, find_changed_records(current_df, next_df, cols_to_check_open_pos, next_month, \"Open Position\")], ignore_index=True)\n",
    "\n",
    "    return new_df, changes_df\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load master file\n",
    "    master_df = pd.read_excel(\"master_file.xlsx\")\n",
    "\n",
    "    # List of monthly files with format [(month, file_path), ...]\n",
    "    monthly_files = [\n",
    "        (\"Jan 24\", \"jan_24_gha.xlsx\"),\n",
    "        (\"Feb 24\", \"feb_24_gha.xlsx\"),\n",
    "        (\"Mar 24\", \"mar_24_gha.xlsx\"),\n",
    "        # Add more files as needed\n",
    "    ]\n",
    "\n",
    "    # Columns to check for GHA and Open Position files\n",
    "    cols_to_check_gha = [\"BF Level 3\", \"BF Level 4\", \"Cost Center\"]\n",
    "    cols_to_check_open_pos = [\"Position Name\", \"Job Level\"]\n",
    "\n",
    "    # Process the files\n",
    "    new_df, changes_df = process_monthly_files(master_df, monthly_files, cols_to_check_gha, cols_to_check_open_pos)\n",
    "\n",
    "    # Save results\n",
    "    new_df.to_excel(\"new_records.xlsx\", index=False)\n",
    "    changes_df.to_excel(\"changed_records.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22013ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_monthly_file(file_df, master_df, month, source_type, updated_records, new_records):\n",
    "    \"\"\"\n",
    "    Process the monthly file and compare it with the master dataframe to identify changes or additions.\n",
    "\n",
    "    Args:\n",
    "        file_df (DataFrame): The dataframe for the current month's data.\n",
    "        master_df (DataFrame): The master dataframe containing previous records.\n",
    "        month (str): The current month being processed (e.g., \"Feb 24\").\n",
    "        source_type (str): The type of data source (e.g., \"GHA\", \"Open Position\").\n",
    "        updated_records (list): List to store records that have been updated.\n",
    "        new_records (list): List to store records that are new.\n",
    "\n",
    "    Returns:\n",
    "        None: Updates `updated_records` and `new_records` in place.\n",
    "    \"\"\"\n",
    "    # Normalize blanks and NaN in both dataframes\n",
    "    file_df = file_df.fillna(\"\").replace(\"nan\", \"\")\n",
    "    master_df = master_df.fillna(\"\").replace(\"nan\", \"\")\n",
    "\n",
    "    for _, row in file_df.iterrows():\n",
    "        if row[\"Position ID\"] in master_df[\"Position ID\"].values:\n",
    "            # Fetch the corresponding row in the master file\n",
    "            master_row = master_df[master_df[\"Position ID\"] == row[\"Position ID\"]].iloc[0]\n",
    "\n",
    "            # Identify columns that have changed\n",
    "            cols_changed = []\n",
    "            for col in file_df.columns:\n",
    "                if col in master_df.columns and row[col] != master_row[col]:\n",
    "                    cols_changed.append(col)\n",
    "\n",
    "            if cols_changed:\n",
    "                # Record the updated row\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \", \".join(cols_changed)\n",
    "                updated_row[\"Source\"] = source_type\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Check if Employee ID exists in master but Position ID has changed\n",
    "            if \"Employee ID\" in row and not master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].empty:\n",
    "                # Fetch the corresponding row in master where Employee ID matches\n",
    "                master_row = master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].iloc[0]\n",
    "\n",
    "                # Check if Position ID has actually changed\n",
    "                if master_row[\"Position ID\"] != row[\"Position ID\"]:\n",
    "                    updated_row = row.to_dict()\n",
    "                    updated_row[\"Month Changed\"] = month\n",
    "                    updated_row[\"Cols Changed\"] = \"Position ID\"\n",
    "                    updated_row[\"Source\"] = source_type\n",
    "                    updated_records.append(updated_row)\n",
    "            else:\n",
    "                # Handle cases where both Employee ID and Position ID are blank or unchanged\n",
    "                if (\n",
    "                    \"Employee ID\" in row\n",
    "                    and row[\"Employee ID\"] == \"\"  # Current file has blank Employee ID\n",
    "                    and not master_df[(master_df[\"Position ID\"] == row[\"Position ID\"]) & (master_df[\"Employee ID\"] == \"\")].empty\n",
    "                ):\n",
    "                    # Skip adding to updated_records because nothing has changed\n",
    "                    continue\n",
    "\n",
    "                # Add new record if no match found\n",
    "                new_row = row.to_dict()\n",
    "                new_row[\"Month Added\"] = month\n",
    "                new_row[\"Source\"] = source_type\n",
    "                new_records.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f099962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_function_and_new_records(file_df, master_df, month, source_type):\n",
    "    \"\"\"\n",
    "    Process the monthly file and compare it with the master dataframe to identify changes or additions.\n",
    "\n",
    "    Args:\n",
    "        file_df (DataFrame): The dataframe for the current month's data.\n",
    "        master_df (DataFrame): The master dataframe containing previous records.\n",
    "        month (str): The current month being processed (e.g., \"Feb 24\").\n",
    "        source_type (str): The type of data source (e.g., \"GHA\", \"Open Position\").\n",
    "\n",
    "    Returns:\n",
    "        updated_records (list): List of records that have been updated.\n",
    "        new_records (list): List of records that are new.\n",
    "    \"\"\"\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "\n",
    "    # Normalize blanks and NaN in both dataframes\n",
    "    file_df = file_df.fillna(\"\").replace(\"nan\", \"\")\n",
    "    master_df = master_df.fillna(\"\").replace(\"nan\", \"\")\n",
    "\n",
    "    for _, row in file_df.iterrows():\n",
    "        if row[\"Position ID\"] in master_df[\"Position ID\"].values:\n",
    "            # Fetch the corresponding row in the master file\n",
    "            master_row = master_df[master_df[\"Position ID\"] == row[\"Position ID\"]].iloc[0]\n",
    "\n",
    "            # Identify columns that have changed\n",
    "            cols_changed = []\n",
    "            for col in file_df.columns:\n",
    "                if col in master_df.columns and row[col] != master_row[col]:\n",
    "                    cols_changed.append(col)\n",
    "\n",
    "            if cols_changed:\n",
    "                # Record the updated row\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \", \".join(cols_changed)\n",
    "                updated_row[\"Source\"] = source_type\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Check if Employee ID exists in master but Position ID has changed\n",
    "            if \"Employee ID\" in row and not master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].empty:\n",
    "                # Fetch the corresponding row in master where Employee ID matches\n",
    "                master_row = master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].iloc[0]\n",
    "\n",
    "                # Check if Position ID has actually changed\n",
    "                if master_row[\"Position ID\"] != row[\"Position ID\"]:\n",
    "                    updated_row = row.to_dict()\n",
    "                    updated_row[\"Month Changed\"] = month\n",
    "                    updated_row[\"Cols Changed\"] = \"Position ID\"\n",
    "                    updated_row[\"Source\"] = source_type\n",
    "                    updated_records.append(updated_row)\n",
    "            else:\n",
    "                # Handle cases where both Employee ID and Position ID are blank or unchanged\n",
    "                if (\n",
    "                    \"Employee ID\" in row\n",
    "                    and row[\"Employee ID\"] == \"\"  # Current file has blank Employee ID\n",
    "                    and not master_df[(master_df[\"Position ID\"] == row[\"Position ID\"]) & (master_df[\"Employee ID\"] == \"\")].empty\n",
    "                ):\n",
    "                    # Skip adding to updated_records because nothing has changed\n",
    "                    continue\n",
    "\n",
    "                # Add new record if no match found\n",
    "                new_row = row.to_dict()\n",
    "                new_row[\"Month Added\"] = month\n",
    "                new_row[\"Source\"] = source_type\n",
    "                new_records.append(new_row)\n",
    "\n",
    "    return updated_records, new_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53425123",
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "    # Check if Employee ID exists in master but Position ID has changed\n",
    "    if \"Employee ID\" in row and not master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].empty:\n",
    "        # Fetch the corresponding row in master where Employee ID matches\n",
    "        master_row = master_df[master_df[\"Employee ID\"] == row[\"Employee ID\"]].iloc[0]\n",
    "        \n",
    "        # Check if Position ID has actually changed\n",
    "        if master_row[\"Position ID\"] != row[\"Position ID\"]:\n",
    "            updated_row = row.to_dict()\n",
    "            updated_row[\"Month Changed\"] = month\n",
    "            updated_row[\"Cols Changed\"] = \"Position ID\"\n",
    "            updated_row[\"Source\"] = source_type\n",
    "            updated_records.append(updated_row)\n",
    "    else:\n",
    "        # Handle cases where both Employee ID and Position ID are blank or unchanged\n",
    "        if (\n",
    "            \"Employee ID\" in row\n",
    "            and row[\"Employee ID\"] == \"\"  # Current file has blank Employee ID\n",
    "            and not master_df[(master_df[\"Position ID\"] == row[\"Position ID\"]) & (master_df[\"Employee ID\"] == \"\")].empty\n",
    "        ):\n",
    "            # Skip adding to updated_records because nothing has changed\n",
    "            continue\n",
    "\n",
    "        # Add new record if no match found\n",
    "        new_row = row.to_dict()\n",
    "        new_row[\"Month Added\"] = month\n",
    "        new_row[\"Source\"] = source_type\n",
    "        new_records.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efec366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated GHA Records:\n",
      "   Position ID Employee ID Col1_current  Col2_current Col3_current  \\\n",
      "1           20        E002    B_Updated           250            Y   \n",
      "2           40        E004            D           400            W   \n",
      "\n",
      "  Col1_master  Col2_master Col3_master ColZ  \n",
      "1           B        200.0           Y  NaN  \n",
      "2         NaN          NaN         NaN  NaN  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Position ID_master'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position ID_master'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-76f17aeaea46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Find new records in Feb24 GHA data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mnew_gha_records\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_new_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeb24_gha_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New GHA Records:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_gha_records\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-76f17aeaea46>\u001b[0m in \u001b[0;36mfind_new_records\u001b[1;34m(current_df, master_df)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Filter rows where Position ID and Employee ID do not have a match in the master data (i.e., new records)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mnew_records\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Position ID_master'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employee ID_master'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position ID_master'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# Strip spaces from co`lumn names to avoid mismatch\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "feb24_gha_df.columns = feb24_gha_df.columns.str.strip()\n",
    "feb24_open_df.columns = feb24_open_df.columns.str.strip()\n",
    "mar24_gha_df.columns = mar24_gha_df.columns.str.strip()\n",
    "mar24_open_df.columns = mar24_open_df.columns.str.strip()\n",
    "\n",
    "# Part 1: Find updated records (matching Position ID and Employee ID, but with changes in other columns)\n",
    "def find_updated_records(current_df, master_df):\n",
    "    # Merge dataframes on Position ID and Employee ID to compare current vs master\n",
    "    merged_df = current_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "    \n",
    "    # Find columns that have been updated (skip Position ID and Employee ID)\n",
    "    updated_columns = [col for col in current_df.columns if col not in ['Position ID', 'Employee ID']]\n",
    "    \n",
    "    # Create a mask to find rows where any column (other than Position ID and Employee ID) has changed\n",
    "    updated_mask = merged_df.apply(lambda row: any(row[col + '_current'] != row[col + '_master'] for col in updated_columns), axis=1)\n",
    "    \n",
    "    # Filter out rows that have been updated\n",
    "    updated_records = merged_df[updated_mask]\n",
    "    \n",
    "    return updated_records\n",
    "\n",
    "# Part 2: Find new records (Position ID and Employee ID exist only in the current data, not in the master data)\n",
    "def find_new_records(current_df, master_df):\n",
    "    # Merge dataframes on Position ID and Employee ID\n",
    "    merged_df = current_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "    \n",
    "    # Filter rows where Position ID and Employee ID do not have a match in the master data (i.e., new records)\n",
    "    new_records = merged_df[merged_df['Position ID_master'].isna() & merged_df['Employee ID_master'].isna()]\n",
    "    \n",
    "    return new_records\n",
    "\n",
    "# Find updated records in Feb24 GHA data\n",
    "updated_gha_records = find_updated_records(feb24_gha_df, master_df)\n",
    "print(\"Updated GHA Records:\")\n",
    "print(updated_gha_records)\n",
    "\n",
    "# Find new records in Feb24 GHA data\n",
    "new_gha_records = find_new_records(feb24_gha_df, master_df)\n",
    "print(\"New GHA Records:\")\n",
    "print(new_gha_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88672fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in GHA DataFrame:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3'], dtype='object')\n",
      "\n",
      "Master DataFrame Columns for Merge:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3', 'ColZ'], dtype='object')\n",
      "\n",
      "Sample data from file_df:\n",
      "   Position ID Employee ID       Col1  Col2 Col3\n",
      "0           10        E001          A   100    X\n",
      "1           20        E002  B_Updated   250    Y\n",
      "2           40        E004          D   400    W\n",
      "\n",
      "Sample data from master_df:\n",
      "   Position ID Employee ID Col1  Col2 Col3 ColZ\n",
      "0           10        E001    A   100    X  NaN\n",
      "1           20        E002    B   200    Y  NaN\n",
      "2           30        E003    C   300    Z  NaN\n",
      "3           31         NaN   DD  9000  NaN   SS\n",
      "4           50         NaN    P   500  NaN    U\n",
      "\n",
      "Merging on both 'Position ID' and 'Employee ID' for GHA\n",
      "\n",
      "Merged DataFrame columns for GHA:\n",
      "Index(['Position ID', 'Employee ID', 'Col1_current', 'Col2_current',\n",
      "       'Col3_current', 'Col1_master', 'Col2_master', 'Col3_master', 'ColZ'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in Open Position DataFrame:\n",
      "Index(['Position ID', 'Col1', 'Col2', 'ColZ'], dtype='object')\n",
      "\n",
      "Master DataFrame Columns for Merge:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3', 'ColZ'], dtype='object')\n",
      "\n",
      "Sample data from file_df:\n",
      "   Position ID Col1  Col2 ColZ\n",
      "0           50    P   500    U\n",
      "1           60    Q   600    V\n",
      "2           70    R   700    T\n",
      "\n",
      "Sample data from master_df:\n",
      "   Position ID Employee ID Col1  Col2 Col3 ColZ\n",
      "0           10        E001    A   100    X  NaN\n",
      "1           20        E002    B   200    Y  NaN\n",
      "2           30        E003    C   300    Z  NaN\n",
      "3           31         NaN   DD  9000  NaN   SS\n",
      "4           50         NaN    P   500  NaN    U\n",
      "\n",
      "Merging on 'Position ID' only for Open Position\n",
      "\n",
      "Merged DataFrame columns for Open Position:\n",
      "Index(['Position ID', 'Col1_current', 'Col2_current', 'ColZ_current',\n",
      "       'Employee ID', 'Col1_master', 'Col2_master', 'Col3', 'ColZ_master'],\n",
      "      dtype='object')\n",
      "                         0 Employee ID Month Changed  Position ID  \\\n",
      "1                      NaN        E002        Feb 24         20.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "1                      NaN        E002        Feb 24         20.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "Position ID             10         NaN           NaN          NaN   \n",
      "Employee ID           E001         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "Position ID             20         NaN           NaN          NaN   \n",
      "Employee ID           E002         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "Position ID             40         NaN           NaN          NaN   \n",
      "Employee ID           E004         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "Position ID             50         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "Position ID             60         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "Position ID             70         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "\n",
      "            Reason Changed         Source  \n",
      "1             Col1 Changed            GHA  \n",
      "2             Col1 Changed            GHA  \n",
      "1             Col2 Changed            GHA  \n",
      "2             Col2 Changed            GHA  \n",
      "2             Col3 Changed            GHA  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "1             Col1 Changed  Open Position  \n",
      "2             Col1 Changed  Open Position  \n",
      "1             Col2 Changed  Open Position  \n",
      "2             Col2 Changed  Open Position  \n",
      "1             ColZ Changed  Open Position  \n",
      "2             ColZ Changed  Open Position  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to check and process changes for GHA and Open Positions files\n",
    "def process_changes(file_df, source, cols_to_check, month_year):\n",
    "    global updateddf\n",
    "\n",
    "    # Strip any leading/trailing spaces in column names to avoid mismatch\n",
    "    file_df.columns = file_df.columns.str.strip()\n",
    "    master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "    # Debug: Print column names of file_df and master_df to ensure 'Position ID' and 'Employee ID' are present\n",
    "    print(f\"\\nColumns in {source} DataFrame:\")\n",
    "    print(file_df.columns)\n",
    "    \n",
    "    print(\"\\nMaster DataFrame Columns for Merge:\")\n",
    "    print(master_df.columns)\n",
    "\n",
    "    # Ensure the correct columns are present before proceeding\n",
    "    if 'Position ID' not in file_df.columns:\n",
    "        print(f\"Error: 'Position ID' not found in {source} data.\")\n",
    "        return\n",
    "    if 'Employee ID' not in file_df.columns and source != 'Open Position':\n",
    "        print(f\"Error: 'Employee ID' not found in {source} data.\")\n",
    "        return\n",
    "\n",
    "    # Show a sample of the first few rows to understand the structure\n",
    "    print(\"\\nSample data from file_df:\")\n",
    "    print(file_df.head())\n",
    "    \n",
    "    print(\"\\nSample data from master_df:\")\n",
    "    print(master_df.head())\n",
    "\n",
    "    # Merge based on 'Position ID' and 'Employee ID' (for GHA) or just 'Position ID' (for Open Position)\n",
    "    if source == 'Open Position':\n",
    "        print(\"\\nMerging on 'Position ID' only for Open Position\")\n",
    "        merged_df = file_df.merge(master_df, on=['Position ID'], how='left', suffixes=('_current', '_master'))\n",
    "    else:\n",
    "        print(\"\\nMerging on both 'Position ID' and 'Employee ID' for GHA\")\n",
    "        merged_df = file_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "\n",
    "    # Print the columns of the merged DataFrame to debug\n",
    "    print(f\"\\nMerged DataFrame columns for {source}:\")\n",
    "    print(merged_df.columns)\n",
    "\n",
    "    # Process the merged DataFrame\n",
    "    for col in cols_to_check:\n",
    "        current_col = f'{col}_current'\n",
    "        master_col = f'{col}_master'\n",
    "\n",
    "        # Ensure both current and master columns exist\n",
    "        if current_col in merged_df.columns and master_col in merged_df.columns:\n",
    "            merged_df[f'{col}_changed'] = merged_df[current_col] != merged_df[master_col]\n",
    "            changed_rows = merged_df[merged_df[f'{col}_changed'] == True]\n",
    "            changed_rows['Reason Changed'] = f'{col} Changed'\n",
    "            changed_rows['Month Changed'] = month_year\n",
    "            changed_rows['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, changed_rows[['Position ID', 'Employee ID', 'Month Changed', 'Reason Changed', 'Source']]])\n",
    "\n",
    "        elif current_col in merged_df.columns:\n",
    "            merged_df[f'{col}_changed'] = False  # Defaulting to False since master column is missing\n",
    "            changed_rows = merged_df[merged_df[f'{col}_changed'] == True]\n",
    "            changed_rows['Reason Changed'] = f'{col} Changed'\n",
    "            changed_rows['Month Changed'] = month_year\n",
    "            changed_rows['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, changed_rows[['Position ID', 'Employee ID', 'Month Changed', 'Reason Changed', 'Source']]])\n",
    "\n",
    "    # Handle new records (those not found in the master file)\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if pd.isna(row.get('Position ID_master')):  # No 'Employee ID' for Open Position source\n",
    "            new_record = row.copy()\n",
    "            new_record['Month Added'] = month_year\n",
    "            new_record['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, new_record[['Position ID', 'Employee ID', 'Month Added', 'Source']]])\n",
    "\n",
    "# Assuming you have defined the file paths for the respective files\n",
    "# feb24_gha_df = pd.read_excel('feb24_gha.xlsx')\n",
    "# feb24_open_df = pd.read_excel('feb24_open.xlsx')\n",
    "# master_df = pd.read_excel('master_file.xlsx')\n",
    "\n",
    "# Define file paths\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df =pd.read_excel( r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# List of columns to check for changes\n",
    "cols_to_check_gha = ['Col1', 'Col2', 'Col3']  # Adjust columns to actual ones\n",
    "cols_to_check_open_pos = ['Col1', 'Col2', 'ColZ']  # Adjust columns to actual ones\n",
    "\n",
    "# Initialize empty dataframe to store updates\n",
    "updateddf = pd.DataFrame()\n",
    "\n",
    "# Process changes for February 24th GHA and Open Position files\n",
    "month_year = 'Feb 24'\n",
    "process_changes(feb24_gha_df, 'GHA', cols_to_check_gha, month_year)\n",
    "process_changes(feb24_open_df, 'Open Position', cols_to_check_open_pos, month_year)\n",
    "\n",
    "# If you want to save the updated DataFrame to an Excel file\n",
    "updateddf.to_excel(\"Updated_Records.xlsx\", index=False)\n",
    "\n",
    "# Output the updated records for review\n",
    "print(updateddf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7def53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ff237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4980f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2bea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063442b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee96439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Records (Feb24 GHA):\n",
      "  Position ID Employee ID Col1  Col2 Col3\n",
      "2          40        E004    D   400    W\n",
      "Changed Records (Feb24 GHA):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, Employee ID, Col1_new, Col2_new, Col3_new, Col1_master, Col2_master, Col3_master]\n",
      "Index: []\n",
      "New Records (mar24 GHA):\n",
      "  Position ID Employee ID       Col1  Col2 Col3\n",
      "1          40        E004  D_Updated   400    W\n",
      "2          50        E005          E   500    Z\n",
      "Changed Records (mar24 GHA):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, Employee ID, Col1_new, Col2_new, Col3_new, Col1_master, Col2_master, Col3_master]\n",
      "Index: []\n",
      "New Records (Feb24 open):\n",
      "  Position ID ColX  ColY ColZ\n",
      "0          50    P   500    U\n",
      "1          60    Q   600    V\n",
      "2          70    R   700    T\n",
      "Changed Records (Feb24 open):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, ColX, ColY, ColZ, Employee ID, Col1, Col2, Col3]\n",
      "Index: []\n",
      "New Records (MAr24 open):\n",
      "  Position ID       ColX  ColY ColZ\n",
      "0          50          P   500    U\n",
      "1          60  Q_Updated   650    V\n",
      "2          80          S   800    T\n",
      "Changed Records (MAr24 open):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, ColX, ColY, ColZ, Employee ID, Col1, Col2, Col3]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load the master file and compare it with a new file\n",
    "def load_and_compare(master_file_path, new_file_path, has_employee_id=True):\n",
    "    # Load the master file and new file into dataframes\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "    new_df = pd.read_excel(new_file_path)\n",
    "    \n",
    "    # Ensure Position ID is treated as a string for consistency\n",
    "    master_df['Position ID'] = master_df['Position ID'].astype(str)\n",
    "    new_df['Position ID'] = new_df['Position ID'].astype(str)\n",
    "\n",
    "    # Check if Employee ID exists in both files, adjust accordingly\n",
    "    if has_employee_id:\n",
    "        master_df['Employee ID'] = master_df['Employee ID'].astype(str)\n",
    "        new_df['Employee ID'] = new_df['Employee ID'].astype(str)\n",
    "        new_records_df = new_df[~new_df[['Position ID', 'Employee ID']].isin(master_df[['Position ID', 'Employee ID']]).all(axis=1)]\n",
    "        changed_records_df = new_df.merge(master_df, on=['Position ID', 'Employee ID'], how='inner', suffixes=('_new', '_master'))\n",
    "    else:\n",
    "        # If Employee ID is not present, compare based on 'Position ID' only\n",
    "        new_records_df = new_df[~new_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_records_df = new_df.merge(master_df, on='Position ID', how='inner', suffixes=('_new', '_master'))\n",
    "\n",
    "    # For changed records, we check for differences in columns that exist in both files\n",
    "    compare_columns = [col for col in new_df.columns if col != 'Position ID' and col != 'Employee ID']\n",
    "    \n",
    "    # Only compare columns that exist in both new_df and master_df\n",
    "    compare_columns = [col for col in compare_columns if f'{col}_new' in changed_records_df.columns and f'{col}_master' in changed_records_df.columns]\n",
    "\n",
    "    # Compare the columns and filter the changed records\n",
    "    for col in compare_columns:\n",
    "        changed_records_df = changed_records_df[changed_records_df[f'{col}_new'] != changed_records_df[f'{col}_master']]\n",
    "\n",
    "    # Remove rows with no differences in the specified columns\n",
    "    changed_records_df = changed_records_df.dropna(subset=[f'{col}_new' for col in compare_columns])\n",
    "    \n",
    "    return new_records_df, changed_records_df\n",
    "\n",
    "# Define file paths\n",
    "master_file_path = r\"Input\\\\\" + \"master_file.xlsx\"\n",
    "feb24_gha_file = r\"Input\\\\\" + \"Feb24_gha.xlsx\"\n",
    "feb24_open_file = r\"Input\\\\\" + \"Feb24_open.xlsx\"\n",
    "mar24_gha_file = r\"Input\\\\\" + \"Mar24_gha.xlsx\"\n",
    "mar24_open_file = r\"Input\\\\\" + \"Mar24_open.xlsx\"\n",
    "\n",
    "# Compare Feb24 GHA file with the master file (Employee ID is present)\n",
    "new_records_feb24_gha, changed_records_feb24_gha = load_and_compare(master_file_path, feb24_gha_file, has_employee_id=True)\n",
    "\n",
    "# Compare Feb24 Open file with the master file (No Employee ID in open file)\n",
    "new_records_feb24_open, changed_records_feb24_open = load_and_compare(master_file_path, feb24_open_file, has_employee_id=False)\n",
    "\n",
    "# Compare Mar24 GHA file with the master file (Employee ID is present)\n",
    "new_records_mar24_gha, changed_records_mar24_gha = load_and_compare(master_file_path, mar24_gha_file, has_employee_id=True)\n",
    "\n",
    "# Compare Mar24 Open file with the master file (No Employee ID in open file)\n",
    "new_records_mar24_open, changed_records_mar24_open = load_and_compare(master_file_path, mar24_open_file, has_employee_id=False)\n",
    "\n",
    "# Print results (or you can save them to a new file)\n",
    "print(\"New Records (Feb24 GHA):\")\n",
    "print(new_records_feb24_gha)\n",
    "\n",
    "print(\"Changed Records (Feb24 GHA):\")\n",
    "print(changed_records_feb24_gha)\n",
    "\n",
    "print(\"New Records (mar24 GHA):\")\n",
    "print(new_records_mar24_gha)\n",
    "\n",
    "print(\"Changed Records (mar24 GHA):\")\n",
    "print(changed_records_mar24_gha)\n",
    "\n",
    "print(\"New Records (Feb24 open):\")\n",
    "print(new_records_feb24_open)\n",
    "\n",
    "print(\"Changed Records (Feb24 open):\")\n",
    "print(changed_records_feb24_open)\n",
    "\n",
    "print(\"New Records (MAr24 open):\")\n",
    "print(new_records_mar24_open)\n",
    "\n",
    "print(\"Changed Records (MAr24 open):\")\n",
    "print(changed_records_mar24_open)\n",
    "\n",
    "\n",
    "\n",
    "# Repeat for other files (Feb24 Open, Mar24 GHA, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70f06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Records DataFrame:\n",
      "  Position ID Employee ID       Col1   Col2 Col3 Month Added     Source Name  \\\n",
      "0      000010        E001          A  100.0    X      Feb 24             GHA   \n",
      "1      000020        E002  B_Updated  250.0    Y      Feb 24             GHA   \n",
      "2      000040        E004          D  400.0    W      Feb 24             GHA   \n",
      "3      000050         NaN        NaN    NaN  NaN      Feb 24  Open Positions   \n",
      "4      000060         NaN        NaN    NaN  NaN      Feb 24  Open Positions   \n",
      "\n",
      "  ColX   ColY ColZ  \n",
      "0  NaN    NaN  NaN  \n",
      "1  NaN    NaN  NaN  \n",
      "2  NaN    NaN  NaN  \n",
      "3    P  500.0    U  \n",
      "4    Q  600.0    V  \n",
      "\n",
      "Changed Records DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample function to process GHA and Open Positions files\n",
    "def process_month_files(master_df, month_files, cols_to_check_gha, cols_to_check_positions):\n",
    "    newdf = pd.DataFrame()  # DataFrame to hold new records\n",
    "    changesdf = pd.DataFrame()  # DataFrame to hold changed records\n",
    "    \n",
    "    # Iterate through each month's GHA and Open Positions files\n",
    "    for month, files in month_files.items():\n",
    "        gha_file, positions_file = files\n",
    "        \n",
    "        # Load the GHA and Open Positions files\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        positions_df = pd.read_excel(positions_file)\n",
    "\n",
    "        # Standardize column names if necessary (e.g., rename 'Position ID' to 'Position Number')\n",
    "        gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(6)  # Ensure 'Position ID' is a string with leading zeros\n",
    "        positions_df['Position ID'] = positions_df['Position ID'].astype(str).str.zfill(6)\n",
    "\n",
    "        # Checking new records and changes for GHA\n",
    "        new_gha_records = gha_df[~gha_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_gha_records = gha_df[gha_df['Position ID'].isin(master_df['Position ID'])]\n",
    "\n",
    "        # Identify changes in GHA based on the specified columns\n",
    "        for index, row in changed_gha_records.iterrows():\n",
    "            master_row = master_df[master_df['Position ID'] == row['Position ID']].iloc[0]\n",
    "            changed_columns = [col for col in cols_to_check_gha if row[col] != master_row[col]]\n",
    "            \n",
    "            if changed_columns:\n",
    "                row['Change Month'] = month\n",
    "                row['Changed Attributes'] = ', '.join(changed_columns)\n",
    "                row['Source Name'] = 'GHA'\n",
    "                changesdf = pd.concat([changesdf, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Add new records from GHA\n",
    "        new_gha_records['Month Added'] = month\n",
    "        new_gha_records['Source Name'] = 'GHA'\n",
    "        newdf = pd.concat([newdf, new_gha_records], ignore_index=True)\n",
    "\n",
    "        # Checking new records and changes for Open Positions\n",
    "        new_positions_records = positions_df[~positions_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_positions_records = positions_df[positions_df['Position ID'].isin(master_df['Position ID'])]\n",
    "\n",
    "        # Identify changes in Open Positions based on the specified columns\n",
    "        for index, row in changed_positions_records.iterrows():\n",
    "            master_row = master_df[master_df['Position ID'] == row['Position ID']].iloc[0]\n",
    "            changed_columns = [col for col in cols_to_check_positions if row[col] != master_row[col]]\n",
    "            \n",
    "            if changed_columns:\n",
    "                row['Change Month'] = month\n",
    "                row['Changed Attributes'] = ', '.join(changed_columns)\n",
    "                row['Source Name'] = 'Open Positions'\n",
    "                changesdf = pd.concat([changesdf, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Add new records from Open Positions\n",
    "        new_positions_records['Month Added'] = month\n",
    "        new_positions_records['Source Name'] = 'Open Positions'\n",
    "        newdf = pd.concat([newdf, new_positions_records], ignore_index=True)\n",
    "\n",
    "    # Return the new and changed records dataframes\n",
    "    return newdf, changesdf\n",
    "\n",
    "# Define the columns to check for GHA and Open Positions (you can modify these lists)\n",
    "cols_to_check_gha = ['Col1', 'Col2', 'Col3']  # Replace with the actual columns for GHA\n",
    "cols_to_check_positions = ['ColX', 'ColY', 'ColZ']  # Replace with the actual columns for Open Positions\n",
    "\n",
    "# Example of files for the month comparison (make sure to adjust paths and file names)\n",
    "month_files = {\n",
    "    'Feb 24': [r\"Input\\\\\"+'Feb24_gha.xlsx', r\"Input\\\\\"+'Feb24_open.xlsx'],\n",
    "    'Mar 24': [r\"Input\\\\\"+'Mar24_gha.xlsx', r\"Input\\\\\"+'Mar24_open.xlsx']\n",
    "}\n",
    "\n",
    "# Load the master file (adjust the file path as needed)\n",
    "master_df = pd.read_excel(r\"Input\\\\\"+'master_file.xlsx')\n",
    "\n",
    "# Process the files and get the new and changed records\n",
    "newdf, changesdf = process_month_files(master_df, month_files, cols_to_check_gha, cols_to_check_positions)\n",
    "\n",
    "# Optionally, save the new and changed records to Excel files for further analysis\n",
    "newdf.to_excel(r\"Input\\\\\"+'New_Records.xlsx', index=False)\n",
    "changesdf.to_excel(r\"Input\\\\\"+'Changed_Records.xlsx', index=False)\n",
    "\n",
    "# Print the new and changed records dataframes for review\n",
    "print(\"New Records DataFrame:\")\n",
    "print(newdf.head())\n",
    "\n",
    "print(\"\\nChanged Records DataFrame:\")\n",
    "print(changesdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb939fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of columns to track for changes\n",
    "columns_to_check = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name', 'Work Location City']\n",
    "\n",
    "def track_changes_across_months(master_df, mom_gha_file, mom_open_positions_file, month):\n",
    "    # Ensure consistency in data types\n",
    "    master_df['Position ID'] = master_df['Position ID'].astype(str)\n",
    "    mom_gha_file['Position ID'] = mom_gha_file['Position ID'].astype(str)\n",
    "    mom_gha_file['Employee ID'] = mom_gha_file['Employee ID'].astype(str)\n",
    "    mom_open_positions_file['Position ID'] = mom_open_positions_file['Position ID'].astype(str)\n",
    "\n",
    "    # Initialize DataFrames to store changed and updated records\n",
    "    changed_rows = []\n",
    "    updated_rows = []\n",
    "\n",
    "    # Combine the merged dataframe with previous month's data\n",
    "    merged_df = master_df.copy()\n",
    "\n",
    "    # Track changes in GHA file (source == 'gha')\n",
    "    for index, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "        emp_id = row['Employee ID']\n",
    "        \n",
    "        # Filter the mom_gha_file for the matching Position ID and Employee ID\n",
    "        gha_match = mom_gha_file[(mom_gha_file['Position ID'] == pos_id) & (mom_gha_file['Employee ID'] == emp_id)]\n",
    "\n",
    "        if not gha_match.empty:\n",
    "            changes = []\n",
    "            for col in columns_to_check:\n",
    "                if row[col] != gha_match.iloc[0][col]:  # Compare values for the specified columns\n",
    "                    changes.append(f\"{col} Changed\")\n",
    "\n",
    "            if changes:\n",
    "                updated_row = row.copy()\n",
    "                updated_row['Description'] = '; '.join(changes)\n",
    "                updated_row['Month Changed'] = month\n",
    "                updated_rows.append(updated_row)\n",
    "\n",
    "            # If combination of Position ID and Employee ID has changed (new employee or position), track as changed\n",
    "            if len(gha_match) > 1:  # More than one match, indicating a position/employee mismatch\n",
    "                changed_row = row.copy()\n",
    "                changed_row['Description'] = 'Position/Employee ID mismatch'\n",
    "                changed_row['Month Changed'] = month\n",
    "                changed_rows.append(changed_row)\n",
    "\n",
    "    # Track changes in Open Positions file (source == 'open positions')\n",
    "    for index, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "\n",
    "        # Filter the mom_open_positions_file for the matching Position ID\n",
    "        open_pos_match = mom_open_positions_file[mom_open_positions_file['Position ID'] == pos_id]\n",
    "\n",
    "        if not open_pos_match.empty:\n",
    "            changes = []\n",
    "            for col in columns_to_check:\n",
    "                # Exclude Work Location City and Employee ID from the comparison for Open Position\n",
    "                if col != 'Work Location City' and col != 'Employee ID' and row[col] != open_pos_match.iloc[0][col]:\n",
    "                    changes.append(f\"{col} Changed\")\n",
    "\n",
    "            if changes:\n",
    "                updated_row = row.copy()\n",
    "                updated_row['Description'] = '; '.join(changes)\n",
    "                updated_row['Month Changed'] = month\n",
    "                updated_rows.append(updated_row)\n",
    "\n",
    "    # Convert lists to DataFrames\n",
    "    changed_rows_df = pd.DataFrame(changed_rows)\n",
    "    updated_rows_df = pd.DataFrame(updated_rows)\n",
    "\n",
    "    return changed_rows_df, updated_rows_df\n",
    "\n",
    "# Example usage:\n",
    "current_month = 'Mar-24'\n",
    "changed_rows_df, updated_rows_df = track_changes_across_months(master_df, mom_gha_file, mom_open_positions_file, current_month)\n",
    "\n",
    "# Display the result\n",
    "print(\"Changed Rows DataFrame:\")\n",
    "print(changed_rows_df)\n",
    "\n",
    "print(\"\\nUpdated Rows DataFrame:\")\n",
    "print(updated_rows_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new_records with the same columns as master_df plus 'Month_Added'\n",
    "new_records = pd.DataFrame(columns=master_df.columns.tolist() + ['Month_Added'])\n",
    "\n",
    "# Define function to process each month\n",
    "def process_single_month(master_df, month, gha_file, open_pos_file, new_records):\n",
    "    max_length = master_df['Position ID'].str.len().max()\n",
    "\n",
    "    # Standardize Position IDs\n",
    "    gha_file['Position ID'] = gha_file['Position ID'].str.zfill(max_length)\n",
    "    open_pos_file['Position ID'] = open_pos_file['Position ID'].str.zfill(max_length)\n",
    "    \n",
    "    # Update master_df with 1/0 based on presence in GHA and Open Positions\n",
    "    master_df[month] = np.where(\n",
    "        master_df['Source'] == 'GHA', \n",
    "        master_df['Position ID'].apply(lambda x: 1 if x in gha_file['Position ID'].values else 0),\n",
    "        np.where(\n",
    "            master_df['Source'] == 'Open Positions', \n",
    "            master_df['Position ID'].apply(lambda x: 1 if x in open_pos_file['Position ID'].values else 0),\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Identify new records in GHA not in master_df or previously in new_records\n",
    "    gha_new_records = gha_file[~gha_file['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "    gha_new_records = gha_new_records.assign(Source='GHA', Month_Added=month)\n",
    "\n",
    "    # Identify new records in Open Positions not in master_df or previously in new_records\n",
    "    open_pos_new_records = open_pos_file[~open_pos_file['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "    open_pos_new_records = open_pos_new_records.assign(Source='Open Positions', Month_Added=month)\n",
    "\n",
    "    # Combine new records found this month into one DataFrame\n",
    "    new_month_records = pd.concat([gha_new_records, open_pos_new_records], ignore_index=True)\n",
    "\n",
    "    # Add presence columns for each month in new_records, filling prior months with 0\n",
    "    for mth in master_df.columns[2:]:  # Assuming month columns start from index 2\n",
    "        if mth < month:\n",
    "            new_month_records[mth] = 0  # Set prior months to 0\n",
    "        elif mth == month:\n",
    "            new_month_records[mth] = new_month_records.apply(\n",
    "                lambda row: 1 if row['Position ID'] in gha_file['Position ID'].values or row['Position ID'] in open_pos_file['Position ID'].values else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            new_month_records[mth] = np.nan\n",
    "\n",
    "    # Trim new_month_records to only include columns in master_df + 'Month_Added'\n",
    "    new_month_records = new_month_records[master_df.columns.tolist() + ['Month_Added']]\n",
    "\n",
    "    # Append to new_records DataFrame\n",
    "    new_records = pd.concat([new_records, new_month_records], ignore_index=True)\n",
    "\n",
    "    return master_df, new_records\n",
    "\n",
    "# Process each month\n",
    "for month, gha_file in gha_monthly_files.items():\n",
    "    open_pos_file = open_pos_monthly_files[month]\n",
    "    master_df, new_records = process_single_month(master_df, month, gha_file, open_pos_file, new_records)\n",
    "\n",
    "# Fill any remaining NaN values in new_records with 0 for months not reached yet\n",
    "for col in master_df.columns[2:]:  # Month columns assumed to start from index 2\n",
    "    new_records[col].fillna(0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrames\n",
    "print(\"Updated Master DataFrame:\\n\", master_df)\n",
    "print(\"\\nNew Records DataFrame:\\n\", new_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10657e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Master DataFrame:\n",
      "   Position ID          Source  Jan 24  Feb 24  Mar 24\n",
      "0      000123             GHA     1.0     0.0     1.0\n",
      "1      000456  Open Positions     1.0     0.0     0.0\n",
      "2      000789             GHA     0.0     1.0     0.0\n",
      "3      001001  Open Positions     0.0     1.0     1.0\n",
      "\n",
      "New Records DataFrame:\n",
      "   Position ID          Source Month Added Month_Added\n",
      "0      002002             GHA         NaN      Feb 24\n",
      "1      004004  Open Positions         NaN      Feb 24\n",
      "2      003003             GHA         NaN      Mar 24\n",
      "3      005005  Open Positions         NaN      Mar 24\n"
     ]
    }
   ],
   "source": [
    "# Declare new_records with relevant columns\n",
    "new_records = pd.DataFrame(columns=['Position ID', 'Source', 'Month Added'])\n",
    "\n",
    "def process_monthly_data(master_df, gha_monthly_files, open_pos_monthly_files):\n",
    "    global new_records\n",
    "    max_length = master_df['Position ID'].str.len().max()\n",
    "    \n",
    "    for month in gha_monthly_files.keys():\n",
    "        gha_df = gha_monthly_files[month].copy()\n",
    "        open_pos_df = open_pos_monthly_files[month].copy()\n",
    "\n",
    "        # Standardize Position IDs\n",
    "        gha_df['Position ID'] = gha_df['Position ID'].str.zfill(max_length)\n",
    "        open_pos_df['Position ID'] = open_pos_df['Position ID'].str.zfill(max_length)\n",
    "        \n",
    "        # Update master_df with 1/0 based on presence in GHA and Open Positions\n",
    "        master_df[month] = np.where(\n",
    "            master_df['Source'] == 'GHA', \n",
    "            master_df['Position ID'].apply(lambda x: 1 if x in gha_df['Position ID'].values else 0),\n",
    "            np.where(\n",
    "                master_df['Source'] == 'Open Positions', \n",
    "                master_df['Position ID'].apply(lambda x: 1 if x in open_pos_df['Position ID'].values else 0),\n",
    "                np.nan\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Identify new records in GHA not in master_df or previously in new_records\n",
    "        gha_new_records = gha_df[~gha_df['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "        gha_new_records = gha_new_records.assign(Source='GHA', Month_Added=month)\n",
    "\n",
    "        # Identify new records in Open Positions not in master_df or previously in new_records\n",
    "        open_pos_new_records = open_pos_df[~open_pos_df['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "        open_pos_new_records = open_pos_new_records.assign(Source='Open Positions', Month_Added=month)\n",
    "\n",
    "        # Append unique new records from both GHA and Open Positions\n",
    "        new_records = pd.concat([new_records, gha_new_records, open_pos_new_records], ignore_index=True)\n",
    "    \n",
    "    return master_df, new_records\n",
    "\n",
    "# Call the function and get updated master_df and new_records\n",
    "master_df, new_records = process_monthly_data(master_df, gha_monthly_files, open_pos_monthly_files)\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "print(\"Updated Master DataFrame:\\n\", master_df)\n",
    "print(\"\\nNew Records DataFrame:\\n\", new_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38ece7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Additional columns to track for changes and their descriptions\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize changes DataFrame\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load GHA and Open Position data for the current month\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Rename 'Position Number' to 'Position ID' to match master_df\n",
    "    gha_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "    open_pos_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "\n",
    "    # Standardize Position ID and Employee ID to strings, with zero-padding for Position ID\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    gha_df['Employee ID'] = gha_df['Employee ID'].astype(str)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "\n",
    "    # Print column names to verify alignment\n",
    "    print(\"Debug: Columns in master_df:\", master_df.columns)\n",
    "    print(\"Debug: Columns in gha_df:\", gha_df.columns)\n",
    "    \n",
    "    # Merge on Position ID and Employee ID, with unique suffixes\n",
    "    merged_df = pd.merge(\n",
    "        master_df, gha_df,\n",
    "        on=['Position ID', 'Employee ID'],\n",
    "        how='outer',\n",
    "        suffixes=('_master', '_gha')\n",
    "    )\n",
    "    \n",
    "    # Check merged columns to verify expected columns are present\n",
    "    print(\"Debug: Columns in merged_df after merging:\", merged_df.columns)\n",
    "    \n",
    "    # If expected columns are missing, print a warning and skip the iteration\n",
    "    if 'Employee ID_master' not in merged_df.columns or 'Employee ID_gha' not in merged_df.columns:\n",
    "        print(\"Warning: Expected columns 'Employee ID_master' and 'Employee ID_gha' not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Track changes in Position-Employee combinations\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "        master_emp_id, gha_emp_id = row.get('Employee ID_master'), row.get('Employee ID_gha')\n",
    "        \n",
    "        # Detect Employee ID changes for the same Position ID\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Detect changes in additional columns\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row.get(f\"{col}_master\"), row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Drop duplicates and keep the first occurrence\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# Output the changes DataFrame\n",
    "print(\"Final changes_df:\\n\", changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Additional columns and descriptions for changes\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize the changes DataFrame with the required columns\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load data\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Standardize 'Position ID' formatting\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    \n",
    "    # Filter out rows with unspecified or empty Position IDs or Employee IDs in GHA data\n",
    "    gha_df = gha_df[(gha_df['Position ID'] != 'unspecified') & (gha_df['Position ID'] != '')]\n",
    "    gha_df = gha_df[(gha_df['Employee ID'] != 'unspecified') & (gha_df['Employee ID'] != '')]\n",
    "\n",
    "    # Merge GHA data with master data\n",
    "    print(\"Debug: GHA Columns before merging:\", gha_df.columns)\n",
    "    print(\"Debug: Master Columns before merging:\", master_df.columns)\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        master_df, gha_df, \n",
    "        on=['Position ID', 'Employee ID'], \n",
    "        how='outer', \n",
    "        suffixes=('_master', '_gha')\n",
    "    )\n",
    "    \n",
    "    # Debug column names after merging\n",
    "    print(\"Debug: Columns in merged_df after merging:\", merged_df.columns)\n",
    "    \n",
    "    # If columns aren't named as expected, skip further processing in this loop iteration\n",
    "    if 'Employee ID_master' not in merged_df.columns or 'Employee ID_gha' not in merged_df.columns:\n",
    "        print(\"Warning: Expected columns 'Employee ID_master' and 'Employee ID_gha' not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Detect changes\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id, emp_id = row['Position ID'], row['Employee ID']\n",
    "        master_emp_id, gha_emp_id = row['Employee ID_master'], row['Employee ID_gha']\n",
    "        \n",
    "        # Record changes in Position ID and Employee ID combinations\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Check for additional column changes\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row.get(f\"{col}_master\"), row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Remove duplicates\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# Output the changes DataFrame\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ad55b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position ID Employee ID  Jan 24  Feb 24  Mar 24\n",
      "0      000123        E001       1       1       0\n",
      "1      000456        E002       1       0       0\n",
      "2      000789        E003       0       0       1\n"
     ]
    }
   ],
   "source": [
    "#option 1\n",
    "import pandas as pd\n",
    "\n",
    "# Define maximum digits for 'Position ID' formatting, based on master file creation\n",
    "max_digits = max(len(str(pos_id)) for pos_id in master_df['Position ID'].astype(str))\n",
    "\n",
    "# Define additional columns to check for changes, with corresponding descriptions\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize empty DataFrame to store changes\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load and prepare GHA and Open Position data for the current month\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Ensure consistent 'Position ID' format (use zfill if needed)\n",
    "    if 'Position Number' in gha_df.columns:\n",
    "        gha_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    \n",
    "    # Filter out records where 'Position ID' or 'Employee ID' is unspecified or blank\n",
    "    gha_df = gha_df[(gha_df['Position ID'] != 'unspecified') & (gha_df['Position ID'] != '')]\n",
    "    gha_df = gha_df[(gha_df['Employee ID'] != 'unspecified') & (gha_df['Employee ID'] != '')]\n",
    "    \n",
    "    # Merge GHA data with master_df based on Position ID and Employee ID\n",
    "    merged_df = pd.merge(master_df, gha_df, on=['Position ID', 'Employee ID'], how='outer', suffixes=('_master', '_gha'))\n",
    "\n",
    "    # Identify changes in 'Position ID' and 'Employee ID' combinations, as well as additional columns\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id, emp_id = row['Position ID'], row['Employee ID']\n",
    "        master_emp_id, gha_emp_id = row['Employee ID_master'], row['Employee ID_gha']\n",
    "        \n",
    "        # Check for changes in Position ID and Employee ID combinations\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            # Log change details if Position ID has a different Employee ID\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Check for changes in additional columns\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row[f\"{col}_master\"], row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Drop duplicates to avoid recording repeated changes in subsequent months\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# View or save changes_df to verify the output\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51c0b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated GHA Records:\n",
      "   Position ID Employee ID       Col1  Col2 Col3\n",
      "1           20        E002  B_Updated   250    Y\n",
      "New GHA Records:\n",
      "   Position ID Employee ID Col1  Col2 Col3\n",
      "2           40        E004    D   400    W\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# Strip spaces from column names to avoid mismatch\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "feb24_gha_df.columns = feb24_gha_df.columns.str.strip()\n",
    "feb24_open_df.columns = feb24_open_df.columns.str.strip()\n",
    "mar24_gha_df.columns = mar24_gha_df.columns.str.strip()\n",
    "mar24_open_df.columns = mar24_open_df.columns.str.strip()\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, master_df):\n",
    "    updated_records = []\n",
    "\n",
    "    # Loop through current dataframe and compare each row with the master dataframe\n",
    "    for index, row in current_df.iterrows():\n",
    "        # Check if the row has a corresponding row in the master dataframe\n",
    "        match = master_df[(master_df['Position ID'] == row['Position ID']) & \n",
    "                          (master_df['Employee ID'] == row['Employee ID'])]\n",
    "\n",
    "        if not match.empty:\n",
    "            # Compare columns (excluding Position ID and Employee ID)\n",
    "            for col in row.index:\n",
    "                if col not in ['Position ID', 'Employee ID']:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        updated_records.append(row)\n",
    "                        break\n",
    "    \n",
    "    # Convert updated records to a DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, master_df):\n",
    "    # Find rows in current_df that don't exist in master_df\n",
    "    new_records = current_df[~current_df['Position ID'].isin(master_df['Position ID']) | \n",
    "                             ~current_df['Employee ID'].isin(master_df['Employee ID'])]\n",
    "    return new_records\n",
    "\n",
    "# Part 1: Find updated records in Feb24 GHA data\n",
    "updated_gha_records = find_updated_records(feb24_gha_df, master_df)\n",
    "print(\"Updated GHA Records:\")\n",
    "print(updated_gha_records)\n",
    "\n",
    "# Part 2: Find new records in Feb24 GHA data\n",
    "new_gha_records = find_new_records(feb24_gha_df, master_df)\n",
    "print(\"New GHA Records:\")\n",
    "print(new_gha_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "149fc18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved in the 'Output' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "files = {\n",
    "    \"Feb24_gha\": pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\"),\n",
    "    \"Mar24_gha\": pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\"),\n",
    "    \"Feb24_open\": pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\"),\n",
    "    \"Mar24_open\": pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "}\n",
    "\n",
    "# Ensure consistent column names\n",
    "for key in files.keys():\n",
    "    files[key].columns = files[key].columns.str.strip()\n",
    "\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, reference_df, month_year, source, key_cols):\n",
    "    updated_records = []\n",
    "\n",
    "    for index, row in current_df.iterrows():\n",
    "        # Find matching row in reference_df based on key_cols\n",
    "        match = reference_df\n",
    "        for key in key_cols:\n",
    "            match = match[match[key] == row[key]]\n",
    "        \n",
    "        if not match.empty:\n",
    "            cols_changed = []\n",
    "            for col in current_df.columns:\n",
    "                if col not in key_cols and col in reference_df.columns:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        cols_changed.append(col)\n",
    "            \n",
    "            if cols_changed:\n",
    "                row_data = row.to_dict()\n",
    "                row_data[\"Month Changed\"] = month_year\n",
    "                row_data[\"Cols Changed\"] = \"; \".join(cols_changed)\n",
    "                row_data[\"Source\"] = source\n",
    "                updated_records.append(row_data)\n",
    "\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, reference_df, month_year, key_cols):\n",
    "    new_records = current_df[\n",
    "        ~current_df[key_cols].apply(tuple, axis=1).isin(reference_df[key_cols].apply(tuple, axis=1))\n",
    "    ]\n",
    "    new_records = new_records.copy()\n",
    "    new_records[\"Month Added\"] = month_year\n",
    "    return new_records\n",
    "\n",
    "# Process all GHA files\n",
    "gha_key_cols = [\"Position ID\", \"Employee ID\"]\n",
    "open_pos_key_cols = [\"Position ID\"]  # No Employee ID for Open Position\n",
    "\n",
    "all_updated_records = []\n",
    "all_new_records = []\n",
    "\n",
    "for file_name, df in files.items():\n",
    "    month_year = file_name.split(\"_\")[0]  # Extract month from filename\n",
    "    source_type = file_name.split(\"_\")[1]  # Extract source type from filename\n",
    "\n",
    "    if source_type == \"gha\":\n",
    "        # Process GHA files\n",
    "        updated_records = find_updated_records(df, master_df, month_year, source_type, gha_key_cols)\n",
    "        new_records = find_new_records(df, master_df, month_year, gha_key_cols)\n",
    "    elif source_type == \"open\":\n",
    "        # Process Open Position files\n",
    "        updated_records = find_updated_records(df, master_df, month_year, source_type, open_pos_key_cols)\n",
    "        new_records = find_new_records(df, master_df, month_year, open_pos_key_cols)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Add to the master results\n",
    "    if not updated_records.empty:\n",
    "        all_updated_records.append(updated_records)\n",
    "    if not new_records.empty:\n",
    "        all_new_records.append(new_records)\n",
    "\n",
    "# Combine all results into final DataFrames\n",
    "final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "# Save results\n",
    "output_dir = \"Input\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_updated_records.to_excel(output_dir + \"Updated_Records.xlsx\", index=False)\n",
    "final_new_records.to_excel(output_dir + \"New_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved in the 'Output' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "080c1d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHA processing complete. Results saved in the 'Output' folder.\n",
      "Open Position processing complete. Results saved in the 'Output' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "gha_files = [\"Feb24_gha.xlsx\", \"Mar24_gha.xlsx\"]  # Extend this list as new files arrive\n",
    "open_files = [\"Feb24_open.xlsx\", \"Mar24_open.xlsx\"]  # Extend similarly for open position files\n",
    "\n",
    "# Strip column names\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "# Ensure column name consistency\n",
    "def load_and_prepare(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, reference_df, month_year, source, key_cols):\n",
    "    updated_records = []\n",
    "    \n",
    "    for index, row in current_df.iterrows():\n",
    "        match = reference_df\n",
    "        for key in key_cols:\n",
    "            match = match[match[key] == row[key]]\n",
    "        \n",
    "        if not match.empty:\n",
    "            cols_changed = []\n",
    "            for col in current_df.columns:\n",
    "                if col not in key_cols and col in reference_df.columns:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        cols_changed.append(col)\n",
    "            \n",
    "            if cols_changed:\n",
    "                row_data = row.to_dict()\n",
    "                row_data[\"Month Changed\"] = month_year\n",
    "                row_data[\"Cols Changed\"] = \"; \".join(cols_changed)\n",
    "                row_data[\"Source\"] = source\n",
    "                updated_records.append(row_data)\n",
    "\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, reference_df, month_year, key_cols):\n",
    "    new_records = current_df[\n",
    "        ~current_df[key_cols].apply(tuple, axis=1).isin(reference_df[key_cols].apply(tuple, axis=1))\n",
    "    ]\n",
    "    new_records = new_records.copy()\n",
    "    new_records[\"Month Added\"] = month_year\n",
    "    return new_records\n",
    "\n",
    "# Main function to process GHA files\n",
    "def process_gha_files(master_df, files, key_cols):\n",
    "    all_updated_records = []\n",
    "    all_new_records = []\n",
    "\n",
    "    previous_df = master_df  # Start with master as the reference\n",
    "    for file in files:\n",
    "        file_path = f\"Input\\\\{file}\"\n",
    "        current_df = load_and_prepare(file_path)\n",
    "\n",
    "        # Extract month and source\n",
    "        month_year = file.split(\"_\")[0]\n",
    "        source_type = \"gha\"\n",
    "\n",
    "        # Find updated and new records\n",
    "        updated_records = find_updated_records(current_df, previous_df, month_year, source_type, key_cols)\n",
    "        new_records = find_new_records(current_df, previous_df, month_year, key_cols)\n",
    "\n",
    "        # Store results\n",
    "        if not updated_records.empty:\n",
    "            all_updated_records.append(updated_records)\n",
    "        if not new_records.empty:\n",
    "            all_new_records.append(new_records)\n",
    "\n",
    "        # Update reference for next iteration\n",
    "        previous_df = current_df\n",
    "\n",
    "    # Combine results\n",
    "    final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "    final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "    return final_updated_records, final_new_records\n",
    "\n",
    "# Process GHA files\n",
    "gha_key_cols = [\"Position ID\", \"Employee ID\"]\n",
    "final_updated_gha, final_new_gha = process_gha_files(master_df, gha_files, gha_key_cols)\n",
    "\n",
    "# Save results for GHA\n",
    "output_dir = \"Input\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_updated_gha.to_excel(output_dir + \"Updated_GHA_Records.xlsx\", index=False)\n",
    "final_new_gha.to_excel(output_dir + \"New_GHA_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"GHA processing complete. Results saved in the 'Output' folder.\")\n",
    "\n",
    "# Extend for Open Position files\n",
    "def process_open_position_files(master_df, files, key_cols):\n",
    "    all_updated_records = []\n",
    "    all_new_records = []\n",
    "\n",
    "    previous_df = master_df  # Start with master as the reference\n",
    "    for file in files:\n",
    "        file_path = f\"Input\\\\{file}\"\n",
    "        current_df = load_and_prepare(file_path)\n",
    "\n",
    "        # Extract month and source\n",
    "        month_year = file.split(\"_\")[0]\n",
    "        source_type = \"open\"\n",
    "\n",
    "        # Find updated and new records\n",
    "        updated_records = find_updated_records(current_df, previous_df, month_year, source_type, key_cols)\n",
    "        new_records = find_new_records(current_df, previous_df, month_year, key_cols)\n",
    "\n",
    "        # Store results\n",
    "        if not updated_records.empty:\n",
    "            all_updated_records.append(updated_records)\n",
    "        if not new_records.empty:\n",
    "            all_new_records.append(new_records)\n",
    "\n",
    "        # Update reference for next iteration\n",
    "        previous_df = current_df\n",
    "\n",
    "    # Combine results\n",
    "    final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "    final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "    return final_updated_records, final_new_records\n",
    "\n",
    "# Process Open Position files\n",
    "open_key_cols = [\"Position ID\"]  # No Employee ID for Open Position\n",
    "final_updated_open, final_new_open = process_open_position_files(master_df, open_files, open_key_cols)\n",
    "\n",
    "# Save results for Open Position\n",
    "final_updated_open.to_excel(output_dir + \"Updated_Open_Position_Records.xlsx\", index=False)\n",
    "final_new_open.to_excel(output_dir + \"New_Open_Position_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"Open Position processing complete. Results saved in the 'Output' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b928900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Combine updated and new records into a final DataFrame\n",
    "def create_final_dataframe(updated_df, new_df):\n",
    "    # Add missing columns to ensure consistent structure\n",
    "    required_columns = [\"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\", \"Source\", \"Month Added\"]\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in updated_df.columns:\n",
    "            updated_df[col] = None\n",
    "        if col not in new_df.columns:\n",
    "            new_df[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    updated_df = updated_df[required_columns]\n",
    "    new_df = new_df[required_columns]\n",
    "    \n",
    "    # Concatenate both DataFrames\n",
    "    final_df = pd.concat([updated_df, new_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Create final DataFrames for GHA and Open Position files\n",
    "final_gha_df = create_final_dataframe(final_updated_gha, final_new_gha)\n",
    "final_open_df = create_final_dataframe(final_updated_open, final_new_open)\n",
    "\n",
    "# Save the final combined data\n",
    "final_gha_df.to_excel(output_dir + \"Final_GHA_Data.xlsx\", index=False)\n",
    "final_open_df.to_excel(output_dir + \"Final_Open_Position_Data.xlsx\", index=False)\n",
    "\n",
    "print(\"Final combined data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3b84b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined data saved to Input\\Final_Combined_Data.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# Combine GHA and Open Position Data into a Single DataFrame\n",
    "def create_combined_dataframe(updated_gha, new_gha, updated_open, new_open):\n",
    "    # Concatenate updated and new records for GHA and Open Position\n",
    "    combined_gha = pd.concat([updated_gha, new_gha], ignore_index=True)\n",
    "    combined_open = pd.concat([updated_open, new_open], ignore_index=True)\n",
    "\n",
    "    # Add missing columns to ensure consistent structure\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in combined_gha.columns:\n",
    "            combined_gha[col] = None\n",
    "        if col not in combined_open.columns:\n",
    "            combined_open[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    combined_gha = combined_gha[required_columns]\n",
    "    combined_open = combined_open[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column to differentiate records\n",
    "    combined_gha['Data Type'] = 'GHA'\n",
    "    combined_open['Data Type'] = 'Open Position'\n",
    "\n",
    "    # Concatenate GHA and Open Position data into one DataFrame\n",
    "    final_combined_df = pd.concat([combined_gha, combined_open], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Create final combined DataFrame\n",
    "final_combined_df = create_combined_dataframe(\n",
    "    final_updated_gha, final_new_gha, final_updated_open, final_new_open\n",
    ")\n",
    "\n",
    "# Save the final combined data\n",
    "output_file = output_dir + \"Final_Combined_Data.xlsx\"\n",
    "final_combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Final combined data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef55835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of monthly files\n",
    "monthly_files = {\n",
    "    'Jan 24': (\"Input\\\\gha_jan_24.xlsx\", \"Input\\\\jan_24 open pos.xlsx\"),\n",
    "    'Feb 24': (\"Input\\\\global headcount_02_24.xlsx\", \"Input\\\\feb open pos.xlsx\"),\n",
    "    # Add more entries as needed...\n",
    "}\n",
    "\n",
    "# Create combined DataFrame for all months\n",
    "def process_all_months(master_file_path, monthly_files, output_file):\n",
    "    # Load master file\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "\n",
    "    # Initialize empty DataFrames for final output\n",
    "    final_gha_combined = pd.DataFrame()\n",
    "    final_open_combined = pd.DataFrame()\n",
    "\n",
    "    for month, (gha_file, open_pos_file) in monthly_files.items():\n",
    "        # Load GHA and Open Position files for the month\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        open_pos_df = pd.read_excel(open_pos_file)\n",
    "\n",
    "        # Process GHA and Open Position files against the master\n",
    "        updated_gha, new_gha = find_updated_and_new_records(gha_df, master_df, month, 'GHA')\n",
    "        updated_open, new_open = find_updated_and_new_records(open_pos_df, master_df, month, 'Open Position')\n",
    "\n",
    "        # Append processed data to the final DataFrames\n",
    "        final_gha_combined = pd.concat([final_gha_combined, updated_gha, new_gha], ignore_index=True)\n",
    "        final_open_combined = pd.concat([final_open_combined, updated_open, new_open], ignore_index=True)\n",
    "\n",
    "        # Update master for the next iteration\n",
    "        master_df = gha_df  # Assuming GHA is the master dataset\n",
    "\n",
    "    # Combine GHA and Open Position into a single DataFrame\n",
    "    final_combined_df = combine_all_records(final_gha_combined, final_open_combined)\n",
    "\n",
    "    # Save to Excel\n",
    "    final_combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"Final combined data saved to {output_file}.\")\n",
    "\n",
    "# Function to find updated and new records\n",
    "def find_updated_and_new_records(file_df, master_df, month, source_type):\n",
    "    # Ensure Position ID column exists\n",
    "    if \"Position ID\" not in file_df.columns:\n",
    "        raise KeyError(f\"'Position ID' not found in {source_type} data for {month}.\")\n",
    "\n",
    "    # Identify updated and new records\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "    for _, row in file_df.iterrows():\n",
    "        position_id = row.get(\"Position ID\")\n",
    "        master_row = master_df[master_df[\"Position ID\"] == position_id]\n",
    "\n",
    "        if not master_row.empty:\n",
    "            # Check for updated columns\n",
    "            changes = []\n",
    "            for col in file_df.columns:\n",
    "                if col in master_row and not pd.isna(row[col]) and row[col] != master_row[col].values[0]:\n",
    "                    changes.append(col)\n",
    "            if changes:\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \"; \".join(changes)\n",
    "                updated_row[\"Source\"] = source_type\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Add new record\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"Month Added\"] = month\n",
    "            new_row[\"Source\"] = source_type\n",
    "            new_records.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "\n",
    "    return updated_df, new_df\n",
    "\n",
    "# Function to combine GHA and Open Position records\n",
    "def combine_all_records(final_gha_combined, final_open_combined):\n",
    "    # Add missing columns for consistency\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in final_gha_combined.columns:\n",
    "            final_gha_combined[col] = None\n",
    "        if col not in final_open_combined.columns:\n",
    "            final_open_combined[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    final_gha_combined = final_gha_combined[required_columns]\n",
    "    final_open_combined = final_open_combined[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column\n",
    "    final_gha_combined[\"Data Type\"] = \"GHA\"\n",
    "    final_open_combined[\"Data Type\"] = \"Open Position\"\n",
    "\n",
    "    # Combine all records\n",
    "    final_combined_df = pd.concat([final_gha_combined, final_open_combined], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Specify master file and output file paths\n",
    "master_file_path = \"Input\\\\master_file.xlsx\"\n",
    "output_file = \"Output\\\\Final_Combined_Data.xlsx\"\n",
    "\n",
    "# Process all files\n",
    "process_all_months(master_file_path, monthly_files, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of monthly files\n",
    "monthly_files = {\n",
    "    'Jan 24': (\"Input\\\\gha_jan_24.xlsx\", \"Input\\\\jan_24 open pos.xlsx\"),\n",
    "    'Feb 24': (\"Input\\\\global headcount_02_24.xlsx\", \"Input\\\\feb open pos.xlsx\"),\n",
    "    # Add more entries as needed...\n",
    "}\n",
    "\n",
    "# Columns for comparison by file type\n",
    "comparison_columns = {\n",
    "    'GHA': [\"Employee ID\", \"Position ID\", \"Col1\", \"Col2\"],  # Specify GHA-specific columns\n",
    "    'Open Position': [\"Position ID\", \"Col1\", \"ColZ\"]        # Specify Open Position-specific columns\n",
    "}\n",
    "\n",
    "# Create combined DataFrame for all months\n",
    "def process_all_months(master_file_path, monthly_files, comparison_columns, output_file):\n",
    "    # Load master file\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "\n",
    "    # Initialize empty DataFrames for final output\n",
    "    final_gha_combined = pd.DataFrame()\n",
    "    final_open_combined = pd.DataFrame()\n",
    "\n",
    "    for month, (gha_file, open_pos_file) in monthly_files.items():\n",
    "        # Load GHA and Open Position files for the month\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        open_pos_df = pd.read_excel(open_pos_file)\n",
    "\n",
    "        # Process GHA and Open Position files against the master\n",
    "        updated_gha, new_gha = find_updated_and_new_records(\n",
    "            gha_df, master_df, month, 'GHA', comparison_columns['GHA']\n",
    "        )\n",
    "        updated_open, new_open = find_updated_and_new_records(\n",
    "            open_pos_df, master_df, month, 'Open Position', comparison_columns['Open Position']\n",
    "        )\n",
    "\n",
    "        # Append processed data to the final DataFrames\n",
    "        final_gha_combined = pd.concat([final_gha_combined, updated_gha, new_gha], ignore_index=True)\n",
    "        final_open_combined = pd.concat([final_open_combined, updated_open, new_open], ignore_index=True)\n",
    "\n",
    "        # Update master for the next iteration\n",
    "        master_df = gha_df  # Assuming GHA is the master dataset\n",
    "\n",
    "    # Combine GHA and Open Position into a single DataFrame\n",
    "    final_combined_df = combine_all_records(final_gha_combined, final_open_combined)\n",
    "\n",
    "    # Save to Excel\n",
    "    final_combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"Final combined data saved to {output_file}.\")\n",
    "\n",
    "# Function to find updated and new records\n",
    "def find_updated_and_new_records(file_df, master_df, month, source_type, comparison_cols):\n",
    "    # Ensure Position ID column exists\n",
    "    if \"Position ID\" not in file_df.columns:\n",
    "        raise KeyError(f\"'Position ID' not found in {source_type} data for {month}.\")\n",
    "\n",
    "    # Identify updated and new records\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "    for _, row in file_df.iterrows():\n",
    "        position_id = row.get(\"Position ID\")\n",
    "        master_row = master_df[master_df[\"Position ID\"] == position_id]\n",
    "\n",
    "        if not master_row.empty:\n",
    "            # Check for updated columns\n",
    "            changes = []\n",
    "            for col in comparison_cols:\n",
    "                if col in master_row and not pd.isna(row[col]) and row[col] != master_row[col].values[0]:\n",
    "                    changes.append(col)\n",
    "            if changes:\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \"; \".join(changes)\n",
    "                updated_row[\"Source\"] = source_type\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Add new record\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"Month Added\"] = month\n",
    "            new_row[\"Source\"] = source_type\n",
    "            new_records.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "\n",
    "    return updated_df, new_df\n",
    "\n",
    "# Function to combine GHA and Open Position records\n",
    "def combine_all_records(final_gha_combined, final_open_combined):\n",
    "    # Add missing columns for consistency\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in final_gha_combined.columns:\n",
    "            final_gha_combined[col] = None\n",
    "        if col not in final_open_combined.columns:\n",
    "            final_open_combined[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    final_gha_combined = final_gha_combined[required_columns]\n",
    "    final_open_combined = final_open_combined[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column\n",
    "    final_gha_combined[\"Data Type\"] = \"GHA\"\n",
    "    final_open_combined[\"Data Type\"] = \"Open Position\"\n",
    "\n",
    "    # Combine all records\n",
    "    final_combined_df = pd.concat([final_gha_combined, final_open_combined], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Specify master file and output file paths\n",
    "master_file_path = \"Input\\\\master_file.xlsx\"\n",
    "output_file = \"Output\\\\Final_Combined_Data.xlsx\"\n",
    "\n",
    "# Process all files\n",
    "process_all_months(master_file_path, monthly_files, comparison_columns, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257226b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of monthly files\n",
    "monthly_files = {\n",
    "    'Jan 24': (\"Input\\\\gha_jan_24.xlsx\", \"Input\\\\jan_24 open pos.xlsx\"),\n",
    "    'Feb 24': (\"Input\\\\global headcount_02_24.xlsx\", \"Input\\\\feb open pos.xlsx\"),\n",
    "    # Add more entries as needed...\n",
    "}\n",
    "\n",
    "# Columns for comparison by file type\n",
    "comparison_columns = {\n",
    "    'GHA': [\"Employee ID\", \"Position ID\", \"Col1\", \"Col2\"],  # Specify GHA-specific columns\n",
    "    'Open Position': [\"Position ID\", \"Col1\", \"ColZ\"]        # Specify Open Position-specific columns\n",
    "}\n",
    "\n",
    "# Create combined DataFrame for all months\n",
    "def process_all_months(master_file_path, monthly_files, comparison_columns, output_file):\n",
    "    # Load master file\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "\n",
    "    # Initialize empty DataFrames for final output\n",
    "    final_gha_combined = pd.DataFrame()\n",
    "    final_open_combined = pd.DataFrame()\n",
    "\n",
    "    for month, (gha_file, open_pos_file) in monthly_files.items():\n",
    "        # Load GHA and Open Position files for the month\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        open_pos_df = pd.read_excel(open_pos_file)\n",
    "\n",
    "        # Process GHA and Open Position files against the master\n",
    "        updated_gha, new_gha = find_updated_and_new_records(\n",
    "            gha_df, master_df, month, 'GHA', comparison_columns\n",
    "        )\n",
    "        updated_open, new_open = find_updated_and_new_records(\n",
    "            open_pos_df, master_df, month, 'Open Position', comparison_columns\n",
    "        )\n",
    "\n",
    "        # Append processed data to the final DataFrames\n",
    "        final_gha_combined = pd.concat([final_gha_combined, updated_gha, new_gha], ignore_index=True)\n",
    "        final_open_combined = pd.concat([final_open_combined, updated_open, new_open], ignore_index=True)\n",
    "\n",
    "        # Update master for the next iteration\n",
    "        master_df = gha_df  # Assuming GHA is the master dataset\n",
    "\n",
    "    # Combine GHA and Open Position into a single DataFrame\n",
    "    final_combined_df = combine_all_records(final_gha_combined, final_open_combined)\n",
    "\n",
    "    # Save to Excel\n",
    "    final_combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"Final combined data saved to {output_file}.\")\n",
    "\n",
    "# Function to find updated and new records\n",
    "def find_updated_and_new_records(file_df, master_df, month, source_type, comparison_columns):\n",
    "    # Ensure Position ID column exists\n",
    "    if \"Position ID\" not in file_df.columns:\n",
    "        raise KeyError(f\"'Position ID' not found in {source_type} data for {month}.\")\n",
    "\n",
    "    # Identify updated and new records\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "    for _, row in file_df.iterrows():\n",
    "        # Determine the actual source dynamically (if column exists)\n",
    "        actual_source = row.get(\"Source\", source_type)\n",
    "\n",
    "        # Get comparison columns based on the source type\n",
    "        cols_to_check = comparison_columns.get(actual_source, [])\n",
    "\n",
    "        # Perform record comparisons\n",
    "        position_id = row.get(\"Position ID\")\n",
    "        master_row = master_df[master_df[\"Position ID\"] == position_id]\n",
    "\n",
    "        if not master_row.empty:\n",
    "            # Check for updated columns\n",
    "            changes = []\n",
    "            for col in cols_to_check:\n",
    "                if col in master_row and not pd.isna(row[col]) and row[col] != master_row[col].values[0]:\n",
    "                    changes.append(col)\n",
    "            if changes:\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \"; \".join(changes)\n",
    "                updated_row[\"Source\"] = actual_source\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Add new record\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"Month Added\"] = month\n",
    "            new_row[\"Source\"] = actual_source\n",
    "            new_records.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "\n",
    "    return updated_df, new_df\n",
    "\n",
    "# Function to combine GHA and Open Position records\n",
    "def combine_all_records(final_gha_combined, final_open_combined):\n",
    "    # Add missing columns for consistency\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in final_gha_combined.columns:\n",
    "            final_gha_combined[col] = None\n",
    "        if col not in final_open_combined.columns:\n",
    "            final_open_combined[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    final_gha_combined = final_gha_combined[required_columns]\n",
    "    final_open_combined = final_open_combined[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column\n",
    "    final_gha_combined[\"Data Type\"] = \"GHA\"\n",
    "    final_open_combined[\"Data Type\"] = \"Open Position\"\n",
    "\n",
    "    # Combine all records\n",
    "    final_combined_df = pd.concat([final_gha_combined, final_open_combined], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Specify master file and output file paths\n",
    "master_file_path = \"Input\\\\master_file.xlsx\"\n",
    "output_file = \"Output\\\\Final_Combined_Data.xlsx\"\n",
    "\n",
    "# Process all files\n",
    "process_all_months(master_file_path, monthly_files, comparison_columns, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of monthly files\n",
    "monthly_files = {\n",
    "    'Jan 24': (\"Input\\\\gha_jan_24.xlsx\", \"Input\\\\jan_24 open pos.xlsx\"),\n",
    "    'Feb 24': (\"Input\\\\global headcount_02_24.xlsx\", \"Input\\\\feb open pos.xlsx\"),\n",
    "    # Add more entries as needed...\n",
    "}\n",
    "\n",
    "# Columns for comparison by file type\n",
    "comparison_columns = {\n",
    "    'GHA': [\"Employee ID\", \"Position ID\", \"Col1\", \"Col2\"],  # Specify GHA-specific columns\n",
    "    'Open Position': [\"Position ID\", \"Col1\", \"ColZ\"]        # Specify Open Position-specific columns\n",
    "}\n",
    "\n",
    "# Create combined DataFrame for all months\n",
    "def process_all_months(master_file_path, monthly_files, comparison_columns, output_file):\n",
    "    # Load master file\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "\n",
    "    # Initialize empty DataFrames for final output\n",
    "    final_gha_combined = pd.DataFrame()\n",
    "    final_open_combined = pd.DataFrame()\n",
    "\n",
    "    for month, (gha_file, open_pos_file) in monthly_files.items():\n",
    "        # Load GHA and Open Position files for the month\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        open_pos_df = pd.read_excel(open_pos_file)\n",
    "\n",
    "        # Process GHA and Open Position files against the master\n",
    "        updated_gha, new_gha = find_updated_and_new_records(\n",
    "            gha_df, master_df, month, 'GHA', comparison_columns\n",
    "        )\n",
    "        updated_open, new_open = find_updated_and_new_records(\n",
    "            open_pos_df, master_df, month, 'Open Position', comparison_columns\n",
    "        )\n",
    "\n",
    "        # Append processed data to the final DataFrames\n",
    "        final_gha_combined = pd.concat([final_gha_combined, updated_gha, new_gha], ignore_index=True)\n",
    "        final_open_combined = pd.concat([final_open_combined, updated_open, new_open], ignore_index=True)\n",
    "\n",
    "        # Update master for the next iteration\n",
    "        master_df = gha_df  # Assuming GHA is the master dataset\n",
    "\n",
    "    # Combine GHA and Open Position into a single DataFrame\n",
    "    final_combined_df = combine_all_records(final_gha_combined, final_open_combined)\n",
    "\n",
    "    # Save to Excel\n",
    "    final_combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"Final combined data saved to {output_file}.\")\n",
    "\n",
    "# Function to find updated and new records\n",
    "def find_updated_and_new_records(file_df, master_df, month, source_type, comparison_columns):\n",
    "    # Ensure Position ID column exists\n",
    "    if \"Position ID\" not in file_df.columns:\n",
    "        raise KeyError(f\"'Position ID' not found in {source_type} data for {month}.\")\n",
    "\n",
    "    # Identify updated and new records\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "    for _, row in file_df.iterrows():\n",
    "        # Determine the actual source dynamically (if column exists)\n",
    "        actual_source = row.get(\"Source\", source_type)\n",
    "\n",
    "        # Get comparison columns based on the source type\n",
    "        cols_to_check = comparison_columns.get(actual_source, [])\n",
    "\n",
    "        # Perform record comparisons\n",
    "        position_id = row.get(\"Position ID\")\n",
    "        master_row = master_df[master_df[\"Position ID\"] == position_id]\n",
    "\n",
    "        if not master_row.empty:\n",
    "            # Check for updated columns\n",
    "            changes = []\n",
    "            for col in cols_to_check:\n",
    "                if col in master_row and not pd.isna(row[col]) and row[col] != master_row[col].values[0]:\n",
    "                    changes.append(col)\n",
    "            if changes:\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \"; \".join(changes)\n",
    "                updated_row[\"Source\"] = actual_source\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Add new record\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"Month Added\"] = month\n",
    "            new_row[\"Source\"] = actual_source\n",
    "            new_records.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "\n",
    "    return updated_df, new_df\n",
    "\n",
    "# Function to combine GHA and Open Position records\n",
    "def combine_all_records(final_gha_combined, final_open_combined):\n",
    "    # Add missing columns for consistency\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in final_gha_combined.columns:\n",
    "            final_gha_combined[col] = None\n",
    "        if col not in final_open_combined.columns:\n",
    "            final_open_combined[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    final_gha_combined = final_gha_combined[required_columns]\n",
    "    final_open_combined = final_open_combined[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column\n",
    "    final_gha_combined[\"Data Type\"] = \"GHA\"\n",
    "    final_open_combined[\"Data Type\"] = \"Open Position\"\n",
    "\n",
    "    # Combine all records\n",
    "    final_combined_df = pd.concat([final_gha_combined, final_open_combined], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Specify master file and output file paths\n",
    "master_file_path = \"Input\\\\master_file.xlsx\"\n",
    "output_file = \"Output\\\\Final_Combined_Data.xlsx\"\n",
    "\n",
    "# Process all files\n",
    "process_all_months(master_file_path, monthly_files, comparison_columns, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff311b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_updated_and_new_records(file_df, reference_df, month, source_type, comparison_columns):\n",
    "    # Filter records based on the 'Source' column\n",
    "    file_df = file_df[file_df['Source'] == source_type]\n",
    "    reference_df = reference_df[reference_df['Source'] == source_type]\n",
    "\n",
    "    # Ensure Position ID exists\n",
    "    if \"Position ID\" not in file_df.columns:\n",
    "        raise KeyError(f\"'Position ID' not found in {source_type} data for {month}.\")\n",
    "\n",
    "    # Retrieve the list of columns for comparison from the dictionary\n",
    "    cols_to_compare = comparison_columns[source_type]\n",
    "\n",
    "    # Identify updated and new records\n",
    "    updated_records = []\n",
    "    new_records = []\n",
    "\n",
    "    for _, row in file_df.iterrows():\n",
    "        position_id = row[\"Position ID\"]\n",
    "        ref_row = reference_df[reference_df[\"Position ID\"] == position_id]\n",
    "\n",
    "        if not ref_row.empty:\n",
    "            # Check for changes in the comparison columns\n",
    "            changes = []\n",
    "            for col in cols_to_compare:\n",
    "                if col in ref_row.columns and row[col] != ref_row[col].values[0]:\n",
    "                    changes.append(col)\n",
    "\n",
    "            if changes:\n",
    "                updated_row = row.to_dict()\n",
    "                updated_row[\"Month Changed\"] = month\n",
    "                updated_row[\"Cols Changed\"] = \"; \".join(changes)\n",
    "                updated_records.append(updated_row)\n",
    "        else:\n",
    "            # Add new record\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"Month Added\"] = month\n",
    "            new_records.append(new_row)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "\n",
    "    return updated_df, new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, (gha_file, open_pos_file) in monthly_files.items():\n",
    "    # Load GHA and Open Position files for the month\n",
    "    gha_df = pd.read_csv(gha_file)  # Using CSV\n",
    "    open_pos_df = pd.read_csv(open_pos_file)\n",
    "\n",
    "    # Process GHA and Open Position files against the master\n",
    "    updated_gha, new_gha = find_updated_and_new_records(\n",
    "        gha_df, master_df, month, 'GHA', comparison_columns\n",
    "    )\n",
    "    updated_open, new_open = find_updated_and_new_records(\n",
    "        open_pos_df, master_df, month, 'Open Position', comparison_columns\n",
    "    )\n",
    "\n",
    "    # Append processed data to the final DataFrames\n",
    "    final_gha_combined = pd.concat([final_gha_combined, updated_gha, new_gha], ignore_index=True)\n",
    "    final_open_combined = pd.concat([final_open_combined, updated_open, new_open], ignore_index=True)\n",
    "\n",
    "    # Update master for the next iteration\n",
    "    master_df = pd.concat([master_df, gha_df, open_pos_df], ignore_index=True).drop_duplicates(\n",
    "        subset=[\"Position ID\"], keep=\"last\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
