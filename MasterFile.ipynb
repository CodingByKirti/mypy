{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd9d0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated GHA Records:\n",
      "   Position ID Employee ID Col1_current  Col2_current Col3_current  \\\n",
      "1           20        E002    B_Updated           250            Y   \n",
      "2           40        E004            D           400            W   \n",
      "\n",
      "  Col1_master  Col2_master Col3_master ColZ  \n",
      "1           B        200.0           Y  NaN  \n",
      "2         NaN          NaN         NaN  NaN  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Position ID_master'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position ID_master'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-76f17aeaea46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Find new records in Feb24 GHA data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mnew_gha_records\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_new_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeb24_gha_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New GHA Records:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_gha_records\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-76f17aeaea46>\u001b[0m in \u001b[0;36mfind_new_records\u001b[1;34m(current_df, master_df)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Filter rows where Position ID and Employee ID do not have a match in the master data (i.e., new records)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mnew_records\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Position ID_master'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employee ID_master'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kirti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position ID_master'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# Strip spaces from column names to avoid mismatch\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "feb24_gha_df.columns = feb24_gha_df.columns.str.strip()\n",
    "feb24_open_df.columns = feb24_open_df.columns.str.strip()\n",
    "mar24_gha_df.columns = mar24_gha_df.columns.str.strip()\n",
    "mar24_open_df.columns = mar24_open_df.columns.str.strip()\n",
    "\n",
    "# Part 1: Find updated records (matching Position ID and Employee ID, but with changes in other columns)\n",
    "def find_updated_records(current_df, master_df):\n",
    "    # Merge dataframes on Position ID and Employee ID to compare current vs master\n",
    "    merged_df = current_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "    \n",
    "    # Find columns that have been updated (skip Position ID and Employee ID)\n",
    "    updated_columns = [col for col in current_df.columns if col not in ['Position ID', 'Employee ID']]\n",
    "    \n",
    "    # Create a mask to find rows where any column (other than Position ID and Employee ID) has changed\n",
    "    updated_mask = merged_df.apply(lambda row: any(row[col + '_current'] != row[col + '_master'] for col in updated_columns), axis=1)\n",
    "    \n",
    "    # Filter out rows that have been updated\n",
    "    updated_records = merged_df[updated_mask]\n",
    "    \n",
    "    return updated_records\n",
    "\n",
    "# Part 2: Find new records (Position ID and Employee ID exist only in the current data, not in the master data)\n",
    "def find_new_records(current_df, master_df):\n",
    "    # Merge dataframes on Position ID and Employee ID\n",
    "    merged_df = current_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "    \n",
    "    # Filter rows where Position ID and Employee ID do not have a match in the master data (i.e., new records)\n",
    "    new_records = merged_df[merged_df['Position ID_master'].isna() & merged_df['Employee ID_master'].isna()]\n",
    "    \n",
    "    return new_records\n",
    "\n",
    "# Find updated records in Feb24 GHA data\n",
    "updated_gha_records = find_updated_records(feb24_gha_df, master_df)\n",
    "print(\"Updated GHA Records:\")\n",
    "print(updated_gha_records)\n",
    "\n",
    "# Find new records in Feb24 GHA data\n",
    "new_gha_records = find_new_records(feb24_gha_df, master_df)\n",
    "print(\"New GHA Records:\")\n",
    "print(new_gha_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8df8316c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in GHA DataFrame:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3'], dtype='object')\n",
      "\n",
      "Master DataFrame Columns for Merge:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3', 'ColZ'], dtype='object')\n",
      "\n",
      "Sample data from file_df:\n",
      "   Position ID Employee ID       Col1  Col2 Col3\n",
      "0           10        E001          A   100    X\n",
      "1           20        E002  B_Updated   250    Y\n",
      "2           40        E004          D   400    W\n",
      "\n",
      "Sample data from master_df:\n",
      "   Position ID Employee ID Col1  Col2 Col3 ColZ\n",
      "0           10        E001    A   100    X  NaN\n",
      "1           20        E002    B   200    Y  NaN\n",
      "2           30        E003    C   300    Z  NaN\n",
      "3           31         NaN   DD  9000  NaN   SS\n",
      "4           50         NaN    P   500  NaN    U\n",
      "\n",
      "Merging on both 'Position ID' and 'Employee ID' for GHA\n",
      "\n",
      "Merged DataFrame columns for GHA:\n",
      "Index(['Position ID', 'Employee ID', 'Col1_current', 'Col2_current',\n",
      "       'Col3_current', 'Col1_master', 'Col2_master', 'Col3_master', 'ColZ'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in Open Position DataFrame:\n",
      "Index(['Position ID', 'Col1', 'Col2', 'ColZ'], dtype='object')\n",
      "\n",
      "Master DataFrame Columns for Merge:\n",
      "Index(['Position ID', 'Employee ID', 'Col1', 'Col2', 'Col3', 'ColZ'], dtype='object')\n",
      "\n",
      "Sample data from file_df:\n",
      "   Position ID Col1  Col2 ColZ\n",
      "0           50    P   500    U\n",
      "1           60    Q   600    V\n",
      "2           70    R   700    T\n",
      "\n",
      "Sample data from master_df:\n",
      "   Position ID Employee ID Col1  Col2 Col3 ColZ\n",
      "0           10        E001    A   100    X  NaN\n",
      "1           20        E002    B   200    Y  NaN\n",
      "2           30        E003    C   300    Z  NaN\n",
      "3           31         NaN   DD  9000  NaN   SS\n",
      "4           50         NaN    P   500  NaN    U\n",
      "\n",
      "Merging on 'Position ID' only for Open Position\n",
      "\n",
      "Merged DataFrame columns for Open Position:\n",
      "Index(['Position ID', 'Col1_current', 'Col2_current', 'ColZ_current',\n",
      "       'Employee ID', 'Col1_master', 'Col2_master', 'Col3', 'ColZ_master'],\n",
      "      dtype='object')\n",
      "                         0 Employee ID Month Changed  Position ID  \\\n",
      "1                      NaN        E002        Feb 24         20.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "1                      NaN        E002        Feb 24         20.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "2                      NaN        E004        Feb 24         40.0   \n",
      "Position ID             10         NaN           NaN          NaN   \n",
      "Employee ID           E001         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "Position ID             20         NaN           NaN          NaN   \n",
      "Employee ID           E002         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "Position ID             40         NaN           NaN          NaN   \n",
      "Employee ID           E004         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source                 GHA         NaN           NaN          NaN   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "1                      NaN         NaN        Feb 24         60.0   \n",
      "2                      NaN         NaN        Feb 24         70.0   \n",
      "Position ID             50         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "Position ID             60         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "Position ID             70         NaN           NaN          NaN   \n",
      "Employee ID            NaN         NaN           NaN          NaN   \n",
      "Month Added         Feb 24         NaN           NaN          NaN   \n",
      "Source       Open Position         NaN           NaN          NaN   \n",
      "\n",
      "            Reason Changed         Source  \n",
      "1             Col1 Changed            GHA  \n",
      "2             Col1 Changed            GHA  \n",
      "1             Col2 Changed            GHA  \n",
      "2             Col2 Changed            GHA  \n",
      "2             Col3 Changed            GHA  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "1             Col1 Changed  Open Position  \n",
      "2             Col1 Changed  Open Position  \n",
      "1             Col2 Changed  Open Position  \n",
      "2             Col2 Changed  Open Position  \n",
      "1             ColZ Changed  Open Position  \n",
      "2             ColZ Changed  Open Position  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n",
      "Position ID            NaN            NaN  \n",
      "Employee ID            NaN            NaN  \n",
      "Month Added            NaN            NaN  \n",
      "Source                 NaN            NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n",
      "<ipython-input-40-0c52680d4ef7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Reason Changed'] = f'{col} Changed'\n",
      "<ipython-input-40-0c52680d4ef7>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Month Changed'] = month_year\n",
      "<ipython-input-40-0c52680d4ef7>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  changed_rows['Source'] = source\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to check and process changes for GHA and Open Positions files\n",
    "def process_changes(file_df, source, cols_to_check, month_year):\n",
    "    global updateddf\n",
    "\n",
    "    # Strip any leading/trailing spaces in column names to avoid mismatch\n",
    "    file_df.columns = file_df.columns.str.strip()\n",
    "    master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "    # Debug: Print column names of file_df and master_df to ensure 'Position ID' and 'Employee ID' are present\n",
    "    print(f\"\\nColumns in {source} DataFrame:\")\n",
    "    print(file_df.columns)\n",
    "    \n",
    "    print(\"\\nMaster DataFrame Columns for Merge:\")\n",
    "    print(master_df.columns)\n",
    "\n",
    "    # Ensure the correct columns are present before proceeding\n",
    "    if 'Position ID' not in file_df.columns:\n",
    "        print(f\"Error: 'Position ID' not found in {source} data.\")\n",
    "        return\n",
    "    if 'Employee ID' not in file_df.columns and source != 'Open Position':\n",
    "        print(f\"Error: 'Employee ID' not found in {source} data.\")\n",
    "        return\n",
    "\n",
    "    # Show a sample of the first few rows to understand the structure\n",
    "    print(\"\\nSample data from file_df:\")\n",
    "    print(file_df.head())\n",
    "    \n",
    "    print(\"\\nSample data from master_df:\")\n",
    "    print(master_df.head())\n",
    "\n",
    "    # Merge based on 'Position ID' and 'Employee ID' (for GHA) or just 'Position ID' (for Open Position)\n",
    "    if source == 'Open Position':\n",
    "        print(\"\\nMerging on 'Position ID' only for Open Position\")\n",
    "        merged_df = file_df.merge(master_df, on=['Position ID'], how='left', suffixes=('_current', '_master'))\n",
    "    else:\n",
    "        print(\"\\nMerging on both 'Position ID' and 'Employee ID' for GHA\")\n",
    "        merged_df = file_df.merge(master_df, on=['Position ID', 'Employee ID'], how='left', suffixes=('_current', '_master'))\n",
    "\n",
    "    # Print the columns of the merged DataFrame to debug\n",
    "    print(f\"\\nMerged DataFrame columns for {source}:\")\n",
    "    print(merged_df.columns)\n",
    "\n",
    "    # Process the merged DataFrame\n",
    "    for col in cols_to_check:\n",
    "        current_col = f'{col}_current'\n",
    "        master_col = f'{col}_master'\n",
    "\n",
    "        # Ensure both current and master columns exist\n",
    "        if current_col in merged_df.columns and master_col in merged_df.columns:\n",
    "            merged_df[f'{col}_changed'] = merged_df[current_col] != merged_df[master_col]\n",
    "            changed_rows = merged_df[merged_df[f'{col}_changed'] == True]\n",
    "            changed_rows['Reason Changed'] = f'{col} Changed'\n",
    "            changed_rows['Month Changed'] = month_year\n",
    "            changed_rows['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, changed_rows[['Position ID', 'Employee ID', 'Month Changed', 'Reason Changed', 'Source']]])\n",
    "\n",
    "        elif current_col in merged_df.columns:\n",
    "            merged_df[f'{col}_changed'] = False  # Defaulting to False since master column is missing\n",
    "            changed_rows = merged_df[merged_df[f'{col}_changed'] == True]\n",
    "            changed_rows['Reason Changed'] = f'{col} Changed'\n",
    "            changed_rows['Month Changed'] = month_year\n",
    "            changed_rows['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, changed_rows[['Position ID', 'Employee ID', 'Month Changed', 'Reason Changed', 'Source']]])\n",
    "\n",
    "    # Handle new records (those not found in the master file)\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if pd.isna(row.get('Position ID_master')):  # No 'Employee ID' for Open Position source\n",
    "            new_record = row.copy()\n",
    "            new_record['Month Added'] = month_year\n",
    "            new_record['Source'] = source\n",
    "            updateddf = pd.concat([updateddf, new_record[['Position ID', 'Employee ID', 'Month Added', 'Source']]])\n",
    "\n",
    "# Assuming you have defined the file paths for the respective files\n",
    "# feb24_gha_df = pd.read_excel('feb24_gha.xlsx')\n",
    "# feb24_open_df = pd.read_excel('feb24_open.xlsx')\n",
    "# master_df = pd.read_excel('master_file.xlsx')\n",
    "\n",
    "# Define file paths\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df =pd.read_excel( r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# List of columns to check for changes\n",
    "cols_to_check_gha = ['Col1', 'Col2', 'Col3']  # Adjust columns to actual ones\n",
    "cols_to_check_open_pos = ['Col1', 'Col2', 'ColZ']  # Adjust columns to actual ones\n",
    "\n",
    "# Initialize empty dataframe to store updates\n",
    "updateddf = pd.DataFrame()\n",
    "\n",
    "# Process changes for February 24th GHA and Open Position files\n",
    "month_year = 'Feb 24'\n",
    "process_changes(feb24_gha_df, 'GHA', cols_to_check_gha, month_year)\n",
    "process_changes(feb24_open_df, 'Open Position', cols_to_check_open_pos, month_year)\n",
    "\n",
    "# If you want to save the updated DataFrame to an Excel file\n",
    "updateddf.to_excel(\"Updated_Records.xlsx\", index=False)\n",
    "\n",
    "# Output the updated records for review\n",
    "print(updateddf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9be547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1b739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ab8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e34375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70712801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da90e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Records (Feb24 GHA):\n",
      "  Position ID Employee ID Col1  Col2 Col3\n",
      "2          40        E004    D   400    W\n",
      "Changed Records (Feb24 GHA):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, Employee ID, Col1_new, Col2_new, Col3_new, Col1_master, Col2_master, Col3_master]\n",
      "Index: []\n",
      "New Records (mar24 GHA):\n",
      "  Position ID Employee ID       Col1  Col2 Col3\n",
      "1          40        E004  D_Updated   400    W\n",
      "2          50        E005          E   500    Z\n",
      "Changed Records (mar24 GHA):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, Employee ID, Col1_new, Col2_new, Col3_new, Col1_master, Col2_master, Col3_master]\n",
      "Index: []\n",
      "New Records (Feb24 open):\n",
      "  Position ID ColX  ColY ColZ\n",
      "0          50    P   500    U\n",
      "1          60    Q   600    V\n",
      "2          70    R   700    T\n",
      "Changed Records (Feb24 open):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, ColX, ColY, ColZ, Employee ID, Col1, Col2, Col3]\n",
      "Index: []\n",
      "New Records (MAr24 open):\n",
      "  Position ID       ColX  ColY ColZ\n",
      "0          50          P   500    U\n",
      "1          60  Q_Updated   650    V\n",
      "2          80          S   800    T\n",
      "Changed Records (MAr24 open):\n",
      "Empty DataFrame\n",
      "Columns: [Position ID, ColX, ColY, ColZ, Employee ID, Col1, Col2, Col3]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load the master file and compare it with a new file\n",
    "def load_and_compare(master_file_path, new_file_path, has_employee_id=True):\n",
    "    # Load the master file and new file into dataframes\n",
    "    master_df = pd.read_excel(master_file_path)\n",
    "    new_df = pd.read_excel(new_file_path)\n",
    "    \n",
    "    # Ensure Position ID is treated as a string for consistency\n",
    "    master_df['Position ID'] = master_df['Position ID'].astype(str)\n",
    "    new_df['Position ID'] = new_df['Position ID'].astype(str)\n",
    "\n",
    "    # Check if Employee ID exists in both files, adjust accordingly\n",
    "    if has_employee_id:\n",
    "        master_df['Employee ID'] = master_df['Employee ID'].astype(str)\n",
    "        new_df['Employee ID'] = new_df['Employee ID'].astype(str)\n",
    "        new_records_df = new_df[~new_df[['Position ID', 'Employee ID']].isin(master_df[['Position ID', 'Employee ID']]).all(axis=1)]\n",
    "        changed_records_df = new_df.merge(master_df, on=['Position ID', 'Employee ID'], how='inner', suffixes=('_new', '_master'))\n",
    "    else:\n",
    "        # If Employee ID is not present, compare based on 'Position ID' only\n",
    "        new_records_df = new_df[~new_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_records_df = new_df.merge(master_df, on='Position ID', how='inner', suffixes=('_new', '_master'))\n",
    "\n",
    "    # For changed records, we check for differences in columns that exist in both files\n",
    "    compare_columns = [col for col in new_df.columns if col != 'Position ID' and col != 'Employee ID']\n",
    "    \n",
    "    # Only compare columns that exist in both new_df and master_df\n",
    "    compare_columns = [col for col in compare_columns if f'{col}_new' in changed_records_df.columns and f'{col}_master' in changed_records_df.columns]\n",
    "\n",
    "    # Compare the columns and filter the changed records\n",
    "    for col in compare_columns:\n",
    "        changed_records_df = changed_records_df[changed_records_df[f'{col}_new'] != changed_records_df[f'{col}_master']]\n",
    "\n",
    "    # Remove rows with no differences in the specified columns\n",
    "    changed_records_df = changed_records_df.dropna(subset=[f'{col}_new' for col in compare_columns])\n",
    "    \n",
    "    return new_records_df, changed_records_df\n",
    "\n",
    "# Define file paths\n",
    "master_file_path = r\"Input\\\\\" + \"master_file.xlsx\"\n",
    "feb24_gha_file = r\"Input\\\\\" + \"Feb24_gha.xlsx\"\n",
    "feb24_open_file = r\"Input\\\\\" + \"Feb24_open.xlsx\"\n",
    "mar24_gha_file = r\"Input\\\\\" + \"Mar24_gha.xlsx\"\n",
    "mar24_open_file = r\"Input\\\\\" + \"Mar24_open.xlsx\"\n",
    "\n",
    "# Compare Feb24 GHA file with the master file (Employee ID is present)\n",
    "new_records_feb24_gha, changed_records_feb24_gha = load_and_compare(master_file_path, feb24_gha_file, has_employee_id=True)\n",
    "\n",
    "# Compare Feb24 Open file with the master file (No Employee ID in open file)\n",
    "new_records_feb24_open, changed_records_feb24_open = load_and_compare(master_file_path, feb24_open_file, has_employee_id=False)\n",
    "\n",
    "# Compare Mar24 GHA file with the master file (Employee ID is present)\n",
    "new_records_mar24_gha, changed_records_mar24_gha = load_and_compare(master_file_path, mar24_gha_file, has_employee_id=True)\n",
    "\n",
    "# Compare Mar24 Open file with the master file (No Employee ID in open file)\n",
    "new_records_mar24_open, changed_records_mar24_open = load_and_compare(master_file_path, mar24_open_file, has_employee_id=False)\n",
    "\n",
    "# Print results (or you can save them to a new file)\n",
    "print(\"New Records (Feb24 GHA):\")\n",
    "print(new_records_feb24_gha)\n",
    "\n",
    "print(\"Changed Records (Feb24 GHA):\")\n",
    "print(changed_records_feb24_gha)\n",
    "\n",
    "print(\"New Records (mar24 GHA):\")\n",
    "print(new_records_mar24_gha)\n",
    "\n",
    "print(\"Changed Records (mar24 GHA):\")\n",
    "print(changed_records_mar24_gha)\n",
    "\n",
    "print(\"New Records (Feb24 open):\")\n",
    "print(new_records_feb24_open)\n",
    "\n",
    "print(\"Changed Records (Feb24 open):\")\n",
    "print(changed_records_feb24_open)\n",
    "\n",
    "print(\"New Records (MAr24 open):\")\n",
    "print(new_records_mar24_open)\n",
    "\n",
    "print(\"Changed Records (MAr24 open):\")\n",
    "print(changed_records_mar24_open)\n",
    "\n",
    "\n",
    "\n",
    "# Repeat for other files (Feb24 Open, Mar24 GHA, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70f06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Records DataFrame:\n",
      "  Position ID Employee ID       Col1   Col2 Col3 Month Added     Source Name  \\\n",
      "0      000010        E001          A  100.0    X      Feb 24             GHA   \n",
      "1      000020        E002  B_Updated  250.0    Y      Feb 24             GHA   \n",
      "2      000040        E004          D  400.0    W      Feb 24             GHA   \n",
      "3      000050         NaN        NaN    NaN  NaN      Feb 24  Open Positions   \n",
      "4      000060         NaN        NaN    NaN  NaN      Feb 24  Open Positions   \n",
      "\n",
      "  ColX   ColY ColZ  \n",
      "0  NaN    NaN  NaN  \n",
      "1  NaN    NaN  NaN  \n",
      "2  NaN    NaN  NaN  \n",
      "3    P  500.0    U  \n",
      "4    Q  600.0    V  \n",
      "\n",
      "Changed Records DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample function to process GHA and Open Positions files\n",
    "def process_month_files(master_df, month_files, cols_to_check_gha, cols_to_check_positions):\n",
    "    newdf = pd.DataFrame()  # DataFrame to hold new records\n",
    "    changesdf = pd.DataFrame()  # DataFrame to hold changed records\n",
    "    \n",
    "    # Iterate through each month's GHA and Open Positions files\n",
    "    for month, files in month_files.items():\n",
    "        gha_file, positions_file = files\n",
    "        \n",
    "        # Load the GHA and Open Positions files\n",
    "        gha_df = pd.read_excel(gha_file)\n",
    "        positions_df = pd.read_excel(positions_file)\n",
    "\n",
    "        # Standardize column names if necessary (e.g., rename 'Position ID' to 'Position Number')\n",
    "        gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(6)  # Ensure 'Position ID' is a string with leading zeros\n",
    "        positions_df['Position ID'] = positions_df['Position ID'].astype(str).str.zfill(6)\n",
    "\n",
    "        # Checking new records and changes for GHA\n",
    "        new_gha_records = gha_df[~gha_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_gha_records = gha_df[gha_df['Position ID'].isin(master_df['Position ID'])]\n",
    "\n",
    "        # Identify changes in GHA based on the specified columns\n",
    "        for index, row in changed_gha_records.iterrows():\n",
    "            master_row = master_df[master_df['Position ID'] == row['Position ID']].iloc[0]\n",
    "            changed_columns = [col for col in cols_to_check_gha if row[col] != master_row[col]]\n",
    "            \n",
    "            if changed_columns:\n",
    "                row['Change Month'] = month\n",
    "                row['Changed Attributes'] = ', '.join(changed_columns)\n",
    "                row['Source Name'] = 'GHA'\n",
    "                changesdf = pd.concat([changesdf, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Add new records from GHA\n",
    "        new_gha_records['Month Added'] = month\n",
    "        new_gha_records['Source Name'] = 'GHA'\n",
    "        newdf = pd.concat([newdf, new_gha_records], ignore_index=True)\n",
    "\n",
    "        # Checking new records and changes for Open Positions\n",
    "        new_positions_records = positions_df[~positions_df['Position ID'].isin(master_df['Position ID'])]\n",
    "        changed_positions_records = positions_df[positions_df['Position ID'].isin(master_df['Position ID'])]\n",
    "\n",
    "        # Identify changes in Open Positions based on the specified columns\n",
    "        for index, row in changed_positions_records.iterrows():\n",
    "            master_row = master_df[master_df['Position ID'] == row['Position ID']].iloc[0]\n",
    "            changed_columns = [col for col in cols_to_check_positions if row[col] != master_row[col]]\n",
    "            \n",
    "            if changed_columns:\n",
    "                row['Change Month'] = month\n",
    "                row['Changed Attributes'] = ', '.join(changed_columns)\n",
    "                row['Source Name'] = 'Open Positions'\n",
    "                changesdf = pd.concat([changesdf, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Add new records from Open Positions\n",
    "        new_positions_records['Month Added'] = month\n",
    "        new_positions_records['Source Name'] = 'Open Positions'\n",
    "        newdf = pd.concat([newdf, new_positions_records], ignore_index=True)\n",
    "\n",
    "    # Return the new and changed records dataframes\n",
    "    return newdf, changesdf\n",
    "\n",
    "# Define the columns to check for GHA and Open Positions (you can modify these lists)\n",
    "cols_to_check_gha = ['Col1', 'Col2', 'Col3']  # Replace with the actual columns for GHA\n",
    "cols_to_check_positions = ['ColX', 'ColY', 'ColZ']  # Replace with the actual columns for Open Positions\n",
    "\n",
    "# Example of files for the month comparison (make sure to adjust paths and file names)\n",
    "month_files = {\n",
    "    'Feb 24': [r\"Input\\\\\"+'Feb24_gha.xlsx', r\"Input\\\\\"+'Feb24_open.xlsx'],\n",
    "    'Mar 24': [r\"Input\\\\\"+'Mar24_gha.xlsx', r\"Input\\\\\"+'Mar24_open.xlsx']\n",
    "}\n",
    "\n",
    "# Load the master file (adjust the file path as needed)\n",
    "master_df = pd.read_excel(r\"Input\\\\\"+'master_file.xlsx')\n",
    "\n",
    "# Process the files and get the new and changed records\n",
    "newdf, changesdf = process_month_files(master_df, month_files, cols_to_check_gha, cols_to_check_positions)\n",
    "\n",
    "# Optionally, save the new and changed records to Excel files for further analysis\n",
    "newdf.to_excel(r\"Input\\\\\"+'New_Records.xlsx', index=False)\n",
    "changesdf.to_excel(r\"Input\\\\\"+'Changed_Records.xlsx', index=False)\n",
    "\n",
    "# Print the new and changed records dataframes for review\n",
    "print(\"New Records DataFrame:\")\n",
    "print(newdf.head())\n",
    "\n",
    "print(\"\\nChanged Records DataFrame:\")\n",
    "print(changesdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb939fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of columns to track for changes\n",
    "columns_to_check = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name', 'Work Location City']\n",
    "\n",
    "def track_changes_across_months(master_df, mom_gha_file, mom_open_positions_file, month):\n",
    "    # Ensure consistency in data types\n",
    "    master_df['Position ID'] = master_df['Position ID'].astype(str)\n",
    "    mom_gha_file['Position ID'] = mom_gha_file['Position ID'].astype(str)\n",
    "    mom_gha_file['Employee ID'] = mom_gha_file['Employee ID'].astype(str)\n",
    "    mom_open_positions_file['Position ID'] = mom_open_positions_file['Position ID'].astype(str)\n",
    "\n",
    "    # Initialize DataFrames to store changed and updated records\n",
    "    changed_rows = []\n",
    "    updated_rows = []\n",
    "\n",
    "    # Combine the merged dataframe with previous month's data\n",
    "    merged_df = master_df.copy()\n",
    "\n",
    "    # Track changes in GHA file (source == 'gha')\n",
    "    for index, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "        emp_id = row['Employee ID']\n",
    "        \n",
    "        # Filter the mom_gha_file for the matching Position ID and Employee ID\n",
    "        gha_match = mom_gha_file[(mom_gha_file['Position ID'] == pos_id) & (mom_gha_file['Employee ID'] == emp_id)]\n",
    "\n",
    "        if not gha_match.empty:\n",
    "            changes = []\n",
    "            for col in columns_to_check:\n",
    "                if row[col] != gha_match.iloc[0][col]:  # Compare values for the specified columns\n",
    "                    changes.append(f\"{col} Changed\")\n",
    "\n",
    "            if changes:\n",
    "                updated_row = row.copy()\n",
    "                updated_row['Description'] = '; '.join(changes)\n",
    "                updated_row['Month Changed'] = month\n",
    "                updated_rows.append(updated_row)\n",
    "\n",
    "            # If combination of Position ID and Employee ID has changed (new employee or position), track as changed\n",
    "            if len(gha_match) > 1:  # More than one match, indicating a position/employee mismatch\n",
    "                changed_row = row.copy()\n",
    "                changed_row['Description'] = 'Position/Employee ID mismatch'\n",
    "                changed_row['Month Changed'] = month\n",
    "                changed_rows.append(changed_row)\n",
    "\n",
    "    # Track changes in Open Positions file (source == 'open positions')\n",
    "    for index, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "\n",
    "        # Filter the mom_open_positions_file for the matching Position ID\n",
    "        open_pos_match = mom_open_positions_file[mom_open_positions_file['Position ID'] == pos_id]\n",
    "\n",
    "        if not open_pos_match.empty:\n",
    "            changes = []\n",
    "            for col in columns_to_check:\n",
    "                # Exclude Work Location City and Employee ID from the comparison for Open Position\n",
    "                if col != 'Work Location City' and col != 'Employee ID' and row[col] != open_pos_match.iloc[0][col]:\n",
    "                    changes.append(f\"{col} Changed\")\n",
    "\n",
    "            if changes:\n",
    "                updated_row = row.copy()\n",
    "                updated_row['Description'] = '; '.join(changes)\n",
    "                updated_row['Month Changed'] = month\n",
    "                updated_rows.append(updated_row)\n",
    "\n",
    "    # Convert lists to DataFrames\n",
    "    changed_rows_df = pd.DataFrame(changed_rows)\n",
    "    updated_rows_df = pd.DataFrame(updated_rows)\n",
    "\n",
    "    return changed_rows_df, updated_rows_df\n",
    "\n",
    "# Example usage:\n",
    "current_month = 'Mar-24'\n",
    "changed_rows_df, updated_rows_df = track_changes_across_months(master_df, mom_gha_file, mom_open_positions_file, current_month)\n",
    "\n",
    "# Display the result\n",
    "print(\"Changed Rows DataFrame:\")\n",
    "print(changed_rows_df)\n",
    "\n",
    "print(\"\\nUpdated Rows DataFrame:\")\n",
    "print(updated_rows_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new_records with the same columns as master_df plus 'Month_Added'\n",
    "new_records = pd.DataFrame(columns=master_df.columns.tolist() + ['Month_Added'])\n",
    "\n",
    "# Define function to process each month\n",
    "def process_single_month(master_df, month, gha_file, open_pos_file, new_records):\n",
    "    max_length = master_df['Position ID'].str.len().max()\n",
    "\n",
    "    # Standardize Position IDs\n",
    "    gha_file['Position ID'] = gha_file['Position ID'].str.zfill(max_length)\n",
    "    open_pos_file['Position ID'] = open_pos_file['Position ID'].str.zfill(max_length)\n",
    "    \n",
    "    # Update master_df with 1/0 based on presence in GHA and Open Positions\n",
    "    master_df[month] = np.where(\n",
    "        master_df['Source'] == 'GHA', \n",
    "        master_df['Position ID'].apply(lambda x: 1 if x in gha_file['Position ID'].values else 0),\n",
    "        np.where(\n",
    "            master_df['Source'] == 'Open Positions', \n",
    "            master_df['Position ID'].apply(lambda x: 1 if x in open_pos_file['Position ID'].values else 0),\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Identify new records in GHA not in master_df or previously in new_records\n",
    "    gha_new_records = gha_file[~gha_file['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "    gha_new_records = gha_new_records.assign(Source='GHA', Month_Added=month)\n",
    "\n",
    "    # Identify new records in Open Positions not in master_df or previously in new_records\n",
    "    open_pos_new_records = open_pos_file[~open_pos_file['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "    open_pos_new_records = open_pos_new_records.assign(Source='Open Positions', Month_Added=month)\n",
    "\n",
    "    # Combine new records found this month into one DataFrame\n",
    "    new_month_records = pd.concat([gha_new_records, open_pos_new_records], ignore_index=True)\n",
    "\n",
    "    # Add presence columns for each month in new_records, filling prior months with 0\n",
    "    for mth in master_df.columns[2:]:  # Assuming month columns start from index 2\n",
    "        if mth < month:\n",
    "            new_month_records[mth] = 0  # Set prior months to 0\n",
    "        elif mth == month:\n",
    "            new_month_records[mth] = new_month_records.apply(\n",
    "                lambda row: 1 if row['Position ID'] in gha_file['Position ID'].values or row['Position ID'] in open_pos_file['Position ID'].values else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            new_month_records[mth] = np.nan\n",
    "\n",
    "    # Trim new_month_records to only include columns in master_df + 'Month_Added'\n",
    "    new_month_records = new_month_records[master_df.columns.tolist() + ['Month_Added']]\n",
    "\n",
    "    # Append to new_records DataFrame\n",
    "    new_records = pd.concat([new_records, new_month_records], ignore_index=True)\n",
    "\n",
    "    return master_df, new_records\n",
    "\n",
    "# Process each month\n",
    "for month, gha_file in gha_monthly_files.items():\n",
    "    open_pos_file = open_pos_monthly_files[month]\n",
    "    master_df, new_records = process_single_month(master_df, month, gha_file, open_pos_file, new_records)\n",
    "\n",
    "# Fill any remaining NaN values in new_records with 0 for months not reached yet\n",
    "for col in master_df.columns[2:]:  # Month columns assumed to start from index 2\n",
    "    new_records[col].fillna(0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrames\n",
    "print(\"Updated Master DataFrame:\\n\", master_df)\n",
    "print(\"\\nNew Records DataFrame:\\n\", new_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10657e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Master DataFrame:\n",
      "   Position ID          Source  Jan 24  Feb 24  Mar 24\n",
      "0      000123             GHA     1.0     0.0     1.0\n",
      "1      000456  Open Positions     1.0     0.0     0.0\n",
      "2      000789             GHA     0.0     1.0     0.0\n",
      "3      001001  Open Positions     0.0     1.0     1.0\n",
      "\n",
      "New Records DataFrame:\n",
      "   Position ID          Source Month Added Month_Added\n",
      "0      002002             GHA         NaN      Feb 24\n",
      "1      004004  Open Positions         NaN      Feb 24\n",
      "2      003003             GHA         NaN      Mar 24\n",
      "3      005005  Open Positions         NaN      Mar 24\n"
     ]
    }
   ],
   "source": [
    "# Declare new_records with relevant columns\n",
    "new_records = pd.DataFrame(columns=['Position ID', 'Source', 'Month Added'])\n",
    "\n",
    "def process_monthly_data(master_df, gha_monthly_files, open_pos_monthly_files):\n",
    "    global new_records\n",
    "    max_length = master_df['Position ID'].str.len().max()\n",
    "    \n",
    "    for month in gha_monthly_files.keys():\n",
    "        gha_df = gha_monthly_files[month].copy()\n",
    "        open_pos_df = open_pos_monthly_files[month].copy()\n",
    "\n",
    "        # Standardize Position IDs\n",
    "        gha_df['Position ID'] = gha_df['Position ID'].str.zfill(max_length)\n",
    "        open_pos_df['Position ID'] = open_pos_df['Position ID'].str.zfill(max_length)\n",
    "        \n",
    "        # Update master_df with 1/0 based on presence in GHA and Open Positions\n",
    "        master_df[month] = np.where(\n",
    "            master_df['Source'] == 'GHA', \n",
    "            master_df['Position ID'].apply(lambda x: 1 if x in gha_df['Position ID'].values else 0),\n",
    "            np.where(\n",
    "                master_df['Source'] == 'Open Positions', \n",
    "                master_df['Position ID'].apply(lambda x: 1 if x in open_pos_df['Position ID'].values else 0),\n",
    "                np.nan\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Identify new records in GHA not in master_df or previously in new_records\n",
    "        gha_new_records = gha_df[~gha_df['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "        gha_new_records = gha_new_records.assign(Source='GHA', Month_Added=month)\n",
    "\n",
    "        # Identify new records in Open Positions not in master_df or previously in new_records\n",
    "        open_pos_new_records = open_pos_df[~open_pos_df['Position ID'].isin(pd.concat([master_df['Position ID'], new_records['Position ID']]))]\n",
    "        open_pos_new_records = open_pos_new_records.assign(Source='Open Positions', Month_Added=month)\n",
    "\n",
    "        # Append unique new records from both GHA and Open Positions\n",
    "        new_records = pd.concat([new_records, gha_new_records, open_pos_new_records], ignore_index=True)\n",
    "    \n",
    "    return master_df, new_records\n",
    "\n",
    "# Call the function and get updated master_df and new_records\n",
    "master_df, new_records = process_monthly_data(master_df, gha_monthly_files, open_pos_monthly_files)\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "print(\"Updated Master DataFrame:\\n\", master_df)\n",
    "print(\"\\nNew Records DataFrame:\\n\", new_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38ece7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Additional columns to track for changes and their descriptions\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize changes DataFrame\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load GHA and Open Position data for the current month\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Rename 'Position Number' to 'Position ID' to match master_df\n",
    "    gha_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "    open_pos_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "\n",
    "    # Standardize Position ID and Employee ID to strings, with zero-padding for Position ID\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    gha_df['Employee ID'] = gha_df['Employee ID'].astype(str)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "\n",
    "    # Print column names to verify alignment\n",
    "    print(\"Debug: Columns in master_df:\", master_df.columns)\n",
    "    print(\"Debug: Columns in gha_df:\", gha_df.columns)\n",
    "    \n",
    "    # Merge on Position ID and Employee ID, with unique suffixes\n",
    "    merged_df = pd.merge(\n",
    "        master_df, gha_df,\n",
    "        on=['Position ID', 'Employee ID'],\n",
    "        how='outer',\n",
    "        suffixes=('_master', '_gha')\n",
    "    )\n",
    "    \n",
    "    # Check merged columns to verify expected columns are present\n",
    "    print(\"Debug: Columns in merged_df after merging:\", merged_df.columns)\n",
    "    \n",
    "    # If expected columns are missing, print a warning and skip the iteration\n",
    "    if 'Employee ID_master' not in merged_df.columns or 'Employee ID_gha' not in merged_df.columns:\n",
    "        print(\"Warning: Expected columns 'Employee ID_master' and 'Employee ID_gha' not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Track changes in Position-Employee combinations\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id = row['Position ID']\n",
    "        master_emp_id, gha_emp_id = row.get('Employee ID_master'), row.get('Employee ID_gha')\n",
    "        \n",
    "        # Detect Employee ID changes for the same Position ID\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Detect changes in additional columns\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row.get(f\"{col}_master\"), row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Drop duplicates and keep the first occurrence\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# Output the changes DataFrame\n",
    "print(\"Final changes_df:\\n\", changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Additional columns and descriptions for changes\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize the changes DataFrame with the required columns\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load data\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Standardize 'Position ID' formatting\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    \n",
    "    # Filter out rows with unspecified or empty Position IDs or Employee IDs in GHA data\n",
    "    gha_df = gha_df[(gha_df['Position ID'] != 'unspecified') & (gha_df['Position ID'] != '')]\n",
    "    gha_df = gha_df[(gha_df['Employee ID'] != 'unspecified') & (gha_df['Employee ID'] != '')]\n",
    "\n",
    "    # Merge GHA data with master data\n",
    "    print(\"Debug: GHA Columns before merging:\", gha_df.columns)\n",
    "    print(\"Debug: Master Columns before merging:\", master_df.columns)\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        master_df, gha_df, \n",
    "        on=['Position ID', 'Employee ID'], \n",
    "        how='outer', \n",
    "        suffixes=('_master', '_gha')\n",
    "    )\n",
    "    \n",
    "    # Debug column names after merging\n",
    "    print(\"Debug: Columns in merged_df after merging:\", merged_df.columns)\n",
    "    \n",
    "    # If columns aren't named as expected, skip further processing in this loop iteration\n",
    "    if 'Employee ID_master' not in merged_df.columns or 'Employee ID_gha' not in merged_df.columns:\n",
    "        print(\"Warning: Expected columns 'Employee ID_master' and 'Employee ID_gha' not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Detect changes\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id, emp_id = row['Position ID'], row['Employee ID']\n",
    "        master_emp_id, gha_emp_id = row['Employee ID_master'], row['Employee ID_gha']\n",
    "        \n",
    "        # Record changes in Position ID and Employee ID combinations\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Check for additional column changes\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row.get(f\"{col}_master\"), row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Remove duplicates\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# Output the changes DataFrame\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ad55b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position ID Employee ID  Jan 24  Feb 24  Mar 24\n",
      "0      000123        E001       1       1       0\n",
      "1      000456        E002       1       0       0\n",
      "2      000789        E003       0       0       1\n"
     ]
    }
   ],
   "source": [
    "#option 1\n",
    "import pandas as pd\n",
    "\n",
    "# Define maximum digits for 'Position ID' formatting, based on master file creation\n",
    "max_digits = max(len(str(pos_id)) for pos_id in master_df['Position ID'].astype(str))\n",
    "\n",
    "# Define additional columns to check for changes, with corresponding descriptions\n",
    "additional_cols = ['Global Career Band', 'BF Level 4 Name', 'Work Location Country/Territory Name']\n",
    "additional_cols_descriptions = {col: f\"{col} Changed\" for col in additional_cols}\n",
    "\n",
    "# Initialize empty DataFrame to store changes\n",
    "changes_df = pd.DataFrame(columns=master_df.columns.tolist() + ['Month', 'Description'])\n",
    "\n",
    "for month, gha_file, open_file in zip(months, gha_files, open_files):\n",
    "    # Load and prepare GHA and Open Position data for the current month\n",
    "    gha_df = pd.read_excel(gha_file, sheet_name='Headcount - Employee Detail')\n",
    "    open_pos_df = pd.read_excel(open_file)\n",
    "    \n",
    "    # Ensure consistent 'Position ID' format (use zfill if needed)\n",
    "    if 'Position Number' in gha_df.columns:\n",
    "        gha_df.rename(columns={'Position Number': 'Position ID'}, inplace=True)\n",
    "    gha_df['Position ID'] = gha_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    open_pos_df['Position ID'] = open_pos_df['Position ID'].astype(str).str.zfill(max_digits)\n",
    "    \n",
    "    # Filter out records where 'Position ID' or 'Employee ID' is unspecified or blank\n",
    "    gha_df = gha_df[(gha_df['Position ID'] != 'unspecified') & (gha_df['Position ID'] != '')]\n",
    "    gha_df = gha_df[(gha_df['Employee ID'] != 'unspecified') & (gha_df['Employee ID'] != '')]\n",
    "    \n",
    "    # Merge GHA data with master_df based on Position ID and Employee ID\n",
    "    merged_df = pd.merge(master_df, gha_df, on=['Position ID', 'Employee ID'], how='outer', suffixes=('_master', '_gha'))\n",
    "\n",
    "    # Identify changes in 'Position ID' and 'Employee ID' combinations, as well as additional columns\n",
    "    for _, row in merged_df.iterrows():\n",
    "        pos_id, emp_id = row['Position ID'], row['Employee ID']\n",
    "        master_emp_id, gha_emp_id = row['Employee ID_master'], row['Employee ID_gha']\n",
    "        \n",
    "        # Check for changes in Position ID and Employee ID combinations\n",
    "        if pd.notna(master_emp_id) and pd.notna(gha_emp_id) and master_emp_id != gha_emp_id:\n",
    "            # Log change details if Position ID has a different Employee ID\n",
    "            changes_df = changes_df.append({\n",
    "                **row[['Position ID', 'Employee ID_master']],\n",
    "                'Month': month,\n",
    "                'Description': 'Position-Employee Combination Changed'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        # Check for changes in additional columns\n",
    "        for col in additional_cols:\n",
    "            master_value, gha_value = row[f\"{col}_master\"], row.get(f\"{col}_gha\")\n",
    "            if pd.notna(master_value) and pd.notna(gha_value) and master_value != gha_value:\n",
    "                changes_df = changes_df.append({\n",
    "                    **row[['Position ID', 'Employee ID_master']],\n",
    "                    'Month': month,\n",
    "                    'Description': additional_cols_descriptions[col]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Drop duplicates to avoid recording repeated changes in subsequent months\n",
    "changes_df.drop_duplicates(subset=['Position ID', 'Employee ID_master', 'Description'], inplace=True)\n",
    "\n",
    "# View or save changes_df to verify the output\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51c0b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated GHA Records:\n",
      "   Position ID Employee ID       Col1  Col2 Col3\n",
      "1           20        E002  B_Updated   250    Y\n",
      "New GHA Records:\n",
      "   Position ID Employee ID Col1  Col2 Col3\n",
      "2           40        E004    D   400    W\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "feb24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\")\n",
    "feb24_open_df = pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\")\n",
    "mar24_gha_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\")\n",
    "mar24_open_df = pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "\n",
    "# Strip spaces from column names to avoid mismatch\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "feb24_gha_df.columns = feb24_gha_df.columns.str.strip()\n",
    "feb24_open_df.columns = feb24_open_df.columns.str.strip()\n",
    "mar24_gha_df.columns = mar24_gha_df.columns.str.strip()\n",
    "mar24_open_df.columns = mar24_open_df.columns.str.strip()\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, master_df):\n",
    "    updated_records = []\n",
    "\n",
    "    # Loop through current dataframe and compare each row with the master dataframe\n",
    "    for index, row in current_df.iterrows():\n",
    "        # Check if the row has a corresponding row in the master dataframe\n",
    "        match = master_df[(master_df['Position ID'] == row['Position ID']) & \n",
    "                          (master_df['Employee ID'] == row['Employee ID'])]\n",
    "\n",
    "        if not match.empty:\n",
    "            # Compare columns (excluding Position ID and Employee ID)\n",
    "            for col in row.index:\n",
    "                if col not in ['Position ID', 'Employee ID']:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        updated_records.append(row)\n",
    "                        break\n",
    "    \n",
    "    # Convert updated records to a DataFrame\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, master_df):\n",
    "    # Find rows in current_df that don't exist in master_df\n",
    "    new_records = current_df[~current_df['Position ID'].isin(master_df['Position ID']) | \n",
    "                             ~current_df['Employee ID'].isin(master_df['Employee ID'])]\n",
    "    return new_records\n",
    "\n",
    "# Part 1: Find updated records in Feb24 GHA data\n",
    "updated_gha_records = find_updated_records(feb24_gha_df, master_df)\n",
    "print(\"Updated GHA Records:\")\n",
    "print(updated_gha_records)\n",
    "\n",
    "# Part 2: Find new records in Feb24 GHA data\n",
    "new_gha_records = find_new_records(feb24_gha_df, master_df)\n",
    "print(\"New GHA Records:\")\n",
    "print(new_gha_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e5074e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved in the 'Output' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "files = {\n",
    "    \"Feb24_gha\": pd.read_excel(r\"Input\\\\\" + \"Feb24_gha.xlsx\"),\n",
    "    \"Mar24_gha\": pd.read_excel(r\"Input\\\\\" + \"Mar24_gha.xlsx\"),\n",
    "    \"Feb24_open\": pd.read_excel(r\"Input\\\\\" + \"Feb24_open.xlsx\"),\n",
    "    \"Mar24_open\": pd.read_excel(r\"Input\\\\\" + \"Mar24_open.xlsx\")\n",
    "}\n",
    "\n",
    "# Ensure consistent column names\n",
    "for key in files.keys():\n",
    "    files[key].columns = files[key].columns.str.strip()\n",
    "\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, reference_df, month_year, source, key_cols):\n",
    "    updated_records = []\n",
    "\n",
    "    for index, row in current_df.iterrows():\n",
    "        # Find matching row in reference_df based on key_cols\n",
    "        match = reference_df\n",
    "        for key in key_cols:\n",
    "            match = match[match[key] == row[key]]\n",
    "        \n",
    "        if not match.empty:\n",
    "            cols_changed = []\n",
    "            for col in current_df.columns:\n",
    "                if col not in key_cols and col in reference_df.columns:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        cols_changed.append(col)\n",
    "            \n",
    "            if cols_changed:\n",
    "                row_data = row.to_dict()\n",
    "                row_data[\"Month Changed\"] = month_year\n",
    "                row_data[\"Cols Changed\"] = \"; \".join(cols_changed)\n",
    "                row_data[\"Source\"] = source\n",
    "                updated_records.append(row_data)\n",
    "\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, reference_df, month_year, key_cols):\n",
    "    new_records = current_df[\n",
    "        ~current_df[key_cols].apply(tuple, axis=1).isin(reference_df[key_cols].apply(tuple, axis=1))\n",
    "    ]\n",
    "    new_records = new_records.copy()\n",
    "    new_records[\"Month Added\"] = month_year\n",
    "    return new_records\n",
    "\n",
    "# Process all GHA files\n",
    "gha_key_cols = [\"Position ID\", \"Employee ID\"]\n",
    "open_pos_key_cols = [\"Position ID\"]  # No Employee ID for Open Position\n",
    "\n",
    "all_updated_records = []\n",
    "all_new_records = []\n",
    "\n",
    "for file_name, df in files.items():\n",
    "    month_year = file_name.split(\"_\")[0]  # Extract month from filename\n",
    "    source_type = file_name.split(\"_\")[1]  # Extract source type from filename\n",
    "\n",
    "    if source_type == \"gha\":\n",
    "        # Process GHA files\n",
    "        updated_records = find_updated_records(df, master_df, month_year, source_type, gha_key_cols)\n",
    "        new_records = find_new_records(df, master_df, month_year, gha_key_cols)\n",
    "    elif source_type == \"open\":\n",
    "        # Process Open Position files\n",
    "        updated_records = find_updated_records(df, master_df, month_year, source_type, open_pos_key_cols)\n",
    "        new_records = find_new_records(df, master_df, month_year, open_pos_key_cols)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Add to the master results\n",
    "    if not updated_records.empty:\n",
    "        all_updated_records.append(updated_records)\n",
    "    if not new_records.empty:\n",
    "        all_new_records.append(new_records)\n",
    "\n",
    "# Combine all results into final DataFrames\n",
    "final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "# Save results\n",
    "output_dir = \"Input\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_updated_records.to_excel(output_dir + \"Updated_Records.xlsx\", index=False)\n",
    "final_new_records.to_excel(output_dir + \"New_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved in the 'Output' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1924846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHA processing complete. Results saved in the 'Output' folder.\n",
      "Open Position processing complete. Results saved in the 'Output' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "master_df = pd.read_excel(r\"Input\\\\\" + \"master_file.xlsx\")\n",
    "gha_files = [\"Feb24_gha.xlsx\", \"Mar24_gha.xlsx\"]  # Extend this list as new files arrive\n",
    "open_files = [\"Feb24_open.xlsx\", \"Mar24_open.xlsx\"]  # Extend similarly for open position files\n",
    "\n",
    "# Strip column names\n",
    "master_df.columns = master_df.columns.str.strip()\n",
    "\n",
    "# Ensure column name consistency\n",
    "def load_and_prepare(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# Function to find updated records\n",
    "def find_updated_records(current_df, reference_df, month_year, source, key_cols):\n",
    "    updated_records = []\n",
    "    \n",
    "    for index, row in current_df.iterrows():\n",
    "        match = reference_df\n",
    "        for key in key_cols:\n",
    "            match = match[match[key] == row[key]]\n",
    "        \n",
    "        if not match.empty:\n",
    "            cols_changed = []\n",
    "            for col in current_df.columns:\n",
    "                if col not in key_cols and col in reference_df.columns:\n",
    "                    if row[col] != match[col].values[0]:\n",
    "                        cols_changed.append(col)\n",
    "            \n",
    "            if cols_changed:\n",
    "                row_data = row.to_dict()\n",
    "                row_data[\"Month Changed\"] = month_year\n",
    "                row_data[\"Cols Changed\"] = \"; \".join(cols_changed)\n",
    "                row_data[\"Source\"] = source\n",
    "                updated_records.append(row_data)\n",
    "\n",
    "    updated_df = pd.DataFrame(updated_records)\n",
    "    return updated_df\n",
    "\n",
    "# Function to find new records\n",
    "def find_new_records(current_df, reference_df, month_year, key_cols):\n",
    "    new_records = current_df[\n",
    "        ~current_df[key_cols].apply(tuple, axis=1).isin(reference_df[key_cols].apply(tuple, axis=1))\n",
    "    ]\n",
    "    new_records = new_records.copy()\n",
    "    new_records[\"Month Added\"] = month_year\n",
    "    return new_records\n",
    "\n",
    "# Main function to process GHA files\n",
    "def process_gha_files(master_df, files, key_cols):\n",
    "    all_updated_records = []\n",
    "    all_new_records = []\n",
    "\n",
    "    previous_df = master_df  # Start with master as the reference\n",
    "    for file in files:\n",
    "        file_path = f\"Input\\\\{file}\"\n",
    "        current_df = load_and_prepare(file_path)\n",
    "\n",
    "        # Extract month and source\n",
    "        month_year = file.split(\"_\")[0]\n",
    "        source_type = \"gha\"\n",
    "\n",
    "        # Find updated and new records\n",
    "        updated_records = find_updated_records(current_df, previous_df, month_year, source_type, key_cols)\n",
    "        new_records = find_new_records(current_df, previous_df, month_year, key_cols)\n",
    "\n",
    "        # Store results\n",
    "        if not updated_records.empty:\n",
    "            all_updated_records.append(updated_records)\n",
    "        if not new_records.empty:\n",
    "            all_new_records.append(new_records)\n",
    "\n",
    "        # Update reference for next iteration\n",
    "        previous_df = current_df\n",
    "\n",
    "    # Combine results\n",
    "    final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "    final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "    return final_updated_records, final_new_records\n",
    "\n",
    "# Process GHA files\n",
    "gha_key_cols = [\"Position ID\", \"Employee ID\"]\n",
    "final_updated_gha, final_new_gha = process_gha_files(master_df, gha_files, gha_key_cols)\n",
    "\n",
    "# Save results for GHA\n",
    "output_dir = \"Input\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_updated_gha.to_excel(output_dir + \"Updated_GHA_Records.xlsx\", index=False)\n",
    "final_new_gha.to_excel(output_dir + \"New_GHA_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"GHA processing complete. Results saved in the 'Output' folder.\")\n",
    "\n",
    "# Extend for Open Position files\n",
    "def process_open_position_files(master_df, files, key_cols):\n",
    "    all_updated_records = []\n",
    "    all_new_records = []\n",
    "\n",
    "    previous_df = master_df  # Start with master as the reference\n",
    "    for file in files:\n",
    "        file_path = f\"Input\\\\{file}\"\n",
    "        current_df = load_and_prepare(file_path)\n",
    "\n",
    "        # Extract month and source\n",
    "        month_year = file.split(\"_\")[0]\n",
    "        source_type = \"open\"\n",
    "\n",
    "        # Find updated and new records\n",
    "        updated_records = find_updated_records(current_df, previous_df, month_year, source_type, key_cols)\n",
    "        new_records = find_new_records(current_df, previous_df, month_year, key_cols)\n",
    "\n",
    "        # Store results\n",
    "        if not updated_records.empty:\n",
    "            all_updated_records.append(updated_records)\n",
    "        if not new_records.empty:\n",
    "            all_new_records.append(new_records)\n",
    "\n",
    "        # Update reference for next iteration\n",
    "        previous_df = current_df\n",
    "\n",
    "    # Combine results\n",
    "    final_updated_records = pd.concat(all_updated_records, ignore_index=True) if all_updated_records else pd.DataFrame()\n",
    "    final_new_records = pd.concat(all_new_records, ignore_index=True) if all_new_records else pd.DataFrame()\n",
    "\n",
    "    return final_updated_records, final_new_records\n",
    "\n",
    "# Process Open Position files\n",
    "open_key_cols = [\"Position ID\"]  # No Employee ID for Open Position\n",
    "final_updated_open, final_new_open = process_open_position_files(master_df, open_files, open_key_cols)\n",
    "\n",
    "# Save results for Open Position\n",
    "final_updated_open.to_excel(output_dir + \"Updated_Open_Position_Records.xlsx\", index=False)\n",
    "final_new_open.to_excel(output_dir + \"New_Open_Position_Records.xlsx\", index=False)\n",
    "\n",
    "print(\"Open Position processing complete. Results saved in the 'Output' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb006d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Combine updated and new records into a final DataFrame\n",
    "def create_final_dataframe(updated_df, new_df):\n",
    "    # Add missing columns to ensure consistent structure\n",
    "    required_columns = [\"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\", \"Source\", \"Month Added\"]\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in updated_df.columns:\n",
    "            updated_df[col] = None\n",
    "        if col not in new_df.columns:\n",
    "            new_df[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    updated_df = updated_df[required_columns]\n",
    "    new_df = new_df[required_columns]\n",
    "    \n",
    "    # Concatenate both DataFrames\n",
    "    final_df = pd.concat([updated_df, new_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Create final DataFrames for GHA and Open Position files\n",
    "final_gha_df = create_final_dataframe(final_updated_gha, final_new_gha)\n",
    "final_open_df = create_final_dataframe(final_updated_open, final_new_open)\n",
    "\n",
    "# Save the final combined data\n",
    "final_gha_df.to_excel(output_dir + \"Final_GHA_Data.xlsx\", index=False)\n",
    "final_open_df.to_excel(output_dir + \"Final_Open_Position_Data.xlsx\", index=False)\n",
    "\n",
    "print(\"Final combined data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2071f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined data saved to Input\\Final_Combined_Data.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# Combine GHA and Open Position Data into a Single DataFrame\n",
    "def create_combined_dataframe(updated_gha, new_gha, updated_open, new_open):\n",
    "    # Concatenate updated and new records for GHA and Open Position\n",
    "    combined_gha = pd.concat([updated_gha, new_gha], ignore_index=True)\n",
    "    combined_open = pd.concat([updated_open, new_open], ignore_index=True)\n",
    "\n",
    "    # Add missing columns to ensure consistent structure\n",
    "    required_columns = [\n",
    "        \"Position ID\", \"Employee ID\", \"Month Changed\", \"Cols Changed\",\n",
    "        \"Source\", \"Month Added\", \"Col1\", \"Col2\", \"Col3\", \"ColZ\"\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in combined_gha.columns:\n",
    "            combined_gha[col] = None\n",
    "        if col not in combined_open.columns:\n",
    "            combined_open[col] = None\n",
    "\n",
    "    # Align column order\n",
    "    combined_gha = combined_gha[required_columns]\n",
    "    combined_open = combined_open[required_columns]\n",
    "\n",
    "    # Add a 'Data Type' column to differentiate records\n",
    "    combined_gha['Data Type'] = 'GHA'\n",
    "    combined_open['Data Type'] = 'Open Position'\n",
    "\n",
    "    # Concatenate GHA and Open Position data into one DataFrame\n",
    "    final_combined_df = pd.concat([combined_gha, combined_open], ignore_index=True)\n",
    "\n",
    "    return final_combined_df\n",
    "\n",
    "\n",
    "# Create final combined DataFrame\n",
    "final_combined_df = create_combined_dataframe(\n",
    "    final_updated_gha, final_new_gha, final_updated_open, final_new_open\n",
    ")\n",
    "\n",
    "# Save the final combined data\n",
    "output_file = output_dir + \"Final_Combined_Data.xlsx\"\n",
    "final_combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Final combined data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db74af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
